# Shadow Writing Agent - å®Œæ•´äº¤äº’æµç¨‹å®ç°è®¡åˆ’

## é¡¹ç›®ç›®æ ‡

å°†ç°æœ‰çš„"ä¸Šä¼ TED txtæ–‡ä»¶"å·¥ä½œæµå‘å‰å»¶ä¼¸ï¼Œå®ç°å®Œæ•´çš„ç”¨æˆ·äº¤äº’æµç¨‹ï¼š

**ç”¨æˆ·è¾“å…¥ä¸»é¢˜ â†’ æœç´¢TED â†’ é€‰æ‹©æ¼”è®² â†’ è‡ªåŠ¨çˆ¬å– â†’ Shadow Writingå¤„ç†**

---

## æ ¸å¿ƒæ¶æ„è®¾è®¡

### å®Œæ•´æ•°æ®æµå›¾

```
ç”¨æˆ·è¾“å…¥å­¦ä¹ ä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼š"AI ethics"ï¼‰
    â†“
communication_agent (LangGraphèµ·å§‹èŠ‚ç‚¹)
    â”œâ”€ è°ƒç”¨ ted_tavily_search tool
    â”œâ”€ è°ƒç”¨ ted_tavily_extract tool
    â†“
è¿”å›å€™é€‰æ¼”è®²åˆ—è¡¨ â†’ æ¨é€åˆ°å‰ç«¯å±•ç¤º
    â†“
ç”¨æˆ·åœ¨å‰ç«¯é€‰æ‹©æ¼”è®²
    â†“
communication_agentç»§ç»­
    â”œâ”€ è°ƒç”¨ ted_transcript_extractor tool (GitHubåŒ…)
    â”œâ”€ ç”ŸæˆTED txtæ–‡ä»¶ (ä½¿ç”¨TEDFileManager)
    â”œâ”€ è°ƒç”¨ parse_ted_file tool
    â†“
[è¿›å…¥ç°æœ‰Shadow Writingå·¥ä½œæµ]
    â†“
semantic_chunking_agent â†’ sentence_shadow_writing_agent 
â†’ validation_agent â†’ quality_agent â†’ correction_agent 
â†’ finalize_agent
    â†“
è¿”å›æœ€ç»ˆShadow Writingç»“æœ
```

### æŠ€æœ¯é€‰å‹

- **Agentè°ƒç”¨Toolæ–¹å¼**: å‡½æ•°åŒ…è£…ï¼ˆæ™®é€šPythonå‡½æ•°ï¼‰
- **å¤–éƒ¨åŒ…é›†æˆ**: ç›´æ¥å¯¼å…¥ `ted-transcript-extractor` åŒ…
- **äº¤äº’æ–¹å¼**: WebSocketï¼ˆå¼‚æ­¥ï¼Œå®æ—¶æ¨é€ï¼‰ + REST APIï¼ˆåŒæ­¥ï¼Œå¤‡é€‰ï¼‰
- **æ–‡ä»¶ç®¡ç†**: TEDFileManager ç±»ï¼Œæ”¯æŒç¼“å­˜å’Œç”¨æˆ·é…ç½®åˆ é™¤ç­–ç•¥

---

## å®æ–½é˜¶æ®µ

### é˜¶æ®µ1: ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–é…ç½®(å®Œæˆ)

**ç›®æ ‡**: é…ç½®é¡¹ç›®ä¾èµ–å’Œç¯å¢ƒå˜é‡

**æ­¥éª¤**:

1. **æ›´æ–° `backend/requirements.txt`**
   ```
   # æ·»åŠ ä»¥ä¸‹ä¾èµ–
   tavily-python>=0.3.0
   litellm>=1.0.0
   git+https://github.com/Xintong120/ted-transcript-extractor.git
   ```

2. **ä¿®æ”¹ `backend/app/config.py`**
   ```python
   # æ·»åŠ æ–°é…ç½®é¡¹
   tavily_api_key: str = ""
   ted_cache_dir: str = "./data/ted_cache"
   auto_delete_ted_files: bool = False
   max_cache_size_mb: int = 500
   ```

3. **æ›´æ–° `backend/.env` å’Œ `.env.example`**
   ```bash
   # æ·»åŠ 
   TAVILY_API_KEY=your_tavily_key_here
   ```

4. **åˆ›å»ºç¼“å­˜ç›®å½•**
   ```bash
   mkdir -p data/ted_cache
   # æ·»åŠ åˆ° .gitignore
   echo "data/ted_cache/" >> .gitignore
   ```

**éªŒè¯**:
- è¿è¡Œ `pip install -r requirements.txt` æ— é”™è¯¯
- config.py èƒ½æ­£ç¡®è¯»å– TAVILY_API_KEY

---

### é˜¶æ®µ2: Toolå±‚å®ç°

**ç›®æ ‡**: åˆ›å»ºå’Œé€‚é…æ‰€æœ‰å·¥å…·å‡½æ•°

#### 2.1 é€‚é…ç°æœ‰Toolsï¼ˆFastAPIç¯å¢ƒï¼‰âœ… å®Œæˆ

**æ–‡ä»¶**: `backend/app/tools/ted_tavily_search.py`

**æ ¸å¿ƒä¿®æ”¹**: ä»Kaggleçš„UserSecretsClientæ”¹ä¸ºsettings
```python
from app.config import settings
from tavily import TavilyClient

def ted_tavily_search(query: str, max_results: int = 5) -> list:
    """æœç´¢TEDæ¼”è®²"""
    if not settings.tavily_api_key:
        raise ValueError("TAVILY_API_KEY not configured")
    
    tavily_client = TavilyClient(api_key=settings.tavily_api_key)
    
    search_response = tavily_client.search(
        query=f"TED talk {query}",
        search_depth="advanced",
        max_results=max_results,
        include_domains=["ted.com"]
    )
    
    return search_response.get('results', [])
```

**æ–‡ä»¶**: `backend/app/tools/ted_tavily_extract.py`

**æ ¸å¿ƒä¿®æ”¹**: åŒæ ·é€‚é…FastAPIç¯å¢ƒ
```python
from app.config import settings

def ted_tavily_extract(url: str) -> dict:
    """æå–TEDæ¼”è®²é¡µé¢è¯¦æƒ…"""
    tavily_client = TavilyClient(api_key=settings.tavily_api_key)
    extract_response = tavily_client.extract(url)
    
    if extract_response.get('results'):
        return {
            "url": url,
            "raw_content": extract_response['results'][0]['raw_content'],
            "success": True
        }
    return {"url": url, "success": False}
```

#### 2.2 åˆ›å»ºæ–°Tools

**æ–‡ä»¶**: `backend/app/tools/ted_transcript_tool.py` (æ–°å»º)

**åŠŸèƒ½**: åŒ…è£… ted-transcript-extractor åŒ…
```python
from ted_extractor import TEDTranscriptExtractor
from app.models import TedTxt

def extract_ted_transcript(url: str) -> TedTxt:
    """ä»TED URLæå–å®Œæ•´transcript"""
    extractor = TEDTranscriptExtractor(
        delay_between_requests=2.0,
        timeout=30
    )
    
    talk = extractor.extract_single(url)
    
    if not talk.success:
        return None
    
    return TedTxt(
        title=talk.title,
        speaker=talk.speaker,
        url=talk.url,
        duration=f"{talk.duration // 60}:{talk.duration % 60:02d}",
        views=talk.views,
        transcript=talk.transcript
    )
```

**æ–‡ä»¶**: `backend/app/tools/ted_file_manager.py` (æ–°å»º)

**åŠŸèƒ½**: æ–‡ä»¶ç¼“å­˜ç®¡ç†
```python
import hashlib
from pathlib import Path
from app.config import settings
from app.models import TedTxt

class TEDFileManager:
    def __init__(self):
        self.cache_dir = Path(settings.ted_cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def save_ted_file(self, ted_data: TedTxt) -> str:
        """ä¿å­˜TEDæ•°æ®ä¸ºtxtæ–‡ä»¶"""
        filename = self._url_to_filename(ted_data.url)
        filepath = self.cache_dir / filename
        
        content = f"""Title: {ted_data.title}
Speaker: {ted_data.speaker}
URL: {ted_data.url}
Duration: {ted_data.duration}
Views: {ted_data.views}

--- Transcript ---
{ted_data.transcript}
"""
        filepath.write_text(content, encoding='utf-8')
        return str(filepath)
    
    def get_cached_file(self, url: str) -> str | None:
        """æ£€æŸ¥ç¼“å­˜"""
        filename = self._url_to_filename(url)
        filepath = self.cache_dir / filename
        return str(filepath) if filepath.exists() else None
    
    def delete_file(self, filepath: str):
        """åˆ é™¤æ–‡ä»¶ï¼ˆæ ¹æ®é…ç½®ï¼‰"""
        if settings.auto_delete_ted_files:
            Path(filepath).unlink(missing_ok=True)
    
    def _url_to_filename(self, url: str) -> str:
        """URLè½¬æ–‡ä»¶å"""
        url_hash = hashlib.md5(url.encode()).hexdigest()[:12]
        return f"ted_{url_hash}.txt"
```

**éªŒè¯**:
- æ‰€æœ‰toolå‡½æ•°å¯ç‹¬ç«‹æµ‹è¯•
- æ­£ç¡®è°ƒç”¨å¤–éƒ¨APIå’ŒåŒ…
- é”™è¯¯å¤„ç†å®Œå–„

---

### é˜¶æ®µ3: Communication Agentå®ç°

**ç›®æ ‡**: å®ç°äº¤äº’å¼æœç´¢å’Œé€‰æ‹©é€»è¾‘

**æ–‡ä»¶**: `backend/app/agents/communication.py`

**å®ç°ä¸¤ä¸ªå‡½æ•°**:

1. **communication_agent**: ç¬¬ä¸€é˜¶æ®µï¼ˆæœç´¢å¹¶è¿”å›å€™é€‰ï¼‰
```python
from app.state import Shadow_Writing_State
from app.tools.ted_tavily_search import ted_tavily_search
from app.tools.ted_tavily_extract import ted_tavily_extract

def communication_agent(state: Shadow_Writing_State):
    """ç¬¬ä¸€é˜¶æ®µï¼šæœç´¢å¹¶è¿”å›å€™é€‰åˆ—è¡¨"""
    user_topic = state.get("user_topic", "")
    
    # 1. æœç´¢TED
    search_results = ted_tavily_search(user_topic, max_results=5)
    
    # 2. æå–è¯¦æƒ…
    candidates = []
    for result in search_results:
        detail = ted_tavily_extract(result['url'])
        if detail.get('success'):
            candidates.append({
                "title": result['title'],
                "url": result['url'],
                "preview": result['content'][:200] + "..."
            })
    
    # 3. è¿”å›å€™é€‰ï¼Œç­‰å¾…ç”¨æˆ·é€‰æ‹©
    return {
        "ted_candidates": candidates,
        "awaiting_user_selection": True
    }
```

2. **communication_continue_agent**: ç¬¬äºŒé˜¶æ®µï¼ˆçˆ¬å–å’Œè§£æï¼‰
```python
from app.tools.ted_transcript_tool import extract_ted_transcript
from app.tools.ted_file_manager import TEDFileManager
from app.tools.ted_txt_parsers import parse_ted_file

def communication_continue_agent(state: Shadow_Writing_State):
    """ç¬¬äºŒé˜¶æ®µï¼šç”¨æˆ·é€‰æ‹©åçˆ¬å–å’Œè§£æ"""
    selected_url = state.get("selected_ted_url", "")
    file_manager = TEDFileManager()
    
    # 1. æ£€æŸ¥ç¼“å­˜
    cached = file_manager.get_cached_file(selected_url)
    if cached:
        ted_data = parse_ted_file(cached)
    else:
        # 2. çˆ¬å–transcript
        ted_data = extract_ted_transcript(selected_url)
        
        # 3. ä¿å­˜æ–‡ä»¶
        filepath = file_manager.save_ted_file(ted_data)
    
    # 4. è¿›å…¥ä¸‹ä¸€èŠ‚ç‚¹
    return {
        "text": ted_data.transcript,
        "ted_title": ted_data.title,
        "ted_speaker": ted_data.speaker,
        "ted_url": ted_data.url,
        "awaiting_user_selection": False
    }
```

---

### é˜¶æ®µ4: æ›´æ–°Stateå®šä¹‰

**ç›®æ ‡**: æ‰©å±•å·¥ä½œæµçŠ¶æ€ä»¥æ”¯æŒæ–°æµç¨‹

**æ–‡ä»¶**: `backend/app/state.py`

**æ·»åŠ å­—æ®µ**:
```python
class Shadow_Writing_State(TypedDict):
    # === æ–°å¢ï¼šç”¨æˆ·äº¤äº’ç›¸å…³ ===
    user_topic: Optional[str]              # ç”¨æˆ·è¾“å…¥çš„å­¦ä¹ ä¸»é¢˜
    ted_candidates: List[dict]             # å€™é€‰TEDæ¼”è®²åˆ—è¡¨
    selected_ted_url: Optional[str]        # ç”¨æˆ·é€‰æ‹©çš„æ¼”è®²URL
    ted_file_path: Optional[str]           # ä¿å­˜çš„txtæ–‡ä»¶è·¯å¾„
    awaiting_user_selection: bool          # æ˜¯å¦ç­‰å¾…ç”¨æˆ·é€‰æ‹©
    
    # === åŸæœ‰å­—æ®µä¿æŒä¸å˜ ===
    text: str
    # ... å…¶ä»–å­—æ®µ
```

---

### é˜¶æ®µ5: ä¿®æ”¹LangGraphå·¥ä½œæµ

**ç›®æ ‡**: é›†æˆcommunication_agentåˆ°å·¥ä½œæµ

**æ–‡ä»¶**: `backend/app/agent.py`

**å…³é”®ä¿®æ”¹**:

1. **å¯¼å…¥æ–°agent**:
```python
from app.agents.communication import (
    communication_agent, 
    communication_continue_agent
)
```

2. **æ·»åŠ èŠ‚ç‚¹**:
```python
builder.add_node("communication", communication_agent)
builder.add_node("communication_continue", communication_continue_agent)
```

3. **æ·»åŠ æ¡ä»¶è·¯ç”±**:
```python
def route_start(state):
    """åˆ¤æ–­æ˜¯æ–‡ä»¶ä¸Šä¼ è¿˜æ˜¯ä¸»é¢˜æœç´¢"""
    if state.get("user_topic"):
        return "communication"
    else:
        return "semantic_chunking"

def route_after_communication(state):
    """åˆ¤æ–­æ˜¯å¦ç­‰å¾…ç”¨æˆ·é€‰æ‹©"""
    if state.get("awaiting_user_selection"):
        return "wait"  # ä¸­æ–­ï¼Œè¿”å›å€™é€‰åˆ—è¡¨
    else:
        return "continue"

# è®¾ç½®è¾¹
builder.add_conditional_edges(START, route_start, {
    "communication": "communication",
    "semantic_chunking": "semantic_chunking"
})

builder.add_conditional_edges("communication", route_after_communication, {
    "wait": END,
    "continue": "communication_continue"
})

builder.add_edge("communication_continue", "semantic_chunking")
# ... å…¶ä»–è¾¹ä¿æŒä¸å˜
```

4. **æ–°å¢å¤„ç†å‡½æ•°**:
```python
def process_ted_by_topic(topic: str) -> dict:
    """é€šè¿‡ä¸»é¢˜æœç´¢TED"""
    workflow = create_shadow_writing_workflow()
    initial_state = {"user_topic": topic, ...}
    result = workflow.invoke(initial_state)
    
    if result.get("awaiting_user_selection"):
        return {
            "status": "awaiting_selection",
            "candidates": result["ted_candidates"]
        }

def process_ted_after_selection(selected_url: str, state: dict):
    """ç”¨æˆ·é€‰æ‹©åç»§ç»­å¤„ç†"""
    state["selected_ted_url"] = selected_url
    workflow = create_shadow_writing_workflow()
    result = workflow.invoke(state)
    return {"results": result["final_shadow_chunks"]}
```

---

### é˜¶æ®µ6: APIæ¥å£å®ç°

**ç›®æ ‡**: åˆ›å»ºå‰åç«¯äº¤äº’çš„APIç«¯ç‚¹

**æ–‡ä»¶**: `backend/app/main.py`

**å®ç°ä¸¤ç§æ¥å£æ–¹å¼**:

#### æ–¹å¼1: REST APIï¼ˆåŒæ­¥ï¼Œç®€å•å®ç°ï¼‰

```python
@app.post("/api/search-ted")
async def search_ted_endpoint(request: dict):
    """
    æœç´¢TEDæ¼”è®²
    
    Request:
        {"topic": "AI ethics"}
    
    Response:
        {
            "status": "success",
            "candidates": [
                {"title": "...", "url": "...", "preview": "..."}
            ]
        }
    """
    topic = request.get("topic", "")
    
    if not topic:
        raise HTTPException(status_code=400, detail="Topic required")
    
    result = process_ted_by_topic(topic)
    
    if result.get("status") == "awaiting_selection":
        return {
            "status": "success",
            "candidates": result["candidates"]
        }
    else:
        raise HTTPException(status_code=500, detail="Unexpected state")


@app.post("/api/select-ted")
async def select_ted_endpoint(request: dict):
    """
    é€‰æ‹©TEDæ¼”è®²å¹¶å¤„ç†
    
    Request:
        {
            "url": "https://ted.com/talks/...",
            "previous_state": {...}
        }
    
    Response:
        {
            "status": "success",
            "results": [...],
            "result_count": 5
        }
    """
    url = request.get("url", "")
    previous_state = request.get("previous_state", {})
    
    if not url:
        raise HTTPException(status_code=400, detail="URL required")
    
    result = process_ted_after_selection(url, previous_state)
    
    return {
        "status": "success",
        "results": result["results"],
        "result_count": len(result["results"])
    }
```

#### æ–¹å¼2: WebSocketï¼ˆå¼‚æ­¥ï¼Œæ¨èï¼‰

```python
@app.websocket("/ws/ted-workflow")
async def websocket_ted_workflow(websocket: WebSocket):
    """
    WebSocketæ¥å£ï¼šå®æ—¶äº¤äº’æµç¨‹
    
    æµç¨‹ï¼š
    1. å®¢æˆ·ç«¯å‘é€ä¸»é¢˜ â†’ æœåŠ¡ç«¯å®æ—¶æ¨é€æœç´¢è¿›åº¦
    2. æœåŠ¡ç«¯æ¨é€å€™é€‰åˆ—è¡¨
    3. å®¢æˆ·ç«¯å‘é€é€‰æ‹© â†’ æœåŠ¡ç«¯å®æ—¶æ¨é€å¤„ç†è¿›åº¦
    4. æœåŠ¡ç«¯æ¨é€æœ€ç»ˆç»“æœ
    """
    await websocket.accept()
    
    try:
        # 1. æ¥æ”¶ä¸»é¢˜
        data = await websocket.receive_json()
        topic = data.get("topic", "")
        
        # 2. æœç´¢é˜¶æ®µ
        await websocket.send_json({
            "type": "status",
            "message": f"æ­£åœ¨æœç´¢: {topic}"
        })
        
        result = process_ted_by_topic(topic)
        
        # 3. æ¨é€å€™é€‰åˆ—è¡¨
        if result.get("status") == "awaiting_selection":
            await websocket.send_json({
                "type": "candidates",
                "data": result["candidates"]
            })
            
            # 4. ç­‰å¾…ç”¨æˆ·é€‰æ‹©
            selection = await websocket.receive_json()
            selected_url = selection.get("selected_url", "")
            
            # 5. å¤„ç†é˜¶æ®µ
            await websocket.send_json({
                "type": "status",
                "message": "æ­£åœ¨çˆ¬å–transcript..."
            })
            
            final_result = process_ted_after_selection(
                selected_url,
                result.get("state", {})
            )
            
            # 6. æ¨é€æœ€ç»ˆç»“æœ
            await websocket.send_json({
                "type": "result",
                "data": final_result
            })
        
    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "message": str(e)
        })
    finally:
        await websocket.close()
```

---

### é˜¶æ®µ7: å‰ç«¯å®ç°

**ç›®æ ‡**: åˆ›å»ºç”¨æˆ·äº¤äº’ç•Œé¢

**æ–‡ä»¶**: `frontend/src/pages/TEDSearch.jsx` (æ–°å»º)

**å®ç°å†…å®¹**:

```jsx
import { useState } from 'react';

export default function TEDSearch() {
  const [topic, setTopic] = useState('');
  const [candidates, setCandidates] = useState([]);
  const [results, setResults] = useState([]);
  const [loading, setLoading] = useState(false);
  const [stage, setStage] = useState('input'); // input, candidates, results
  
  // 1. æœç´¢TED
  const handleSearch = async () => {
    setLoading(true);
    setStage('searching');
    
    const response = await fetch('/api/search-ted', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ topic })
    });
    
    const data = await response.json();
    setCandidates(data.candidates);
    setStage('candidates');
    setLoading(false);
  };
  
  // 2. é€‰æ‹©å¹¶å¤„ç†
  const handleSelect = async (url) => {
    setLoading(true);
    setStage('processing');
    
    const response = await fetch('/api/select-ted', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ url })
    });
    
    const data = await response.json();
    setResults(data.results);
    setStage('results');
    setLoading(false);
  };
  
  return (
    <div className="container">
      <h1>TED Shadow Writing</h1>
      
      {/* é˜¶æ®µ1: è¾“å…¥ä¸»é¢˜ */}
      {stage === 'input' && (
        <div className="search-box">
          <input 
            type="text"
            value={topic}
            onChange={(e) => setTopic(e.target.value)}
            placeholder="è¾“å…¥å­¦ä¹ ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šAI ethics"
            className="input"
          />
          <button onClick={handleSearch} className="btn-primary">
            æœç´¢TEDæ¼”è®²
          </button>
        </div>
      )}
      
      {/* é˜¶æ®µ2: é€‰æ‹©æ¼”è®² */}
      {stage === 'candidates' && (
        <div className="candidates">
          <h2>æ‰¾åˆ°ä»¥ä¸‹TEDæ¼”è®²ï¼Œè¯·é€‰æ‹©ä¸€ä¸ªï¼š</h2>
          {candidates.map((c, i) => (
            <div key={i} className="candidate-card">
              <h3>{c.title}</h3>
              <p>{c.preview}</p>
              <button onClick={() => handleSelect(c.url)} className="btn-secondary">
                é€‰æ‹©è¿™ä¸ªæ¼”è®²
              </button>
            </div>
          ))}
        </div>
      )}
      
      {/* é˜¶æ®µ3: æ˜¾ç¤ºç»“æœ */}
      {stage === 'results' && (
        <div className="results">
          <h2>Shadow Writing ç»“æœ</h2>
          {results.map((r, i) => (
            <div key={i} className="result-card">
              <h3>åŸå¥: {r.original}</h3>
              <p>è¿ç§»: {r.imitation}</p>
              <div>æ˜ å°„: {JSON.stringify(r.map)}</div>
            </div>
          ))}
        </div>
      )}
      
      {/* LoadingçŠ¶æ€ */}
      {loading && (
        <div className="loading">
          {stage === 'searching' && 'æ­£åœ¨æœç´¢...'}
          {stage === 'processing' && 'æ­£åœ¨å¤„ç†...'}
        </div>
      )}
    </div>
  );
}
```

**è·¯ç”±é…ç½®**: `frontend/src/App.jsx`

```jsx
import { BrowserRouter, Routes, Route } from 'react-router-dom';
import TEDSearch from './pages/TEDSearch';
import FileUpload from './pages/FileUpload'; // åŸæœ‰çš„ä¸Šä¼ é¡µé¢

export default function App() {
  return (
    <BrowserRouter>
      <Routes>
        <Route path="/" element={<TEDSearch />} />
        <Route path="/upload" element={<FileUpload />} />
      </Routes>
    </BrowserRouter>
  );
}
```

---

## æµ‹è¯•æ¸…å•

### Toolå±‚æµ‹è¯•

- [ ] `ted_tavily_search` èƒ½æ­£ç¡®æœç´¢TED
- [ ] `ted_tavily_extract` èƒ½æ­£ç¡®æå–é¡µé¢è¯¦æƒ…
- [ ] `ted_transcript_tool` èƒ½æ­£ç¡®çˆ¬å–transcript
- [ ] `ted_file_manager` èƒ½æ­£ç¡®ä¿å­˜/è¯»å–/åˆ é™¤æ–‡ä»¶
- [ ] ç¼“å­˜æœºåˆ¶æ­£å¸¸å·¥ä½œ

### Agentå±‚æµ‹è¯•

- [ ] `communication_agent` èƒ½æ­£ç¡®æœç´¢å¹¶è¿”å›å€™é€‰åˆ—è¡¨
- [ ] `communication_continue_agent` èƒ½æ­£ç¡®å¤„ç†ç”¨æˆ·é€‰æ‹©
- [ ] çŠ¶æ€ç®¡ç†æ­£ç¡®ï¼ˆawaiting_user_selectionå­—æ®µï¼‰
- [ ] é”™è¯¯å¤„ç†å®Œå–„

### å·¥ä½œæµæµ‹è¯•

- [ ] ä¸»é¢˜æœç´¢æµç¨‹å®Œæ•´è¿è¡Œï¼ˆç”¨æˆ·è¾“å…¥â†’æœç´¢â†’é€‰æ‹©â†’å¤„ç†ï¼‰
- [ ] æ–‡ä»¶ä¸Šä¼ æµç¨‹ä¸å—å½±å“ï¼ˆåŸæœ‰åŠŸèƒ½ä¿æŒï¼‰
- [ ] æ¡ä»¶è·¯ç”±æ­£ç¡®ï¼ˆä¸»é¢˜æœç´¢ vs æ–‡ä»¶ä¸Šä¼ ï¼‰
- [ ] ä¸­æ–­å’Œæ¢å¤æœºåˆ¶æ­£å¸¸ï¼ˆç­‰å¾…ç”¨æˆ·é€‰æ‹©ï¼‰

### APIæµ‹è¯•

- [ ] RESTæ¥å£ `/api/search-ted` æ­£å¸¸å·¥ä½œ
- [ ] RESTæ¥å£ `/api/select-ted` æ­£å¸¸å·¥ä½œ
- [ ] WebSocketæ¥å£ `/ws/ted-workflow` å®æ—¶æ¨é€æ­£å¸¸
- [ ] é”™è¯¯å¤„ç†å’Œå¼‚å¸¸è¿”å›æ­£ç¡®

### å‰ç«¯æµ‹è¯•

- [ ] ä¸»é¢˜æœç´¢ç•Œé¢æ­£å¸¸æ˜¾ç¤º
- [ ] å€™é€‰åˆ—è¡¨å±•ç¤ºæ­£ç¡®
- [ ] ç”¨æˆ·é€‰æ‹©äº¤äº’æµç•…
- [ ] ç»“æœå±•ç¤ºå®Œæ•´
- [ ] LoadingçŠ¶æ€æ˜¾ç¤ºæ­£ç¡®

---

## æ³¨æ„äº‹é¡¹

### 1. ç¯å¢ƒå˜é‡é…ç½®
- ç¡®ä¿ `.env` æ–‡ä»¶åŒ…å« `TAVILY_API_KEY`
- å¤šä¸ªGroq API Keyé…ç½®ï¼ˆé¿å…é€Ÿç‡é™åˆ¶ï¼‰
- ä¸è¦å°†API Keyæäº¤åˆ°Git

### 2. ç¼“å­˜ç®¡ç†
- é¦–æ¬¡è¿è¡Œè‡ªåŠ¨åˆ›å»º `data/ted_cache/` ç›®å½•
- ç¼“å­˜æ–‡ä»¶ä½¿ç”¨MD5å“ˆå¸Œå‘½åï¼Œé¿å…é‡å¤
- å®šæœŸæ¸…ç†ç¼“å­˜ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

### 3. åŒ…å®‰è£…
- ä»GitHubå®‰è£… `ted-transcript-extractor`
- ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
- å¯èƒ½éœ€è¦ä»£ç†ï¼ˆGitHubè®¿é—®ï¼‰

### 4. APIé€Ÿç‡é™åˆ¶
- **Tavily API**: æœ‰å…è´¹é…é¢é™åˆ¶
- **TEDç½‘ç«™**: æœ‰çˆ¬è™«é€Ÿç‡é™åˆ¶ï¼ˆå·²è®¾ç½®2ç§’å»¶è¿Ÿï¼‰
- **Groq API**: ä½¿ç”¨å¤šKeyè½®æ¢æœºåˆ¶

### 5. é”™è¯¯å¤„ç†
- æ¯ä¸ªtoolå’Œagentéƒ½åº”æœ‰å®Œå–„çš„å¼‚å¸¸å¤„ç†
- å‘ç”¨æˆ·æ˜¾ç¤ºå‹å¥½çš„é”™è¯¯ä¿¡æ¯
- è®°å½•è¯¦ç»†çš„é”™è¯¯æ—¥å¿—ï¼ˆä¾¿äºè°ƒè¯•ï¼‰

### 6. ç”¨æˆ·ä½“éªŒ
- **æ¨èä½¿ç”¨WebSocket**ï¼šå®æ—¶åé¦ˆï¼Œä½“éªŒæœ€ä½³
- REST APIä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼ˆç®€å•ä½†ä½“éªŒç¨å·®ï¼‰
- æ·»åŠ LoadingçŠ¶æ€ï¼Œé¿å…ç”¨æˆ·ç­‰å¾…ç„¦è™‘
- æä¾›è¿›åº¦æç¤ºï¼ˆæœç´¢ä¸­ã€çˆ¬å–ä¸­ã€å¤„ç†ä¸­ï¼‰

### 7. æ€§èƒ½ä¼˜åŒ–
- ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤çˆ¬å–
- æ‰¹é‡å¤„ç†å€™é€‰æ¼”è®²ï¼ˆå¹¶å‘æå–ï¼‰
- å‰ç«¯æ‡’åŠ è½½ç»“æœï¼ˆå¤§é‡æ•°æ®æ—¶ï¼‰

---

## å®æ–½é¡ºåºå»ºè®®

### å»ºè®®çš„å®æ–½é¡ºåºï¼š

1. **é˜¶æ®µ1** â†’ ç¯å¢ƒå‡†å¤‡ï¼ˆé…ç½®ä¾èµ–å’Œç¯å¢ƒå˜é‡ï¼‰
2. **é˜¶æ®µ2** â†’ Toolå±‚å®ç°ï¼ˆå…ˆå®ç°å’Œæµ‹è¯•å·¥å…·å‡½æ•°ï¼‰
3. **é˜¶æ®µ3** â†’ Communication Agentï¼ˆå®ç°æœç´¢å’Œé€‰æ‹©é€»è¾‘ï¼‰
4. **é˜¶æ®µ4** â†’ Stateå®šä¹‰æ›´æ–°ï¼ˆæ‰©å±•å·¥ä½œæµçŠ¶æ€ï¼‰
5. **é˜¶æ®µ5** â†’ å·¥ä½œæµé›†æˆï¼ˆä¿®æ”¹LangGraphå·¥ä½œæµï¼‰
6. **é˜¶æ®µ6a** â†’ REST APIå®ç°ï¼ˆå…ˆå®ç°ç®€å•ç‰ˆæœ¬ï¼‰
7. **æµ‹è¯•** â†’ ç«¯åˆ°ç«¯æµ‹è¯•REST APIæµç¨‹
8. **é˜¶æ®µ7** â†’ å‰ç«¯å®ç°ï¼ˆé…åˆREST APIï¼‰
9. **é˜¶æ®µ6b** â†’ WebSocketå‡çº§ï¼ˆä½“éªŒæ›´å¥½ï¼‰
10. **æœ€ç»ˆæµ‹è¯•** â†’ å®Œæ•´æµç¨‹æµ‹è¯•å’Œä¼˜åŒ–

### æ¸è¿›å¼å¼€å‘ç­–ç•¥ï¼š

- **æ¯ä¸ªé˜¶æ®µå®Œæˆåè¿›è¡ŒéªŒè¯**ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸
- **å…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½**ï¼ˆREST APIï¼‰ï¼Œå†ä¼˜åŒ–ä½“éªŒï¼ˆWebSocketï¼‰
- **ä¿æŒåŸæœ‰åŠŸèƒ½ä¸å—å½±å“**ï¼ˆæ–‡ä»¶ä¸Šä¼ æµç¨‹ï¼‰
- **åŠæ—¶å¤„ç†é”™è¯¯å’Œè¾¹ç•Œæƒ…å†µ**

---

## å®Œæˆæ ‡å‡†

å½“ä»¥ä¸‹æ‰€æœ‰é¡¹éƒ½å®Œæˆæ—¶ï¼Œé¡¹ç›®å³ä¸ºå®Œæˆï¼š

âœ… **åŠŸèƒ½å®Œæ•´æ€§**
- ç”¨æˆ·å¯ä»¥é€šè¿‡ä¸»é¢˜æœç´¢TEDæ¼”è®²
- ç”¨æˆ·å¯ä»¥é€‰æ‹©æ¼”è®²å¹¶è‡ªåŠ¨å¤„ç†
- åŸæœ‰æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æ­£å¸¸
- Shadow Writingå¤„ç†ç»“æœæ­£ç¡®

âœ… **ä»£ç è´¨é‡**
- æ‰€æœ‰toolå‡½æ•°å¯ç‹¬ç«‹æµ‹è¯•
- Agenté€»è¾‘æ¸…æ™°ï¼ŒèŒè´£åˆ†ç¦»
- é”™è¯¯å¤„ç†å®Œå–„
- ä»£ç æ³¨é‡Šå……åˆ†

âœ… **ç”¨æˆ·ä½“éªŒ**
- ç•Œé¢å‹å¥½ï¼Œäº¤äº’æµç•…
- æœ‰å®æ—¶åé¦ˆå’Œè¿›åº¦æç¤º
- é”™è¯¯ä¿¡æ¯å‹å¥½
- å“åº”é€Ÿåº¦å¿«ï¼ˆç¼“å­˜ä¼˜åŒ–ï¼‰

âœ… **æ–‡æ¡£å®Œå–„**
- READMEæ›´æ–°ï¼ˆæ–°åŠŸèƒ½è¯´æ˜ï¼‰
- APIæ–‡æ¡£å®Œæ•´
- ç¯å¢ƒé…ç½®è¯´æ˜æ¸…æ™°

---

## åç»­ä¼˜åŒ–æ–¹å‘

å®ŒæˆåŸºæœ¬åŠŸèƒ½åï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹ä¼˜åŒ–ï¼š

1. **æ‰¹é‡å¤„ç†**: æ”¯æŒä¸€æ¬¡é€‰æ‹©å¤šä¸ªæ¼”è®²
2. **è¿‡æ»¤å’Œæ’åº**: æŒ‰ç›¸å…³åº¦ã€æ—¶é•¿ã€è§‚çœ‹æ¬¡æ•°æ’åºå€™é€‰
3. **å†å²è®°å½•**: ä¿å­˜ç”¨æˆ·çš„æœç´¢å’Œå¤„ç†å†å²
4. **å¯¼å‡ºåŠŸèƒ½**: å°†ç»“æœå¯¼å‡ºä¸ºPDFã€Markdownç­‰æ ¼å¼
5. **è¿›åº¦æŒä¹…åŒ–**: ä¸­æ–­åå¯æ¢å¤è¿›åº¦
6. **æ¨èç³»ç»Ÿ**: æ ¹æ®å­¦ä¹ å†å²æ¨èç›¸å…³æ¼”è®²
7. **å¤šè¯­è¨€æ”¯æŒ**: ç•Œé¢å›½é™…åŒ–

---

**è®¡åˆ’ç¼–å†™å®Œæˆï¼æŒ‰ç…§è¿™ä¸ªè®¡åˆ’é€æ­¥å®æ–½å³å¯ã€‚** 

---

---

# é˜¶æ®µ8: Shadow Writingæµæ°´çº¿å¹¶è¡Œæ¶æ„é‡æ„

## é—®é¢˜è¯Šæ–­

### å½“å‰æ¶æ„çš„æ€§èƒ½ç“¶é¢ˆ

**ä¸²è¡Œå¤„ç†æ¨¡å¼**ï¼š
```
61ä¸ªè¯­ä¹‰å—å…¨éƒ¨å®Œæˆsentence_shadow_writing 
    â†“
61ä¸ªç»“æœå…¨éƒ¨å®Œæˆvalidation
    â†“
61ä¸ªç»“æœå…¨éƒ¨å®Œæˆquality
    â†“
ä¸åˆæ ¼çš„å…¨éƒ¨å®Œæˆcorrection
    â†“
finalizeæ±‡æ€»
```

**å®é™…é—®é¢˜**ï¼š
1. **å¼ºåˆ¶å»¶è¿Ÿå¯¼è‡´æ•ˆç‡ä½ä¸‹**
   - `sentence_shadow_writing.py` ç¬¬38-42è¡Œæœ‰ `time.sleep(15)` å¼ºåˆ¶ç­‰å¾…
   - å¤„ç†61ä¸ªå—éœ€è¦ç­‰å¾…ï¼š61 Ã— 15ç§’ â‰ˆ **15åˆ†é’Ÿ**
   - å®é™…APIè°ƒç”¨æ—¶é—´åªå æ€»æ—¶é—´çš„10-20%

2. **å¤šAPI Keyèµ„æºæµªè´¹**
   - é…ç½®äº†13ä¸ªGroq API Key
   - ç†è®ºååé‡ï¼š13 Ã— 30æ¬¡/åˆ†é’Ÿ = 390æ¬¡/åˆ†é’Ÿ
   - å®é™…ååé‡ï¼š4æ¬¡/åˆ†é’Ÿ
   - **èµ„æºåˆ©ç”¨ç‡åªæœ‰1%**

3. **é¢‘ç¹çš„é€Ÿç‡é™åˆ¶é”™è¯¯**
   ```
   Key ***YIwaDE7b è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œå†·å´ 60ç§’
   æ‰€æœ‰ Key éƒ½åœ¨å†·å´ä¸­ï¼Œç­‰å¾… 30ç§’...
   ```
   - ä¸²è¡Œå¤„ç†è®©å•ä¸ªKeyè¢«å¿«é€Ÿè€—å°½
   - å…¶ä»–Keysåœ¨ç­‰å¾…ä¸­ç™½ç™½æµªè´¹

---

## ç›®æ ‡æ¶æ„ï¼šæµæ°´çº¿å¹¶è¡Œ

### æ ¸å¿ƒç†å¿µè½¬å˜

**ä»æ‰¹é‡ä¸²è¡Œåˆ°æµæ°´çº¿å¹¶è¡Œ**ï¼š

```
å½“å‰ä¸²è¡Œï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Chunk1â†’61: Shadow Writing (15åˆ†é’Ÿ)
           â†“
Chunk1â†’61: Validation (1åˆ†é’Ÿ)
           â†“
Chunk1â†’61: Quality (3åˆ†é’Ÿ)
           â†“
Failed: Correction (1åˆ†é’Ÿ)
           â†“
Finalize (5ç§’)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»è€—æ—¶ï¼š~20åˆ†é’Ÿ


ç›®æ ‡æµæ°´çº¿å¹¶è¡Œï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Chunk1:  SWâ†’Vâ†’Qâ†’[C]â†’F â”â”â”â”â”â”â”â”â”â”â”â”â”“
Chunk2:     SWâ†’Vâ†’Qâ†’[C]â†’F â”â”â”â”â”â”â”â”â”â”«
Chunk3:        SWâ†’Vâ†’Qâ†’[C]â†’F â”â”â”â”â”â”â”«
Chunk4:           SWâ†’Vâ†’Qâ†’[C]â†’F â”â”â”â”«â†’ Aggregate
...                                 â”ƒ   Results
Chunk59:                        SWâ†’â”«
Chunk60:                           SWâ†’â”«
Chunk61:                              SWâ†’â”›
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»è€—æ—¶ï¼š~1.5-2åˆ†é’Ÿï¼ˆ90%æå‡ï¼‰
```

### å…³é”®æŠ€æœ¯ç‚¹

1. **ä½¿ç”¨LangGraphçš„Send API**
   - åŠ¨æ€åˆ†å‘ï¼šä¸ºæ¯ä¸ªchunkåˆ›å»ºç‹¬ç«‹çš„æ‰§è¡Œæµ
   - è‡ªåŠ¨å¹¶è¡Œï¼šLangGraphè‡ªåŠ¨ç®¡ç†å¹¶å‘

2. **ä½¿ç”¨operator.addè‡ªåŠ¨æ±‡æ€»**
   - åœ¨Stateä¸­å®šä¹‰ï¼š`Annotated[list, operator.add]`
   - æ¯ä¸ªchunkå®Œæˆåè‡ªåŠ¨è¿½åŠ åˆ°ç»“æœåˆ—è¡¨

3. **å­å›¾å°è£…å®Œæ•´æµç¨‹**
   - å°† shadow_writingâ†’validationâ†’qualityâ†’correctionâ†’finalize å°è£…ä¸ºå­å›¾
   - æ¯ä¸ªchunkç‹¬ç«‹è¿è¡Œå®Œæ•´æµç¨‹

---

## å®æ–½æ­¥éª¤

### æ­¥éª¤1: ä¿®æ”¹Stateå®šä¹‰ï¼ˆæ·»åŠ operator.addï¼‰

**æ–‡ä»¶**: `backend/app/state.py`

```python
from typing import TypedDict, List, Optional, Annotated
import operator
from app.models import Ted_Shadows

class Shadow_Writing_State(TypedDict):
    """shadow writingå·¥ä½œæµçŠ¶æ€"""
    
    # === è¾“å…¥ ===
    topic: Optional[str]
    user_id: Optional[str]
    text: str
    target_topic: Optional[str]
    ted_title: Optional[str]
    ted_speaker: Optional[str]
    ted_url: Optional[str]
    
    # === è¯­ä¹‰åˆ†å— ===
    semantic_chunks: List[str]
    
    # === å¹¶è¡Œå¤„ç†å…³é”®ï¼šä½¿ç”¨operator.addè‡ªåŠ¨æ±‡æ€» ===
    final_shadow_chunks: Annotated[List[Ted_Shadows], operator.add]  # è‡ªåŠ¨åˆå¹¶
    
    # === å…ƒæ•°æ® ===
    current_node: str
    processing_logs: Optional[List[str]]
    errors: Optional[List[str]]
    error_message: Optional[str]

# æ–°å¢ï¼šå•ä¸ªChunkçš„å­çŠ¶æ€
class ChunkProcessState(TypedDict):
    """å•ä¸ªè¯­ä¹‰å—çš„å¤„ç†çŠ¶æ€"""
    chunk_text: str                        # å½“å‰è¯­ä¹‰å—æ–‡æœ¬
    chunk_id: int                          # å—ID
    
    # å¤„ç†æµç¨‹
    raw_shadow: Optional[dict]             # Shadow WritingåŸå§‹ç»“æœ
    validated_shadow: Optional[Ted_Shadows] # éªŒè¯é€šè¿‡çš„ç»“æœ
    quality_passed: bool                   # è´¨é‡æ£€æŸ¥æ˜¯å¦é€šè¿‡
    quality_score: float                   # è´¨é‡åˆ†æ•°
    quality_detail: Optional[dict]         # è´¨é‡è¯„ä¼°è¯¦æƒ…
    corrected_shadow: Optional[Ted_Shadows] # ä¿®æ­£åçš„ç»“æœ
    
    # æœ€ç»ˆè¾“å‡º
    final_result: Optional[Ted_Shadows]    # æœ€ç»ˆç»“æœ
```

---

### æ­¥éª¤2: åˆ›å»ºå•Chunkå¤„ç†å­å›¾

**æ–‡ä»¶**: `backend/app/workflows.py` (æ–°å¢å‡½æ•°)

```python
from langgraph.graph import StateGraph, END, START
from langgraph.types import Send
from app.state import Shadow_Writing_State, ChunkProcessState
from app.agents.sentence_shadow_writing import shadow_writing_single_chunk
from app.agents.validation import validation_single_chunk
from app.agents.quality import quality_single_chunk
from app.agents.correction import correction_single_chunk
from app.agents.finalize import finalize_single_chunk


def create_chunk_pipeline():
    """
    åˆ›å»ºå•ä¸ªChunkçš„å¤„ç†æµæ°´çº¿å­å›¾
    
    æµç¨‹ï¼š
    shadow_writing â†’ validation â†’ quality â†’ [correction] â†’ finalize_chunk
    """
    pipeline = StateGraph(ChunkProcessState)
    
    # æ·»åŠ æ‰€æœ‰å¤„ç†èŠ‚ç‚¹
    pipeline.add_node("shadow_writing", shadow_writing_single_chunk)
    pipeline.add_node("validation", validation_single_chunk)
    pipeline.add_node("quality", quality_single_chunk)
    pipeline.add_node("correction", correction_single_chunk)
    pipeline.add_node("finalize_chunk", finalize_single_chunk)
    
    # æ¡ä»¶è·¯ç”±å‡½æ•°
    def should_correct(state: ChunkProcessState) -> str:
        """å†³å®šæ˜¯å¦éœ€è¦ä¿®æ­£"""
        if not state.get("quality_passed", False):
            return "correction"
        else:
            return "finalize_chunk"
    
    # è®¾ç½®æµæ°´çº¿è·¯å¾„
    pipeline.add_edge(START, "shadow_writing")
    pipeline.add_edge("shadow_writing", "validation")
    pipeline.add_edge("validation", "quality")
    
    # æ¡ä»¶è·¯ç”±ï¼šquality â†’ correction æˆ– finalize_chunk
    pipeline.add_conditional_edges(
        "quality",
        should_correct,
        {
            "correction": "correction",
            "finalize_chunk": "finalize_chunk"
        }
    )
    
    pipeline.add_edge("correction", "finalize_chunk")
    pipeline.add_edge("finalize_chunk", END)
    
    return pipeline.compile()


def create_parallel_shadow_writing_workflow():
    """
    åˆ›å»ºå¹¶è¡ŒShadow Writingå·¥ä½œæµï¼ˆä½¿ç”¨Send APIï¼‰
    
    æµç¨‹ï¼š
    START â†’ semantic_chunking â†’ [åŠ¨æ€åˆ†å‘åˆ°å¤šä¸ªchunk_pipeline] â†’ aggregate_results â†’ END
    """
    builder = StateGraph(Shadow_Writing_State)
    
    # 1. è¯­ä¹‰åˆ†å—èŠ‚ç‚¹ï¼ˆä¸å˜ï¼‰
    builder.add_node("semantic_chunking", Semantic_Chunking_Agent())
    
    # 2. Chunkå¤„ç†æµæ°´çº¿ï¼ˆå­å›¾ï¼‰
    chunk_pipeline = create_chunk_pipeline()
    builder.add_node("chunk_pipeline", chunk_pipeline)
    
    # 3. æ±‡æ€»èŠ‚ç‚¹ï¼ˆæ–°å¢ï¼‰
    builder.add_node("aggregate_results", aggregate_results_node)
    
    # 4. åŠ¨æ€åˆ†å‘å‡½æ•°ï¼ˆå…³é”®ï¼‰
    def continue_to_pipelines(state: Shadow_Writing_State):
        """
        ä¸ºæ¯ä¸ªè¯­ä¹‰å—åˆ›å»ºç‹¬ç«‹çš„å¤„ç†æµæ°´çº¿
        
        ä½¿ç”¨Send APIåŠ¨æ€åˆ†å‘
        """
        semantic_chunks = state.get("semantic_chunks", [])
        
        # ä¸ºæ¯ä¸ªchunkåˆ›å»ºä¸€ä¸ªSendæŒ‡ä»¤
        return [
            Send(
                "chunk_pipeline",
                {
                    "chunk_text": chunk,
                    "chunk_id": i,
                    # å¯ä»¥ä¼ é€’å…¨å±€ä¿¡æ¯
                    "ted_url": state.get("ted_url", ""),
                    "ted_title": state.get("ted_title", "")
                }
            )
            for i, chunk in enumerate(semantic_chunks)
        ]
    
    # 5. è®¾ç½®å·¥ä½œæµè·¯å¾„
    builder.add_edge(START, "semantic_chunking")
    
    # å…³é”®ï¼šä½¿ç”¨conditional_edges + SendåŠ¨æ€åˆ†å‘
    builder.add_conditional_edges(
        "semantic_chunking",
        continue_to_pipelines,
        ["chunk_pipeline"]
    )
    
    # æ‰€æœ‰chunk_pipelineå®Œæˆåï¼Œè‡ªåŠ¨è¿›å…¥aggregate_results
    builder.add_edge("chunk_pipeline", "aggregate_results")
    builder.add_edge("aggregate_results", END)
    
    return builder.compile()
```

---

### æ­¥éª¤3: å®ç°å•Chunkå¤„ç†Agent

**æ–‡ä»¶**: `backend/app/agents/sentence_shadow_writing.py` (é‡æ„)

```python
from app.state import ChunkProcessState
from app.utils import create_llm_function_native

def shadow_writing_single_chunk(state: ChunkProcessState) -> ChunkProcessState:
    """
    å¤„ç†å•ä¸ªè¯­ä¹‰å—çš„Shadow Writing
    
    ã€é‡è¦ã€‘ï¼šç§»é™¤ time.sleep(15) å¼ºåˆ¶ç­‰å¾…
    LangGraphçš„å¹¶å‘æ§åˆ¶ + API Keyè½®æ¢æœºåˆ¶å·²è¶³å¤Ÿ
    """
    chunk_text = state.get("chunk_text", "")
    chunk_id = state.get("chunk_id", 0)
    
    print(f"\n[Pipeline {chunk_id}] Shadow Writing...")
    
    if not chunk_text:
        return {"raw_shadow": None, "error": "Empty chunk"}
    
    try:
        llm_function = create_llm_function_native()
        
        output_format = {
            "original": "å®Œæ•´åŸå¥, str",
            "imitation": "è¯é¢˜è¿ç§»åçš„å®Œæ•´æ–°å¥ï¼ˆâ‰¥12è¯ï¼‰, str",
            "map": "è¯æ±‡æ˜ å°„å­—å…¸, dict"
        }
        
        shadow_prompt = f"""
        [Shadow Writing Prompt - å®Œæ•´å†…å®¹ä¿æŒä¸å˜]
        
        æ®µè½ï¼š
        {chunk_text}
        """
        
        # ç›´æ¥è°ƒç”¨LLMï¼Œä¸å†å¼ºåˆ¶ç­‰å¾…
        result = llm_function(shadow_prompt, output_format)
        
        print(f"[Pipeline {chunk_id}] âœ“ Shadow Writingå®Œæˆ")
        
        return {"raw_shadow": result}
        
    except Exception as e:
        print(f"[Pipeline {chunk_id}] âœ— Shadow Writingå¤±è´¥: {e}")
        return {"raw_shadow": None, "error": str(e)}
```

**æ–‡ä»¶**: `backend/app/agents/validation.py` (æ–°å¢å•Chunkç‰ˆæœ¬)

```python
def validation_single_chunk(state: ChunkProcessState) -> ChunkProcessState:
    """éªŒè¯å•ä¸ªChunkçš„Shadowç»“æœ"""
    chunk_id = state.get("chunk_id", 0)
    raw_shadow = state.get("raw_shadow")
    
    print(f"[Pipeline {chunk_id}] Validation...")
    
    if not raw_shadow:
        return {"validated_shadow": None}
    
    try:
        # ä½¿ç”¨PydanticéªŒè¯
        validated = Ted_Shadows(**raw_shadow)
        print(f"[Pipeline {chunk_id}] âœ“ Validationé€šè¿‡")
        return {"validated_shadow": validated}
    except Exception as e:
        print(f"[Pipeline {chunk_id}] âœ— Validationå¤±è´¥: {e}")
        return {"validated_shadow": None, "error": str(e)}
```

**æ–‡ä»¶**: `backend/app/agents/quality.py` (æ–°å¢å•Chunkç‰ˆæœ¬)

```python
def quality_single_chunk(state: ChunkProcessState) -> ChunkProcessState:
    """è´¨é‡è¯„ä¼°å•ä¸ªChunk"""
    chunk_id = state.get("chunk_id", 0)
    validated = state.get("validated_shadow")
    
    print(f"[Pipeline {chunk_id}] Quality Check...")
    
    if not validated:
        return {"quality_passed": False, "quality_score": 0.0}
    
    # LLMè´¨é‡è¯„ä¼°ï¼ˆ11åˆ†åˆ¶ï¼‰
    score, detail = evaluate_quality_with_llm(validated)
    
    passed = score >= 9.0  # é˜ˆå€¼
    
    status = "âœ“" if passed else "âœ—"
    print(f"[Pipeline {chunk_id}] {status} Quality: {score}/11")
    
    return {
        "quality_passed": passed,
        "quality_score": score,
        "quality_detail": detail
    }
```

**æ–‡ä»¶**: `backend/app/agents/correction.py` (æ–°å¢å•Chunkç‰ˆæœ¬)

```python
def correction_single_chunk(state: ChunkProcessState) -> ChunkProcessState:
    """ä¿®æ­£å•ä¸ªChunk"""
    chunk_id = state.get("chunk_id", 0)
    validated = state.get("validated_shadow")
    quality_detail = state.get("quality_detail", {})
    
    print(f"[Pipeline {chunk_id}] Correction...")
    
    # è°ƒç”¨LLMä¿®æ­£
    corrected = correct_shadow_with_llm(validated, quality_detail)
    
    print(f"[Pipeline {chunk_id}] âœ“ Correctionå®Œæˆ")
    
    return {"corrected_shadow": corrected}
```

**æ–‡ä»¶**: `backend/app/agents/finalize.py` (æ–°å¢å•Chunkç‰ˆæœ¬)

```python
def finalize_single_chunk(state: ChunkProcessState) -> dict:
    """
    æ±‡æ€»å•ä¸ªChunkçš„æœ€ç»ˆç»“æœ
    
    ã€å…³é”®ã€‘ï¼šè¿”å›çš„ç»“æœä¼šè¢«operator.addè‡ªåŠ¨åˆå¹¶åˆ°ä¸»Stateçš„final_shadow_chunks
    """
    chunk_id = state.get("chunk_id", 0)
    
    # ä¼˜å…ˆä½¿ç”¨ä¿®æ­£åçš„ç»“æœ
    final_result = state.get("corrected_shadow") or state.get("validated_shadow")
    
    if final_result:
        print(f"[Pipeline {chunk_id}] âœ“ Finalized")
        # è¿”å›æ ¼å¼ï¼šä¼šè¢«åŠ å…¥åˆ°ä¸»Stateçš„final_shadow_chunksåˆ—è¡¨
        return {"final_shadow_chunks": [final_result]}
    else:
        print(f"[Pipeline {chunk_id}] âœ— No valid result")
        return {"final_shadow_chunks": []}
```

---

### æ­¥éª¤4: å®ç°æ±‡æ€»èŠ‚ç‚¹

**æ–‡ä»¶**: `backend/app/agents/finalize.py` (è¿½åŠ )

```python
def aggregate_results_node(state: Shadow_Writing_State) -> Shadow_Writing_State:
    """
    æ±‡æ€»æ‰€æœ‰Chunkçš„å¤„ç†ç»“æœ
    
    æ­¤æ—¶state["final_shadow_chunks"]å·²ç»è‡ªåŠ¨åŒ…å«äº†æ‰€æœ‰chunkçš„ç»“æœ
    ï¼ˆç”±operator.addè‡ªåŠ¨åˆå¹¶ï¼‰
    """
    final_chunks = state.get("final_shadow_chunks", [])
    
    print(f"\n[AGGREGATE] æ±‡æ€»å®Œæˆ")
    print(f"   æ€»è¯­ä¹‰å—: {len(state.get('semantic_chunks', []))}")
    print(f"   æˆåŠŸå¤„ç†: {len(final_chunks)}")
    print(f"   æˆåŠŸç‡: {len(final_chunks) / len(state.get('semantic_chunks', [1])) * 100:.1f}%")
    
    return {
        "current_node": "aggregate_results",
        "processing_logs": [f"Successfully processed {len(final_chunks)} chunks"]
    }
```

---

### æ­¥éª¤5: ç§»é™¤å¼ºåˆ¶å»¶è¿Ÿ

**æ–‡ä»¶**: `backend/app/agents/sentence_shadow_writing.py`

**åˆ é™¤ä»¥ä¸‹ä»£ç **ï¼š
```python
# ç¬¬38-42è¡Œ - åˆ é™¤è¿™æ®µ
if i > 1:
    delay = 15  # ç­‰å¾…15ç§’è®©é€Ÿç‡é™åˆ¶é‡ç½®
    print(f"   ç­‰å¾… {delay} ç§’ä»¥é¿å…é€Ÿç‡é™åˆ¶...")
    time.sleep(delay)
```

**åŸå› **ï¼š
- æµæ°´çº¿å¹¶è¡Œæ¶æ„ä¸‹ï¼ŒLangGraphè‡ªåŠ¨ç®¡ç†å¹¶å‘
- API Keyè½®æ¢æœºåˆ¶å·²ç»å†…ç½®åœ¨ `utils.py` çš„ `create_llm_function_native()`
- è‡ªåŠ¨å†·å´æœºåˆ¶ä¼šåœ¨Keyè€—å°½æ—¶ç­‰å¾…ï¼Œä¸éœ€è¦æ‰‹åŠ¨sleep

---

### æ­¥éª¤6: æ›´æ–°batch_processor

**æ–‡ä»¶**: `backend/app/batch_processor.py`

```python
from app.workflows import create_parallel_shadow_writing_workflow  # æ–°å¯¼å…¥

async def process_urls_batch(task_id: str, urls: List[str]):
    """æ‰¹é‡å¼‚æ­¥å¤„ç†å¤šä¸ªTED URLs"""
    total = len(urls)
    task_manager.update_status(task_id, "processing")
    
    # ä½¿ç”¨æ–°çš„å¹¶è¡Œå·¥ä½œæµ
    workflow = create_parallel_shadow_writing_workflow()  # æ”¹è¿™é‡Œ
    
    for idx, url in enumerate(urls, 1):
        try:
            # ... æå–transcriptçš„ä»£ç ä¿æŒä¸å˜ ...
            
            # å‡†å¤‡åˆå§‹çŠ¶æ€
            initial_state = {
                "text": transcript_data.transcript,
                "ted_title": transcript_data.title,
                "ted_speaker": transcript_data.speaker,
                "ted_url": url,
                "semantic_chunks": [],
                "final_shadow_chunks": [],  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
                "current_node": "",
                "error_message": None
            }
            
            # è¿è¡Œå¹¶è¡Œå·¥ä½œæµ
            print(f"   å¯åŠ¨å¹¶è¡ŒShadow Writingå·¥ä½œæµ...")
            result = workflow.invoke(initial_state)
            
            # æå–æœ€ç»ˆç»“æœ
            final_chunks = result.get("final_shadow_chunks", [])
            
            # ... åç»­å¤„ç†ä¿æŒä¸å˜ ...
            
        except Exception as e:
            # ... é”™è¯¯å¤„ç†ä¿æŒä¸å˜ ...
```

---

## æ€§èƒ½å¯¹æ¯”ä¸é¢„æœŸ

### ç†è®ºåˆ†æ

**å½“å‰ä¸²è¡Œæ¶æ„**ï¼š
- å¤„ç†61ä¸ªchunk
- æ¯ä¸ªchunkå¼ºåˆ¶ç­‰å¾…15ç§’
- æ€»è€—æ—¶ï¼š61 Ã— 15ç§’ = **915ç§’ï¼ˆçº¦15åˆ†é’Ÿï¼‰**
- API Keyåˆ©ç”¨ç‡ï¼š1%

**æµæ°´çº¿å¹¶è¡Œæ¶æ„**ï¼š
- å‡è®¾å¹¶å‘åº¦10ï¼ˆLangGraphè‡ªåŠ¨ç®¡ç†ï¼‰
- æ¯ä¸ªchunkå®é™…å¤„ç†æ—¶é—´ï¼šçº¦3-5ç§’
- æµæ°´çº¿é‡å ï¼šç¬¬1ä¸ªchunkå®Œæˆvalidationæ—¶ï¼Œç¬¬10ä¸ªchunkæ‰å¼€å§‹shadow_writing
- æ€»è€—æ—¶ï¼šçº¦61 Ã· 10 Ã— 5ç§’ = **30-40ç§’**ï¼ˆæé™æƒ…å†µï¼‰
- è€ƒè™‘é€Ÿç‡é™åˆ¶å’Œé‡è¯•ï¼š**1.5-2åˆ†é’Ÿ**
- API Keyåˆ©ç”¨ç‡ï¼š30-50%

### å®æµ‹åŸºå‡†

æ ¹æ®è¿è¡Œè®°å½•åˆ†æï¼š
- å•ä¸ªShadow Writingè°ƒç”¨ï¼šçº¦1-2ç§’
- å•ä¸ªQualityè¯„ä¼°è°ƒç”¨ï¼šçº¦1-2ç§’
- å½“å‰æ‰€æœ‰Keyå†·å´ç­‰å¾…ï¼šæœ€å¤š30-60ç§’

**é¢„æœŸæ€§èƒ½æå‡**ï¼š
- æ—¶é—´èŠ‚çœï¼š**85-90%**
- ä»15åˆ†é’Ÿé™è‡³1.5-2åˆ†é’Ÿ

---

## æµ‹è¯•éªŒè¯

### å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `backend/tests/test_parallel_workflow.py` (æ–°å»º)

```python
import pytest
from app.workflows import create_parallel_shadow_writing_workflow
from app.state import Shadow_Writing_State

def test_parallel_workflow_basic():
    """æµ‹è¯•åŸºç¡€å¹¶è¡Œå·¥ä½œæµ"""
    workflow = create_parallel_shadow_writing_workflow()
    
    initial_state = {
        "text": "æµ‹è¯•æ–‡æœ¬" * 100,  # æ¨¡æ‹Ÿé•¿æ–‡æœ¬
        "semantic_chunks": [],
        "final_shadow_chunks": [],
        "current_node": ""
    }
    
    result = workflow.invoke(initial_state)
    
    assert "final_shadow_chunks" in result
    assert len(result["final_shadow_chunks"]) > 0

def test_chunk_pipeline():
    """æµ‹è¯•å•Chunkæµæ°´çº¿"""
    from app.workflows import create_chunk_pipeline
    
    pipeline = create_chunk_pipeline()
    
    chunk_state = {
        "chunk_text": "This is a test sentence for shadow writing.",
        "chunk_id": 1
    }
    
    result = pipeline.invoke(chunk_state)
    
    assert "final_result" in result
```

### æ€§èƒ½æµ‹è¯•

```python
import time

def test_performance_comparison():
    """å¯¹æ¯”ä¸²è¡Œvså¹¶è¡Œæ€§èƒ½"""
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆ10ä¸ªchunkï¼‰
    test_chunks = ["Test chunk " + str(i) for i in range(10)]
    
    # æµ‹è¯•å¹¶è¡Œå·¥ä½œæµ
    start = time.time()
    # ... è¿è¡Œå¹¶è¡Œå·¥ä½œæµ ...
    parallel_time = time.time() - start
    
    print(f"å¹¶è¡Œå¤„ç†10ä¸ªchunkè€—æ—¶: {parallel_time:.2f}ç§’")
    
    # é¢„æœŸï¼šåº”è¯¥åœ¨10-20ç§’å†…å®Œæˆ
    assert parallel_time < 30
```

---

## æ³¨æ„äº‹é¡¹

### 1. å¹¶å‘æ§åˆ¶

LangGraphé»˜è®¤å¹¶å‘åº¦ï¼š
- è‡ªåŠ¨æ ¹æ®ç³»ç»Ÿèµ„æºè°ƒæ•´
- å¯ä»¥é€šè¿‡é…ç½®é™åˆ¶æœ€å¤§å¹¶å‘æ•°

å¦‚éœ€é™åˆ¶å¹¶å‘ï¼š
```python
# åœ¨workflows.pyä¸­
app = builder.compile(
    checkpointer=...,  # å¯é€‰
    interrupt_before=[],
    interrupt_after=[],
    debug=False
)

# è¿è¡Œæ—¶æ§åˆ¶
result = app.invoke(
    initial_state,
    config={"recursion_limit": 100, "max_concurrency": 10}  # æœ€å¤š10ä¸ªå¹¶å‘
)
```

### 2. APIé€Ÿç‡é™åˆ¶å¤„ç†

å³ä½¿ä½¿ç”¨å¹¶è¡Œï¼Œä»éœ€å¤„ç†é€Ÿç‡é™åˆ¶ï¼š
- `utils.py` ä¸­çš„API Keyè½®æ¢æœºåˆ¶ä¿æŒä¸å˜
- å†·å´ç­‰å¾…æœºåˆ¶è‡ªåŠ¨ç”Ÿæ•ˆ
- å»ºè®®é…ç½®è¶³å¤Ÿçš„API Keysï¼ˆå½“å‰13ä¸ªå·²è¶³å¤Ÿï¼‰

### 3. é”™è¯¯å¤„ç†

æ¯ä¸ªChunkç‹¬ç«‹å¤„ç†ï¼Œé”™è¯¯ä¸ä¼šå½±å“å…¶ä»–Chunkï¼š
- å•ä¸ªChunkå¤±è´¥ä¼šè¿”å›ç©ºç»“æœ
- åœ¨ `aggregate_results_node` ä¸­ç»Ÿè®¡æˆåŠŸç‡
- å¯ä»¥åœ¨æœ€ç»ˆç»“æœä¸­æ ‡è®°å¤±è´¥çš„Chunk

### 4. å†…å­˜ç®¡ç†

å¹¶è¡Œå¤„ç†ä¼šå¢åŠ å†…å­˜ä½¿ç”¨ï¼š
- 61ä¸ªchunkåŒæ—¶åœ¨å†…å­˜ä¸­
- æ¯ä¸ªchunkçš„ä¸­é—´ç»“æœéƒ½ä¿ç•™
- å¯¹äºè¶…å¤§æ–‡æœ¬ï¼ˆ>100KBï¼‰ï¼Œè€ƒè™‘åˆ†æ‰¹å¤„ç†

### 5. æ—¥å¿—å’Œç›‘æ§

å¹¶è¡Œæ‰§è¡Œæ—¶æ—¥å¿—ä¼šäº¤é”™ï¼š
```
[Pipeline 1] Shadow Writing...
[Pipeline 3] Shadow Writing...
[Pipeline 2] Validation...
[Pipeline 1] âœ“ Shadow Writingå®Œæˆ
```

å»ºè®®ï¼š
- æ¯æ¡æ—¥å¿—åŠ ä¸Š `[Pipeline {chunk_id}]` å‰ç¼€
- ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—å·¥å…·ï¼ˆå¦‚loguruï¼‰
- WebSocketå®æ—¶æ¨é€æ¯ä¸ªChunkçš„è¿›åº¦

---

## å®æ–½é¡ºåº

### æ¨èæ­¥éª¤ï¼š

1. **æ­¥éª¤1-2**: ä¿®æ”¹State + åˆ›å»ºå­å›¾æ¶æ„ï¼ˆ1å°æ—¶ï¼‰
2. **æ­¥éª¤3**: é‡æ„Agentä¸ºå•Chunkç‰ˆæœ¬ï¼ˆ2å°æ—¶ï¼‰
3. **æ­¥éª¤4**: å®ç°æ±‡æ€»èŠ‚ç‚¹ï¼ˆ30åˆ†é’Ÿï¼‰
4. **æ­¥éª¤5**: ç§»é™¤å¼ºåˆ¶å»¶è¿Ÿï¼ˆ5åˆ†é’Ÿï¼‰
5. **æ­¥éª¤6**: æ›´æ–°batch_processorï¼ˆ30åˆ†é’Ÿï¼‰
6. **æµ‹è¯•**: å•å…ƒæµ‹è¯• + æ€§èƒ½æµ‹è¯•ï¼ˆ1å°æ—¶ï¼‰
7. **éªŒè¯**: å®Œæ•´ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆ30åˆ†é’Ÿï¼‰

**æ€»å·¥ä½œé‡**: çº¦5-6å°æ—¶

### æ¸è¿›å¼å®æ–½ï¼š

- å…ˆåœ¨æœ¬åœ°æµ‹è¯•å°è§„æ¨¡æ•°æ®ï¼ˆ5ä¸ªchunkï¼‰
- éªŒè¯å¹¶è¡Œæœºåˆ¶æ­£å¸¸å·¥ä½œ
- é€æ­¥å¢åŠ åˆ°å®Œæ•´è§„æ¨¡ï¼ˆ61ä¸ªchunkï¼‰
- ç›‘æ§APIä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½æŒ‡æ ‡

---

## å®Œæˆæ ‡å‡†

âœ… **åŠŸèƒ½å®Œæ•´æ€§**
- æ‰€æœ‰Chunkèƒ½å¹¶è¡Œå¤„ç†
- æ¯ä¸ªChunkç‹¬ç«‹ç»è¿‡å®Œæ•´æµæ°´çº¿
- operator.addæ­£ç¡®æ±‡æ€»ç»“æœ
- é”™è¯¯å¤„ç†ä¸å½±å“å…¶ä»–Chunk

âœ… **æ€§èƒ½æå‡**
- å¤„ç†æ—¶é—´ä»15åˆ†é’Ÿé™è‡³2åˆ†é’Ÿå†…
- API Keyåˆ©ç”¨ç‡æå‡è‡³30%ä»¥ä¸Š
- æ— é€Ÿç‡é™åˆ¶é”™è¯¯ï¼ˆæˆ–è‡ªåŠ¨æ¢å¤ï¼‰

âœ… **ä»£ç è´¨é‡**
- ç§»é™¤æ‰€æœ‰time.sleepå¼ºåˆ¶ç­‰å¾…
- æ—¥å¿—æ¸…æ™°ï¼Œå¯è¿½è¸ªæ¯ä¸ªChunk
- å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒé€»è¾‘
- æ€§èƒ½æµ‹è¯•éªŒè¯æå‡æ•ˆæœ

âœ… **å‘åå…¼å®¹**
- ä¿ç•™åŸæœ‰ä¸²è¡Œå·¥ä½œæµï¼ˆå¯é€‰ï¼‰
- æ–°å¹¶è¡Œå·¥ä½œæµå¯å¹³æ»‘åˆ‡æ¢
- APIæ¥å£ä¸å˜ï¼Œå‰ç«¯æ— æ„ŸçŸ¥

---

**æµæ°´çº¿å¹¶è¡Œæ¶æ„å®æ–½è®¡åˆ’å®Œæˆï¼é¢„æœŸæ€§èƒ½æå‡ï¼š85-90%** ğŸš€

---
---

# API Key ç›‘æ§ç³»ç»Ÿå®æ–½è®¡åˆ’

## èƒŒæ™¯

å½“å‰ç³»ç»Ÿä½¿ç”¨ **14ä¸ªç‹¬ç«‹è´¦å·çš„Groq API Key** è¿›è¡Œå¹¶è¡Œå¤„ç†ï¼Œéœ€è¦ç›‘æ§æ¯ä¸ªKeyçš„ä½¿ç”¨æƒ…å†µã€æˆåŠŸç‡ã€é€Ÿç‡é™åˆ¶ç­‰æŒ‡æ ‡ï¼Œä»¥ä¾¿ï¼š
- ğŸ¯ ä¼˜åŒ–Keyè½®æ¢ç­–ç•¥
- ğŸ“Š äº†è§£æ¯ä¸ªKeyçš„å®é™…ä½¿ç”¨æƒ…å†µ
- âš ï¸ åŠæ—¶å‘ç°é—®é¢˜Key
- ğŸ“ˆ åˆ†æç³»ç»Ÿæ€§èƒ½ç“¶é¢ˆ

---

## ç›‘æ§åŠŸèƒ½æ¸…å•

### æ ¸å¿ƒåŠŸèƒ½

1. **å®æ—¶ç»Ÿè®¡**
   - âœ… æ¯ä¸ªKeyçš„è°ƒç”¨æ¬¡æ•°
   - âœ… æˆåŠŸç‡ vs å¤±è´¥ç‡
   - âœ… 429é€Ÿç‡é™åˆ¶è§¦å‘æ¬¡æ•°
   - âœ… å¹³å‡å“åº”æ—¶é—´
   - âœ… å½“å‰å†·å´çŠ¶æ€

2. **é…é¢ç›‘æ§**ï¼ˆåŸºäºå“åº”å¤´ï¼‰
   - âœ… å‰©ä½™RPMï¼ˆRequests Per Minuteï¼‰
   - âœ… å‰©ä½™TPMï¼ˆTokens Per Minuteï¼‰
   - âœ… é‡ç½®æ—¶é—´
   - âœ… é™åˆ¶ç±»å‹ï¼ˆè¯·æ±‚é™åˆ¶/Tokené™åˆ¶ï¼‰

3. **æŠ¥å‘Šç”Ÿæˆ**
   - âœ… å®æ—¶ä»ªè¡¨æ¿
   - âœ… å¯¼å‡ºJSON/CSVæŠ¥å‘Š
   - âœ… å†å²è¶‹åŠ¿åˆ†æ
   - âœ… Keyä½¿ç”¨æ’è¡Œ

4. **å‘Šè­¦åŠŸèƒ½**
   - âš ï¸ Keyå¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼
   - âš ï¸ æŒç»­è§¦å‘é€Ÿç‡é™åˆ¶
   - âš ï¸ å“åº”æ—¶é—´å¼‚å¸¸
   - âš ï¸ Keyå¯èƒ½å·²å¤±æ•ˆ

---

## æ–‡ä»¶ç»“æ„

```
backend/app/
â”œâ”€â”€ monitoring/                      # â­ï¸ æ–°å¢ç›‘æ§æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api_key_monitor.py          # æ ¸å¿ƒç›‘æ§ç±»
â”‚   â”œâ”€â”€ api_key_stats.py            # ç»Ÿè®¡æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ api_key_reporter.py         # æŠ¥å‘Šç”Ÿæˆå™¨
â”‚   â””â”€â”€ api_key_dashboard.py        # ä»ªè¡¨æ¿API
â”œâ”€â”€ agents/
â”œâ”€â”€ utils.py                         # ç°æœ‰Keyç®¡ç†å™¨
â”œâ”€â”€ main.py                          # æ·»åŠ ç›‘æ§è·¯ç”±
â””â”€â”€ ...
```

---

## å®æ–½æ­¥éª¤

### æ­¥éª¤1: åˆ›å»ºç»Ÿè®¡æ•°æ®æ¨¡å‹

**æ–‡ä»¶**: `backend/app/monitoring/api_key_stats.py`

```python
from datetime import datetime
from typing import Dict, List, Optional
from pydantic import BaseModel


class APIKeyStats(BaseModel):
    """å•ä¸ªAPI Keyçš„ç»Ÿè®¡æ•°æ®"""
    key_id: str                          # Keyæ ‡è¯†ï¼ˆå¦‚ï¼šKEY_1ï¼‰
    key_suffix: str                      # Keyå4ä½ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    # è°ƒç”¨ç»Ÿè®¡
    total_calls: int = 0                 # æ€»è°ƒç”¨æ¬¡æ•°
    successful_calls: int = 0            # æˆåŠŸæ¬¡æ•°
    failed_calls: int = 0                # å¤±è´¥æ¬¡æ•°
    rate_limit_hits: int = 0             # 429é”™è¯¯æ¬¡æ•°
    
    # æ—¶é—´ç»Ÿè®¡
    total_response_time: float = 0.0     # æ€»å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    avg_response_time: float = 0.0       # å¹³å‡å“åº”æ—¶é—´
    last_used_at: Optional[datetime] = None  # æœ€åä½¿ç”¨æ—¶é—´
    
    # é…é¢ä¿¡æ¯ï¼ˆä»å“åº”å¤´è·å–ï¼‰
    current_rpm_limit: Optional[int] = None      # RPMé™åˆ¶
    current_rpm_remaining: Optional[int] = None  # å‰©ä½™RPM
    current_tpm_limit: Optional[int] = None      # TPMé™åˆ¶
    current_tpm_remaining: Optional[int] = None  # å‰©ä½™TPM
    reset_time: Optional[int] = None             # é‡ç½®æ—¶é—´ï¼ˆç§’ï¼‰
    
    # å†·å´çŠ¶æ€
    is_cooling: bool = False             # æ˜¯å¦åœ¨å†·å´ä¸­
    cooling_until: Optional[datetime] = None  # å†·å´ç»“æŸæ—¶é—´
    
    # è®¡ç®—å±æ€§
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        if self.total_calls == 0:
            return 0.0
        return (self.successful_calls / self.total_calls) * 100
    
    @property
    def failure_rate(self) -> float:
        """å¤±è´¥ç‡"""
        return 100 - self.success_rate


class MonitoringSummary(BaseModel):
    """ç›‘æ§æ€»è§ˆ"""
    total_keys: int                      # æ€»Keyæ•°é‡
    active_keys: int                     # æ´»è·ƒKeyæ•°é‡
    cooling_keys: int                    # å†·å´ä¸­Keyæ•°é‡
    total_calls: int                     # æ€»è°ƒç”¨æ¬¡æ•°
    total_successes: int                 # æ€»æˆåŠŸæ¬¡æ•°
    total_failures: int                  # æ€»å¤±è´¥æ¬¡æ•°
    total_rate_limits: int               # æ€»é€Ÿç‡é™åˆ¶æ¬¡æ•°
    avg_success_rate: float              # å¹³å‡æˆåŠŸç‡
    monitoring_start_time: datetime      # ç›‘æ§å¼€å§‹æ—¶é—´
    uptime_seconds: float                # è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
```

---

### æ­¥éª¤2: å®ç°æ ¸å¿ƒç›‘æ§ç±»

**æ–‡ä»¶**: `backend/app/monitoring/api_key_monitor.py`

```python
import time
from datetime import datetime, timedelta
from typing import Dict, Optional
from collections import defaultdict
from app.monitoring.api_key_stats import APIKeyStats, MonitoringSummary


class APIKeyMonitor:
    """API Keyä½¿ç”¨ç›‘æ§å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        self.stats: Dict[str, APIKeyStats] = {}  # key_id -> stats
        self.start_time = datetime.now()
        self._initialized = True
        print("[MONITOR] API Keyç›‘æ§å™¨å·²å¯åŠ¨")
    
    def register_key(self, key_id: str, key_value: str):
        """æ³¨å†Œä¸€ä¸ªAPI Key"""
        if key_id not in self.stats:
            key_suffix = key_value[-4:] if len(key_value) >= 4 else "****"
            self.stats[key_id] = APIKeyStats(
                key_id=key_id,
                key_suffix=key_suffix
            )
    
    def record_call(self, 
                   key_id: str, 
                   success: bool, 
                   response_time: float,
                   rate_limited: bool = False,
                   response_headers: Optional[Dict] = None):
        """
        è®°å½•ä¸€æ¬¡APIè°ƒç”¨
        
        Args:
            key_id: Keyæ ‡è¯†
            success: æ˜¯å¦æˆåŠŸ
            response_time: å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
            rate_limited: æ˜¯å¦è§¦å‘é€Ÿç‡é™åˆ¶
            response_headers: å“åº”å¤´ï¼ˆç”¨äºæå–é…é¢ä¿¡æ¯ï¼‰
        """
        if key_id not in self.stats:
            return
        
        stat = self.stats[key_id]
        
        # æ›´æ–°è°ƒç”¨ç»Ÿè®¡
        stat.total_calls += 1
        if success:
            stat.successful_calls += 1
        else:
            stat.failed_calls += 1
        
        if rate_limited:
            stat.rate_limit_hits += 1
        
        # æ›´æ–°å“åº”æ—¶é—´
        stat.total_response_time += response_time
        stat.avg_response_time = stat.total_response_time / stat.total_calls
        stat.last_used_at = datetime.now()
        
        # è§£æå“åº”å¤´é…é¢ä¿¡æ¯
        if response_headers:
            stat.current_rpm_limit = response_headers.get('x-ratelimit-limit-requests')
            stat.current_rpm_remaining = response_headers.get('x-ratelimit-remaining-requests')
            stat.current_tpm_limit = response_headers.get('x-ratelimit-limit-tokens')
            stat.current_tpm_remaining = response_headers.get('x-ratelimit-remaining-tokens')
            stat.reset_time = response_headers.get('x-ratelimit-reset-requests')
    
    def mark_cooling(self, key_id: str, cooling_seconds: int = 60):
        """æ ‡è®°Keyè¿›å…¥å†·å´çŠ¶æ€"""
        if key_id in self.stats:
            self.stats[key_id].is_cooling = True
            self.stats[key_id].cooling_until = datetime.now() + timedelta(seconds=cooling_seconds)
    
    def update_cooling_status(self):
        """æ›´æ–°æ‰€æœ‰Keyçš„å†·å´çŠ¶æ€"""
        now = datetime.now()
        for stat in self.stats.values():
            if stat.is_cooling and stat.cooling_until:
                if now >= stat.cooling_until:
                    stat.is_cooling = False
                    stat.cooling_until = None
    
    def get_key_stats(self, key_id: str) -> Optional[APIKeyStats]:
        """è·å–å•ä¸ªKeyçš„ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.get(key_id)
    
    def get_all_stats(self) -> Dict[str, APIKeyStats]:
        """è·å–æ‰€æœ‰Keyçš„ç»Ÿè®¡ä¿¡æ¯"""
        self.update_cooling_status()
        return self.stats
    
    def get_summary(self) -> MonitoringSummary:
        """è·å–ç›‘æ§æ€»è§ˆ"""
        self.update_cooling_status()
        
        total_calls = sum(s.total_calls for s in self.stats.values())
        total_successes = sum(s.successful_calls for s in self.stats.values())
        total_failures = sum(s.failed_calls for s in self.stats.values())
        total_rate_limits = sum(s.rate_limit_hits for s in self.stats.values())
        
        active_keys = sum(1 for s in self.stats.values() if s.last_used_at)
        cooling_keys = sum(1 for s in self.stats.values() if s.is_cooling)
        
        avg_success_rate = (total_successes / total_calls * 100) if total_calls > 0 else 0.0
        uptime = (datetime.now() - self.start_time).total_seconds()
        
        return MonitoringSummary(
            total_keys=len(self.stats),
            active_keys=active_keys,
            cooling_keys=cooling_keys,
            total_calls=total_calls,
            total_successes=total_successes,
            total_failures=total_failures,
            total_rate_limits=total_rate_limits,
            avg_success_rate=avg_success_rate,
            monitoring_start_time=self.start_time,
            uptime_seconds=uptime
        )
    
    def reset_stats(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡æ•°æ®"""
        self.stats.clear()
        self.start_time = datetime.now()
        print("[MONITOR] ç»Ÿè®¡æ•°æ®å·²é‡ç½®")


# å…¨å±€å•ä¾‹
api_key_monitor = APIKeyMonitor()
```

---

### æ­¥éª¤3: é›†æˆåˆ°ç°æœ‰çš„Keyç®¡ç†å™¨

**æ–‡ä»¶**: `backend/app/utils.py` (ä¿®æ”¹)

åœ¨ `APIKeyManager` ç±»ä¸­æ·»åŠ ç›‘æ§è°ƒç”¨ï¼š

```python
from app.monitoring.api_key_monitor import api_key_monitor

class APIKeyManager:
    # ... ç°æœ‰ä»£ç  ...
    
    def __init__(self, api_keys: List[str], cooldown_seconds: int = 60):
        # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
        
        # æ³¨å†Œæ‰€æœ‰Keyåˆ°ç›‘æ§å™¨
        for i, key in enumerate(self.api_keys):
            key_id = f"KEY_{i+1}"
            api_key_monitor.register_key(key_id, key)
    
    def call_with_retry(self, func, *args, **kwargs):
        # ... ç°æœ‰ä»£ç  ...
        
        start_time = time.time()
        current_key = self.api_keys[self.current_key_index]
        key_id = f"KEY_{self.current_key_index + 1}"
        
        try:
            result = func(*args, **kwargs)
            
            # è®°å½•æˆåŠŸè°ƒç”¨
            response_time = time.time() - start_time
            api_key_monitor.record_call(
                key_id=key_id,
                success=True,
                response_time=response_time,
                response_headers=getattr(result, 'headers', None)  # å¦‚æœæœ‰å“åº”å¤´
            )
            
            return result
            
        except RateLimitError as e:
            # è®°å½•é€Ÿç‡é™åˆ¶
            response_time = time.time() - start_time
            api_key_monitor.record_call(
                key_id=key_id,
                success=False,
                response_time=response_time,
                rate_limited=True
            )
            api_key_monitor.mark_cooling(key_id, self.cooldown_seconds)
            
            # ... ç°æœ‰çš„åˆ‡æ¢Keyé€»è¾‘ ...
            
        except Exception as e:
            # è®°å½•å¤±è´¥
            response_time = time.time() - start_time
            api_key_monitor.record_call(
                key_id=key_id,
                success=False,
                response_time=response_time
            )
            raise
```

---

### æ­¥éª¤4: åˆ›å»ºä»ªè¡¨æ¿API

**æ–‡ä»¶**: `backend/app/monitoring/api_key_dashboard.py`

```python
from fastapi import APIRouter
from app.monitoring.api_key_monitor import api_key_monitor
from app.monitoring.api_key_stats import APIKeyStats, MonitoringSummary
from typing import Dict, List

router = APIRouter(prefix="/monitoring", tags=["monitoring"])


@router.get("/summary", response_model=MonitoringSummary)
async def get_monitoring_summary():
    """è·å–ç›‘æ§æ€»è§ˆ"""
    return api_key_monitor.get_summary()


@router.get("/keys", response_model=Dict[str, APIKeyStats])
async def get_all_key_stats():
    """è·å–æ‰€æœ‰Keyçš„è¯¦ç»†ç»Ÿè®¡"""
    return api_key_monitor.get_all_stats()


@router.get("/keys/{key_id}", response_model=APIKeyStats)
async def get_key_stats(key_id: str):
    """è·å–å•ä¸ªKeyçš„ç»Ÿè®¡ä¿¡æ¯"""
    stat = api_key_monitor.get_key_stats(key_id)
    if not stat:
        raise HTTPException(status_code=404, detail=f"Key {key_id} not found")
    return stat


@router.get("/keys/top/success", response_model=List[APIKeyStats])
async def get_top_keys_by_success(limit: int = 5):
    """è·å–æˆåŠŸç‡æœ€é«˜çš„Keys"""
    stats = list(api_key_monitor.get_all_stats().values())
    sorted_stats = sorted(stats, key=lambda s: s.success_rate, reverse=True)
    return sorted_stats[:limit]


@router.get("/keys/top/usage", response_model=List[APIKeyStats])
async def get_top_keys_by_usage(limit: int = 5):
    """è·å–ä½¿ç”¨æ¬¡æ•°æœ€å¤šçš„Keys"""
    stats = list(api_key_monitor.get_all_stats().values())
    sorted_stats = sorted(stats, key=lambda s: s.total_calls, reverse=True)
    return sorted_stats[:limit]


@router.post("/reset")
async def reset_monitoring():
    """é‡ç½®ç›‘æ§ç»Ÿè®¡"""
    api_key_monitor.reset_stats()
    return {"message": "Monitoring stats reset successfully"}
```

---

### æ­¥éª¤5: æ³¨å†Œè·¯ç”±

**æ–‡ä»¶**: `backend/app/main.py` (ä¿®æ”¹)

```python
from app.monitoring.api_key_dashboard import router as monitoring_router

# ... ç°æœ‰ä»£ç  ...

# æ³¨å†Œç›‘æ§è·¯ç”±
app.include_router(monitoring_router)
```

---

## è®¿é—®æ–¹å¼

å¯åŠ¨ç³»ç»Ÿåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ¥å£è®¿é—®ç›‘æ§æ•°æ®ï¼š

```bash
# 1. ç›‘æ§æ€»è§ˆ
GET http://localhost:8000/monitoring/summary

# 2. æ‰€æœ‰Keyç»Ÿè®¡
GET http://localhost:8000/monitoring/keys

# 3. å•ä¸ªKeyç»Ÿè®¡
GET http://localhost:8000/monitoring/keys/KEY_1

# 4. æˆåŠŸç‡TOP5
GET http://localhost:8000/monitoring/keys/top/success?limit=5

# 5. ä½¿ç”¨æ¬¡æ•°TOP5
GET http://localhost:8000/monitoring/keys/top/usage?limit=5

# 6. é‡ç½®ç»Ÿè®¡
POST http://localhost:8000/monitoring/reset
```

---

## å®æ–½é¡ºåº

### æ¨èæ­¥éª¤ï¼š

1. **æ­¥éª¤1**: åˆ›å»ºç»Ÿè®¡æ•°æ®æ¨¡å‹ï¼ˆ30åˆ†é’Ÿï¼‰
2. **æ­¥éª¤2**: å®ç°æ ¸å¿ƒç›‘æ§ç±»ï¼ˆ1å°æ—¶ï¼‰
3. **æ­¥éª¤3**: é›†æˆåˆ°Keyç®¡ç†å™¨ï¼ˆ1å°æ—¶ï¼‰
4. **æ­¥éª¤4**: åˆ›å»ºä»ªè¡¨æ¿APIï¼ˆ1å°æ—¶ï¼‰
5. **æ­¥éª¤5**: æ³¨å†Œè·¯ç”±å¹¶æµ‹è¯•ï¼ˆ30åˆ†é’Ÿï¼‰
6. **å¯é€‰**: åˆ›å»ºå‰ç«¯ä»ªè¡¨æ¿é¡µé¢ï¼ˆ2-3å°æ—¶ï¼‰

**æ€»å·¥ä½œé‡**: çº¦4-7å°æ—¶ï¼ˆä¸å«å‰ç«¯ï¼‰

---

## å®Œæˆæ ‡å‡†

âœ… **åŠŸèƒ½å®Œæ•´æ€§**
- èƒ½è¿½è¸ªæ¯ä¸ªKeyçš„è°ƒç”¨ç»Ÿè®¡
- èƒ½ä»å“åº”å¤´æå–é…é¢ä¿¡æ¯
- èƒ½æ˜¾ç¤ºå†·å´çŠ¶æ€å’Œå‰©ä½™æ—¶é—´
- æä¾›RESTful APIè®¿é—®

âœ… **æ•°æ®å‡†ç¡®æ€§**
- æˆåŠŸç‡/å¤±è´¥ç‡è®¡ç®—æ­£ç¡®
- å“åº”æ—¶é—´ç»Ÿè®¡å‡†ç¡®
- é…é¢ä¿¡æ¯å®æ—¶æ›´æ–°
- å†·å´çŠ¶æ€æ­£ç¡®ç»´æŠ¤

âœ… **æ€§èƒ½å½±å“**
- ç›‘æ§å¼€é”€ < 1%
- ä¸å½±å“ä¸»æµç¨‹æ€§èƒ½
- å¼‚æ­¥è®°å½•ï¼Œä¸é˜»å¡è°ƒç”¨

âœ… **å¯ç”¨æ€§**
- APIæ–‡æ¡£å®Œæ•´
- è¿”å›æ•°æ®æ ¼å¼æ¸…æ™°
- æ”¯æŒé‡ç½®ç»Ÿè®¡
- æ”¯æŒå¯¼å‡ºæŠ¥å‘Š

---

**API Keyç›‘æ§ç³»ç»Ÿå®æ–½è®¡åˆ’å®Œæˆï¼é¢„æœŸæä¾›å®Œæ•´çš„Keyä½¿ç”¨å¯è§æ€§** ğŸ“Š

---
---

# API Key å¤±æ•ˆæ£€æµ‹ç³»ç»Ÿ

## èƒŒæ™¯

ç”¨æˆ·å†å²ä¸Šæœ‰å¤šä¸ªGroqè´¦å·è¢«å°ç¦ï¼Œéœ€è¦åŠæ—¶æ£€æµ‹Keyæ˜¯å¦å¤±æ•ˆï¼Œé¿å…ï¼š
- âŒ å¤±æ•ˆKeyå ç”¨è½®æ¢æ§½ä½
- âŒ æµªè´¹é‡è¯•æ¬¡æ•°
- âŒ å½±å“ç³»ç»Ÿæ€§èƒ½
- âš ï¸ æ— æ³•åŠæ—¶å‘ç°é—®é¢˜

---

## æ£€æµ‹ç­–ç•¥

### 1. è¢«åŠ¨æ£€æµ‹ï¼ˆåŸºäºè°ƒç”¨ç»“æœï¼‰

**è§¦å‘æ¡ä»¶**ï¼š
- âœ… è¿”å› `401 Unauthorized` é”™è¯¯
- âœ… è¿”å› `403 Forbidden` é”™è¯¯
- âœ… è¿ç»­å¤±è´¥æ¬¡æ•° â‰¥ 10æ¬¡
- âœ… å¤±è´¥ç‡æŒç»­ > 80%ï¼ˆ50æ¬¡è°ƒç”¨å†…ï¼‰
- âœ… ç‰¹å®šé”™è¯¯æ¶ˆæ¯ï¼ˆ"invalid api key", "account suspended"ç­‰ï¼‰

**ä¼˜ç‚¹**ï¼š
- æ— é¢å¤–å¼€é”€
- å®æ—¶æ£€æµ‹
- å‡†ç¡®ç‡é«˜

**ç¼ºç‚¹**ï¼š
- éœ€è¦ç­‰å¾…å¤±è´¥æ‰èƒ½æ£€æµ‹
- å¯èƒ½å½±å“æ­£åœ¨å¤„ç†çš„ä»»åŠ¡

---

### 2. ä¸»åŠ¨æ£€æµ‹ï¼ˆå®šæœŸå¥åº·æ£€æŸ¥ï¼‰

**æ£€æŸ¥æ–¹å¼**ï¼š
```python
# è½»é‡çº§æµ‹è¯•è¯·æ±‚
def health_check_key(api_key: str) -> bool:
    """
    ä½¿ç”¨æœ€ç®€å•çš„è¯·æ±‚æµ‹è¯•Keyæ˜¯å¦æœ‰æ•ˆ
    - æ¨¡å‹ï¼šæœ€å°çš„æ¨¡å‹ï¼ˆllama3-8bï¼‰
    - Tokenï¼šæœ€å°‘ï¼ˆmax_tokens=1ï¼‰
    - Promptï¼šæœ€çŸ­ï¼ˆ"test"ï¼‰
    """
    try:
        response = client.chat.completions.create(
            model="llama3-8b-8192",
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=1,
            temperature=0
        )
        return True  # Keyæœ‰æ•ˆ
    except AuthenticationError:
        return False  # Keyå¤±æ•ˆ
    except Exception as e:
        return None  # æš‚æ—¶æ— æ³•åˆ¤æ–­ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰
```

**æ£€æŸ¥æ—¶æœº**ï¼š
- âœ… ç³»ç»Ÿå¯åŠ¨æ—¶ï¼šéªŒè¯æ‰€æœ‰14ä¸ªKey
- âœ… å®šæœŸæ£€æŸ¥ï¼šæ¯30åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
- âœ… å¤±è´¥åå¤æŸ¥ï¼šè¿ç»­å¤±è´¥5æ¬¡åç«‹å³éªŒè¯
- âœ… æ‰‹åŠ¨è§¦å‘ï¼šé€šè¿‡APIæ¥å£ä¸»åŠ¨æ£€æŸ¥

**ä¼˜ç‚¹**ï¼š
- ä¸»åŠ¨å‘ç°é—®é¢˜
- ä¸ä¾èµ–å®é™…è°ƒç”¨
- å¯ä»¥æå‰é¢„è­¦

**ç¼ºç‚¹**ï¼š
- æ¶ˆè€—å°‘é‡é¢å¤–è¯·æ±‚
- éœ€è¦å®šæ—¶ä»»åŠ¡

---

## æ•°æ®æ¨¡å‹æ‰©å±•

### åœ¨ `APIKeyStats` ä¸­æ·»åŠ å­—æ®µ

**æ–‡ä»¶**: `backend/app/monitoring/api_key_stats.py` (æ‰©å±•)

```python
class APIKeyStats(BaseModel):
    # ... ç°æœ‰å­—æ®µ ...
    
    # å¥åº·çŠ¶æ€
    is_valid: bool = True                        # Keyæ˜¯å¦æœ‰æ•ˆ
    is_suspended: bool = False                   # æ˜¯å¦è¢«å°ç¦
    last_health_check: Optional[datetime] = None # æœ€åå¥åº·æ£€æŸ¥æ—¶é—´
    health_check_failures: int = 0               # å¥åº·æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°
    
    # å¤±æ•ˆæ£€æµ‹
    consecutive_failures: int = 0                # è¿ç»­å¤±è´¥æ¬¡æ•°
    failure_rate_window: List[bool] = []         # æœ€è¿‘50æ¬¡è°ƒç”¨çš„æˆåŠŸ/å¤±è´¥è®°å½•
    invalidation_reason: Optional[str] = None    # å¤±æ•ˆåŸå› 
    invalidated_at: Optional[datetime] = None    # å¤±æ•ˆæ—¶é—´
    
    # è®¡ç®—å±æ€§
    @property
    def recent_failure_rate(self) -> float:
        """æœ€è¿‘50æ¬¡è°ƒç”¨çš„å¤±è´¥ç‡"""
        if not self.failure_rate_window:
            return 0.0
        failures = sum(1 for success in self.failure_rate_window if not success)
        return (failures / len(self.failure_rate_window)) * 100
```

---

## æ ¸å¿ƒæ£€æµ‹é€»è¾‘

### æ–‡ä»¶: `backend/app/monitoring/api_key_health.py` (æ–°å¢)

```python
import asyncio
from datetime import datetime, timedelta
from typing import Optional, Dict
from app.monitoring.api_key_monitor import api_key_monitor
from app.utils import create_llm_function_native
import os


class APIKeyHealthChecker:
    """API Keyå¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.check_interval = 1800  # 30åˆ†é’Ÿ
        self.is_running = False
    
    async def check_single_key(self, key_id: str, api_key: str) -> Dict:
        """
        æ£€æŸ¥å•ä¸ªKeyçš„å¥åº·çŠ¶æ€
        
        Returns:
            {
                "key_id": str,
                "is_valid": bool,
                "response_time": float,
                "error": Optional[str]
            }
        """
        try:
            # ä¸´æ—¶è®¾ç½®API Key
            original_key = os.environ.get("GROQ_API_KEY")
            os.environ["GROQ_API_KEY"] = api_key
            
            start_time = datetime.now()
            
            # ä½¿ç”¨æœ€å°çš„è¯·æ±‚æµ‹è¯•
            llm = create_llm_function_native()
            result = llm(
                "Hi",  # æœ€ç®€å•çš„prompt
                {"response": "str"},  # æœ€ç®€å•çš„è¾“å‡º
                max_tokens=1
            )
            
            response_time = (datetime.now() - start_time).total_seconds()
            
            # æ¢å¤åŸKey
            if original_key:
                os.environ["GROQ_API_KEY"] = original_key
            
            return {
                "key_id": key_id,
                "is_valid": True,
                "response_time": response_time,
                "error": None
            }
            
        except Exception as e:
            error_msg = str(e).lower()
            
            # åˆ¤æ–­å¤±æ•ˆåŸå› 
            if "401" in error_msg or "unauthorized" in error_msg:
                reason = "Authentication failed - Key may be invalid"
                is_suspended = True
            elif "403" in error_msg or "forbidden" in error_msg:
                reason = "Access forbidden - Account may be suspended"
                is_suspended = True
            else:
                reason = f"Health check failed: {str(e)}"
                is_suspended = False
            
            return {
                "key_id": key_id,
                "is_valid": False,
                "response_time": None,
                "error": reason,
                "is_suspended": is_suspended
            }
    
    async def check_all_keys(self) -> Dict[str, Dict]:
        """æ£€æŸ¥æ‰€æœ‰Keyçš„å¥åº·çŠ¶æ€"""
        print("[HEALTH CHECK] å¼€å§‹æ£€æŸ¥æ‰€æœ‰API Keys...")
        
        results = {}
        stats = api_key_monitor.get_all_stats()
        
        # å¹¶å‘æ£€æŸ¥æ‰€æœ‰Keyï¼ˆä½†é™åˆ¶å¹¶å‘æ•°ï¼‰
        tasks = []
        for key_id, stat in stats.items():
            # ä»ç¯å¢ƒå˜é‡è·å–å®é™…çš„Key
            key_index = int(key_id.split('_')[1])
            api_key = os.environ.get(f"GROQ_API_KEY_{key_index}")
            
            if api_key:
                tasks.append(self.check_single_key(key_id, api_key))
        
        # æ‰§è¡Œæ£€æŸ¥
        check_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ›´æ–°ç›‘æ§ç»Ÿè®¡
        for result in check_results:
            if isinstance(result, dict):
                key_id = result["key_id"]
                stat = stats.get(key_id)
                
                if stat:
                    stat.is_valid = result["is_valid"]
                    stat.last_health_check = datetime.now()
                    
                    if not result["is_valid"]:
                        stat.health_check_failures += 1
                        stat.is_suspended = result.get("is_suspended", False)
                        stat.invalidation_reason = result.get("error")
                        stat.invalidated_at = datetime.now()
                        print(f"[HEALTH CHECK] âŒ {key_id} å¤±æ•ˆ: {result['error']}")
                    else:
                        stat.health_check_failures = 0
                        stat.is_suspended = False
                        print(f"[HEALTH CHECK] âœ… {key_id} æ­£å¸¸")
                
                results[key_id] = result
        
        print(f"[HEALTH CHECK] æ£€æŸ¥å®Œæˆ: {len(results)} ä¸ªKeys")
        return results
    
    async def start_periodic_check(self):
        """å¯åŠ¨å®šæœŸå¥åº·æ£€æŸ¥"""
        self.is_running = True
        print(f"[HEALTH CHECK] å®šæœŸæ£€æŸ¥å·²å¯åŠ¨ï¼ˆé—´éš”: {self.check_interval}ç§’ï¼‰")
        
        # å¯åŠ¨æ—¶ç«‹å³æ£€æŸ¥ä¸€æ¬¡
        await self.check_all_keys()
        
        # å®šæœŸæ£€æŸ¥
        while self.is_running:
            await asyncio.sleep(self.check_interval)
            await self.check_all_keys()
    
    def stop_periodic_check(self):
        """åœæ­¢å®šæœŸæ£€æŸ¥"""
        self.is_running = False
        print("[HEALTH CHECK] å®šæœŸæ£€æŸ¥å·²åœæ­¢")


# å…¨å±€å•ä¾‹
health_checker = APIKeyHealthChecker()
```

---

## é›†æˆåˆ°ç›‘æ§å™¨

### æ›´æ–° `api_key_monitor.py`

```python
class APIKeyMonitor:
    # ... ç°æœ‰ä»£ç  ...
    
    def record_call(self, key_id: str, success: bool, ...):
        """è®°å½•è°ƒç”¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        if key_id not in self.stats:
            return
        
        stat = self.stats[key_id]
        
        # ... ç°æœ‰ç»Ÿè®¡é€»è¾‘ ...
        
        # ã€æ–°å¢ã€‘æ›´æ–°å¤±è´¥ç‡çª—å£
        stat.failure_rate_window.append(success)
        if len(stat.failure_rate_window) > 50:
            stat.failure_rate_window.pop(0)  # ä¿æŒæœ€è¿‘50æ¬¡
        
        # ã€æ–°å¢ã€‘è¿ç»­å¤±è´¥æ£€æµ‹
        if success:
            stat.consecutive_failures = 0
        else:
            stat.consecutive_failures += 1
            
            # è§¦å‘å¤±æ•ˆæ£€æµ‹
            if stat.consecutive_failures >= 10:
                print(f"[MONITOR] âš ï¸ {key_id} è¿ç»­å¤±è´¥{stat.consecutive_failures}æ¬¡ï¼Œæ ‡è®°ä¸ºç–‘ä¼¼å¤±æ•ˆ")
                stat.is_valid = False
                stat.invalidation_reason = f"Consecutive failures: {stat.consecutive_failures}"
                stat.invalidated_at = datetime.now()
        
        # ã€æ–°å¢ã€‘å¤±è´¥ç‡æ£€æµ‹
        if len(stat.failure_rate_window) >= 50 and stat.recent_failure_rate > 80:
            print(f"[MONITOR] âš ï¸ {key_id} å¤±è´¥ç‡{stat.recent_failure_rate:.1f}%ï¼Œæ ‡è®°ä¸ºç–‘ä¼¼å¤±æ•ˆ")
            stat.is_valid = False
            stat.invalidation_reason = f"High failure rate: {stat.recent_failure_rate:.1f}%"
```

---

## APIæ¥å£æ‰©å±•

### åœ¨ `api_key_dashboard.py` ä¸­æ·»åŠ 

```python
@router.get("/health/check")
async def trigger_health_check():
    """æ‰‹åŠ¨è§¦å‘å¥åº·æ£€æŸ¥"""
    from app.monitoring.api_key_health import health_checker
    results = await health_checker.check_all_keys()
    return {
        "checked_keys": len(results),
        "valid_keys": sum(1 for r in results.values() if r["is_valid"]),
        "invalid_keys": sum(1 for r in results.values() if not r["is_valid"]),
        "results": results
    }


@router.get("/health/invalid")
async def get_invalid_keys():
    """è·å–æ‰€æœ‰å¤±æ•ˆçš„Keys"""
    stats = api_key_monitor.get_all_stats()
    invalid_keys = {
        key_id: stat
        for key_id, stat in stats.items()
        if not stat.is_valid or stat.is_suspended
    }
    return {
        "count": len(invalid_keys),
        "keys": invalid_keys
    }


@router.post("/keys/{key_id}/revalidate")
async def revalidate_key(key_id: str):
    """é‡æ–°éªŒè¯å•ä¸ªKey"""
    from app.monitoring.api_key_health import health_checker
    
    # è·å–Key
    key_index = int(key_id.split('_')[1])
    api_key = os.environ.get(f"GROQ_API_KEY_{key_index}")
    
    if not api_key:
        raise HTTPException(status_code=404, detail=f"Key {key_id} not found")
    
    result = await health_checker.check_single_key(key_id, api_key)
    return result
```

---

## å¯åŠ¨æ—¶é›†æˆ

### åœ¨ `main.py` ä¸­æ·»åŠ 

```python
from app.monitoring.api_key_health import health_checker
import asyncio

@app.on_event("startup")
async def startup_event():
    # ... ç°æœ‰å¯åŠ¨é€»è¾‘ ...
    
    # å¯åŠ¨å¥åº·æ£€æŸ¥
    asyncio.create_task(health_checker.start_periodic_check())
    print("âœ… API Keyå¥åº·æ£€æŸ¥å·²å¯åŠ¨")


@app.on_event("shutdown")
async def shutdown_event():
    health_checker.stop_periodic_check()
    print("ğŸ‘‹ API Keyå¥åº·æ£€æŸ¥å·²åœæ­¢")
```

---

## ä½¿ç”¨æ–¹å¼

### 1. è‡ªåŠ¨æ£€æµ‹ï¼ˆæ— éœ€æ“ä½œï¼‰
- ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥
- æ¯30åˆ†é’Ÿè‡ªåŠ¨é‡æ–°æ£€æŸ¥
- è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨æ ‡è®°

### 2. æ‰‹åŠ¨æ£€æŸ¥
```bash
# ç«‹å³æ£€æŸ¥æ‰€æœ‰Keys
GET http://localhost:8000/monitoring/health/check

# æŸ¥çœ‹å¤±æ•ˆçš„Keys
GET http://localhost:8000/monitoring/health/invalid

# é‡æ–°éªŒè¯å•ä¸ªKey
POST http://localhost:8000/monitoring/keys/KEY_5/revalidate
```

### 3. æŸ¥çœ‹ç»Ÿè®¡
```bash
# åœ¨æ‰€æœ‰Keyç»Ÿè®¡ä¸­æŸ¥çœ‹is_validå­—æ®µ
GET http://localhost:8000/monitoring/keys
```

---

## å®æ–½é¡ºåº

1. **æ­¥éª¤1**: æ‰©å±•æ•°æ®æ¨¡å‹ï¼ˆ30åˆ†é’Ÿï¼‰
2. **æ­¥éª¤2**: å®ç°å¥åº·æ£€æŸ¥å™¨ï¼ˆ1.5å°æ—¶ï¼‰
3. **æ­¥éª¤3**: é›†æˆåˆ°ç›‘æ§å™¨ï¼ˆ1å°æ—¶ï¼‰
4. **æ­¥éª¤4**: æ·»åŠ APIæ¥å£ï¼ˆ30åˆ†é’Ÿï¼‰
5. **æ­¥éª¤5**: å¯åŠ¨æ—¶é›†æˆï¼ˆ30åˆ†é’Ÿï¼‰
6. **æµ‹è¯•**: æ•…æ„ä½¿ç”¨å¤±æ•ˆKeyæµ‹è¯•æ£€æµ‹é€»è¾‘ï¼ˆ1å°æ—¶ï¼‰

**æ€»å·¥ä½œé‡**: çº¦4.5å°æ—¶

---

## å‘Šè­¦å»ºè®®

### å¯é€‰ï¼šæ·»åŠ å‘Šè­¦é€šçŸ¥

```python
def send_alert(key_id: str, reason: str):
    """å‘é€å¤±æ•ˆå‘Šè­¦"""
    # å¯ä»¥é›†æˆï¼š
    # - é‚®ä»¶é€šçŸ¥
    # - ä¼ä¸šå¾®ä¿¡/é’‰é’‰æœºå™¨äºº
    # - Telegram Bot
    # - æ—¥å¿—è®°å½•
    
    print(f"ğŸš¨ [ALERT] Key {key_id} å¤±æ•ˆ: {reason}")
    
    # ç¤ºä¾‹ï¼šå†™å…¥å‘Šè­¦æ—¥å¿—
    with open("alerts.log", "a") as f:
        f.write(f"{datetime.now()} - {key_id} - {reason}\n")
```

---

## å®Œæˆæ ‡å‡†

âœ… **æ£€æµ‹å‡†ç¡®æ€§**
- èƒ½æ­£ç¡®è¯†åˆ«401/403é”™è¯¯
- è¿ç»­å¤±è´¥10æ¬¡è§¦å‘æ ‡è®°
- å¤±è´¥ç‡>80%è§¦å‘æ ‡è®°
- å¥åº·æ£€æŸ¥è¯·æ±‚æˆæœ¬<0.01ç¾å…ƒ/æ¬¡

âœ… **å®æ—¶æ€§**
- å¯åŠ¨æ—¶5ç§’å†…å®Œæˆåˆå§‹æ£€æŸ¥
- å®šæœŸæ£€æŸ¥30åˆ†é’Ÿä¸€æ¬¡
- æ‰‹åŠ¨æ£€æŸ¥5ç§’å†…è¿”å›ç»“æœ

âœ… **å¯é æ€§**
- å¥åº·æ£€æŸ¥ä¸å½±å“ä¸»æµç¨‹
- ç½‘ç»œé—®é¢˜ä¸è¯¯æŠ¥å¤±æ•ˆ
- æ”¯æŒé‡æ–°éªŒè¯æ¢å¤æ ‡è®°

âœ… **å¯ç”¨æ€§**
- æä¾›æ¸…æ™°çš„å¤±æ•ˆåŸå› 
- æ”¯æŒæ‰‹åŠ¨è§¦å‘æ£€æŸ¥
- å¤±æ•ˆKeyæ•°é‡å®æ—¶å¯è§

---

 

---

# LangGraph Memoryç³»ç»Ÿå®æ–½è®¡åˆ’

## æ¦‚è¿°

å®ç°åŸºäºLangGraph Store APIçš„é•¿æœŸè®°å¿†ç³»ç»Ÿï¼Œæ”¯æŒï¼š
1. ä¿å­˜ç”¨æˆ·çœ‹è¿‡çš„TEDæ¼”è®²ï¼ˆseen_urlsï¼‰- é¿å…é‡å¤æ¨è
2. ä¿å­˜æœç´¢å†å²ï¼ˆsearch_historyï¼‰- ä¼˜åŒ–æœç´¢ä½“éªŒ
3. ä¿å­˜Shadow Writingå­¦ä¹ è®°å½•ï¼ˆlearning_recordsï¼‰- è¿½è¸ªå­¦ä¹ è¿›åº¦

---

## ç³»ç»Ÿæ¶æ„

### Memoryåˆ†ç±»

æ ¹æ®LangGraphæ¦‚å¿µæ–‡æ¡£ï¼Œæˆ‘ä»¬å®ç°ä¸¤ç§Memoryç±»å‹ï¼š

#### 1. Semantic Memoryï¼ˆè¯­ä¹‰è®°å¿†ï¼‰- äº‹å®ä¸æ¦‚å¿µ
- **seen_urls**: ç”¨æˆ·è§‚çœ‹è¿‡çš„TEDæ¼”è®²URLåˆ—è¡¨
- **æ•°æ®ç»“æ„**: Collectionï¼ˆæ–‡æ¡£é›†åˆï¼‰
- **ç”¨é€”**: é˜²æ­¢é‡å¤æ¨èï¼Œä¸ªæ€§åŒ–å†…å®¹è¿‡æ»¤

#### 2. Episodic Memoryï¼ˆæƒ…èŠ‚è®°å¿†ï¼‰- ç»å†ä¸äº‹ä»¶
- **search_history**: ç”¨æˆ·çš„æœç´¢è®°å½•
- **learning_records**: Shadow Writingå­¦ä¹ æˆæœè®°å½•
- **æ•°æ®ç»“æ„**: Collectionï¼ˆäº‹ä»¶æµï¼‰
- **ç”¨é€”**: åˆ†æå­¦ä¹ è¡Œä¸ºï¼Œæä¾›å­¦ä¹ ç»Ÿè®¡

### Namespaceè®¾è®¡

LangGraph Storeä½¿ç”¨åˆ†å±‚namespaceç»„ç»‡memoryï¼š

```python
# åŸºç¡€ç»“æ„
namespace = (user_id, memory_type)

# ä¸‰ç§å…·ä½“namespaceï¼š
("user_123", "ted_history")          # TEDè§‚çœ‹å†å²
("user_123", "search_history")       # æœç´¢å†å²
("user_123", "shadow_writing_records") # å­¦ä¹ è®°å½•
```

### å†™å…¥ç­–ç•¥

| Memoryç±»å‹ | å†™å…¥æ–¹å¼ | æ—¶æœº | åŸå›  |
|-----------|---------|------|------|
| seen_urls | In the hot path | Communication Agentå¤„ç†åç«‹å³å†™å…¥ | éœ€è¦å®æ—¶é˜²æ­¢é‡å¤æ¨è |
| search_history | In the hot path | æœç´¢å®Œæˆåç«‹å³å†™å…¥ | è®°å½•å³æ—¶æœç´¢ä¸Šä¸‹æ–‡ |
| learning_records | In the background | æ‰¹é‡å†™å…¥æˆ–å®šæ—¶å†™å…¥ | ä¸é˜»å¡ä¸»æµç¨‹ï¼Œå¯å¼‚æ­¥å¤„ç† |

---

## æ•°æ®æ¨¡å‹è®¾è®¡

### 1. TEDè§‚çœ‹å†å²ï¼ˆseen_urlsï¼‰

```python
# Namespace: (user_id, "ted_history")
# Key: ted_urlçš„hashæˆ–å”¯ä¸€ID

{
    "url": "https://www.ted.com/talks/speaker_title",
    "title": "æ¼”è®²æ ‡é¢˜",
    "speaker": "æ¼”è®²è€…å§“å",
    "watched_at": "2025-10-09T21:18:57+08:00",  # ISO 8601æ ¼å¼
    "search_topic": "ç”¨æˆ·æœç´¢çš„åŸå§‹ä¸»é¢˜",
    "chunks_processed": 15,                      # å¤„ç†çš„è¯­ä¹‰å—æ•°é‡
    "shadow_writing_count": 12,                  # æˆåŠŸç”Ÿæˆçš„Shadow Writingæ•°é‡
    "metadata": {
        "ted_duration": "12:30",
        "ted_views": "1.2M",
        "transcript_length": 8500
    }
}
```

### 2. æœç´¢å†å²ï¼ˆsearch_historyï¼‰

```python
# Namespace: (user_id, "search_history")
# Key: è‡ªåŠ¨ç”Ÿæˆçš„UUID

{
    "original_query": "leadership",
    "optimized_query": "effective leadership strategies in modern workplace",
    "alternative_queries": [
        "team management best practices",
        "inspiring leadership talks"
    ],
    "results_count": 5,
    "selected_url": "https://www.ted.com/talks/...",
    "selected_title": "ç”¨æˆ·æœ€ç»ˆé€‰æ‹©çš„æ¼”è®²æ ‡é¢˜",
    "searched_at": "2025-10-09T21:18:57+08:00",
    "search_duration_ms": 1250,
    "new_results": 5,                            # å»é‡åçš„æ–°ç»“æœæ•°
    "filtered_seen": 3                           # å·²çœ‹è¿‡è¢«è¿‡æ»¤çš„æ•°é‡
}
```

### 3. Shadow Writingå­¦ä¹ è®°å½•ï¼ˆlearning_recordsï¼‰

```python
# Namespace: (user_id, "shadow_writing_records")
# Key: è‡ªåŠ¨ç”Ÿæˆçš„UUID

{
    "ted_url": "https://www.ted.com/talks/...",
    "ted_title": "æ¼”è®²æ ‡é¢˜",
    "original_sentence": "å®Œæ•´åŸå¥",
    "imitation": "è¯é¢˜è¿ç§»åçš„å¥å­",
    "word_map": {
        "Category_1": ["original", "migrated"],
        "Category_2": ["original", "migrated"]
    },
    "quality_score": 8.5,
    "quality_details": {
        "structure_preservation": 3,
        "naturalness": 3,
        "semantic_accuracy": 2
    },
    "paragraph": "åŸå§‹æ®µè½ä¸Šä¸‹æ–‡",
    "created_at": "2025-10-09T21:18:57+08:00",
    "processing_time_ms": 3500,
    "semantic_categories": ["leadership", "motivation", "team building"]
}
```

---

## å®æ–½é˜¶æ®µ

### é˜¶æ®µ1: ç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–é…ç½®

#### æ­¥éª¤1.1: å®‰è£…LangGraphä¾èµ–

**æ–‡ä»¶**: `backend/requirements.txt`

```txt
# ç°æœ‰ä¾èµ–...

# Memoryæ”¯æŒ
langgraph>=0.2.0
langgraph-checkpoint-postgres>=1.0.0  # ç”Ÿäº§ç¯å¢ƒPostgresStore
```

**æ“ä½œ**:
```bash
cd backend
pip install -r requirements.txt
```

#### æ­¥éª¤1.2: é…ç½®ç¯å¢ƒå˜é‡

**æ–‡ä»¶**: `backend/.env` å’Œ `backend/.env.example`

æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```env
# ===== Memory Storeé…ç½® =====
# å¼€å‘ç¯å¢ƒä½¿ç”¨InMemoryStoreï¼Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨PostgresStore

# PostgreSQLé…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
POSTGRES_URI=postgresql://user:password@localhost:5432/shadow_writing_db

# Memory Storeé…ç½®
MEMORY_STORE_TYPE=inmemory  # å¯é€‰: inmemory, postgres
MEMORY_EMBEDDING_MODEL=text-embedding-3-small  # OpenAI embeddingæ¨¡å‹

# MemoryåŠŸèƒ½å¼€å…³
ENABLE_MEMORY=true
ENABLE_SEARCH_HISTORY=true
ENABLE_LEARNING_RECORDS=true
```

#### æ­¥éª¤1.3: æ•°æ®åº“å‡†å¤‡ï¼ˆå¯é€‰ï¼Œç”Ÿäº§ç¯å¢ƒï¼‰

å¦‚æœä½¿ç”¨PostgresStoreï¼Œéœ€è¦åˆ›å»ºæ•°æ®åº“ï¼š

```bash
# åˆ›å»ºæ•°æ®åº“
createdb shadow_writing_db

# LangGraphä¼šè‡ªåŠ¨åˆ›å»ºæ‰€éœ€çš„è¡¨ç»“æ„
```

---

### é˜¶æ®µ2: Memory Serviceå±‚å®ç°ï¼ˆæ‹†åˆ†æ–¹æ¡ˆï¼‰

#### æ­¥éª¤2.1: åˆ›å»ºMemoryç›®å½•ç»“æ„

```
backend/app/memory/
â”œâ”€â”€ __init__.py              # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ store_factory.py         # Storeå·¥å‚
â”œâ”€â”€ base_memory.py           # åŸºç¡€Memoryç±»ï¼ˆ~50è¡Œï¼‰
â”œâ”€â”€ ted_history_memory.py    # TEDè§‚çœ‹å†å²ï¼ˆ~120è¡Œï¼‰
â”œâ”€â”€ search_history_memory.py # æœç´¢å†å²ï¼ˆ~100è¡Œï¼‰
â”œâ”€â”€ learning_records_memory.py # å­¦ä¹ è®°å½•ï¼ˆç©ºç™½å¾…å®ç°ï¼‰
â””â”€â”€ service.py               # ç»Ÿä¸€å…¥å£æœåŠ¡ï¼ˆ~80è¡Œï¼‰
```

#### æ­¥éª¤2.2: å®ç°åŸºç¡€Memoryç±»

**æ–‡ä»¶**: `backend/app/memory/base_memory.py` (æ–°å»º)

```python
"""Base Memory - Memoryæ“ä½œåŸºç±»"""

from typing import Optional
from langgraph.store.base import BaseStore
import hashlib

class BaseMemory:
    """Memoryæ“ä½œåŸºç±»
    
    æä¾›é€šç”¨çš„Storeè®¿é—®å’Œå·¥å…·æ–¹æ³•
    """
    
    def __init__(self, store: BaseStore):
        """åˆå§‹åŒ–Memory
        
        Args:
            store: LangGraph Storeå®ä¾‹
        """
        self.store = store
    
    @staticmethod
    def hash_string(text: str, length: int = 16) -> str:
        """ç”Ÿæˆå­—ç¬¦ä¸²çš„hashå€¼
        
        Args:
            text: éœ€è¦hashçš„å­—ç¬¦ä¸²
            length: hashé•¿åº¦ï¼ˆé»˜è®¤16ä½ï¼‰
            
        Returns:
            SHA256 hashçš„å‰Nä½
        """
        return hashlib.sha256(text.encode()).hexdigest()[:length]
```

#### æ­¥éª¤2.3: å®ç°TEDè§‚çœ‹å†å²Memory

**æ–‡ä»¶**: `backend/app/memory/ted_history_memory.py` (æ–°å»º)

```python
"""TED History Memory - TEDè§‚çœ‹å†å²ç®¡ç†"""

from typing import Dict, Any, Optional, Set
from datetime import datetime
from app.memory.base_memory import BaseMemory

class TEDHistoryMemory(BaseMemory):
    """TEDè§‚çœ‹å†å²ç®¡ç†
    
    è´Ÿè´£è®°å½•ç”¨æˆ·çœ‹è¿‡çš„TEDæ¼”è®²ï¼Œç”¨äºå»é‡å’Œä¸ªæ€§åŒ–æ¨è
    """
    
    NAMESPACE_TYPE = "ted_history"
    
    def get_seen_urls(self, user_id: str) -> Set[str]:
        """è·å–ç”¨æˆ·çœ‹è¿‡çš„TED URLåˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            URLé›†åˆ
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        items = self.store.search(namespace)
        
        return {item.value.get("url") for item in items if item.value.get("url")}
    
    def add_seen_ted(
        self, 
        user_id: str, 
        url: str, 
        title: str,
        speaker: str,
        search_topic: str,
        chunks_processed: int = 0,
        shadow_writing_count: int = 0,
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """æ·»åŠ TEDè§‚çœ‹è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            url: TED URL
            title: æ¼”è®²æ ‡é¢˜
            speaker: æ¼”è®²è€…
            search_topic: æœç´¢ä¸»é¢˜
            chunks_processed: å¤„ç†çš„è¯­ä¹‰å—æ•°é‡
            shadow_writing_count: æˆåŠŸç”Ÿæˆçš„Shadow Writingæ•°é‡
            metadata: é¢å¤–å…ƒæ•°æ®
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        
        # ä½¿ç”¨URLçš„hashä½œä¸ºkeyï¼ˆé¿å…URLè¿‡é•¿ï¼‰
        key = self.hash_string(url)
        
        memory_data = {
            "url": url,
            "title": title,
            "speaker": speaker,
            "watched_at": datetime.now().isoformat(),
            "search_topic": search_topic,
            "chunks_processed": chunks_processed,
            "shadow_writing_count": shadow_writing_count,
            "metadata": metadata or {}
        }
        
        self.store.put(namespace, key, memory_data)
    
    def is_seen(self, user_id: str, url: str) -> bool:
        """æ£€æŸ¥TEDæ˜¯å¦å·²è§‚çœ‹
        
        Args:
            user_id: ç”¨æˆ·ID
            url: TED URL
            
        Returns:
            æ˜¯å¦å·²è§‚çœ‹
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        key = self.hash_string(url)
        
        item = self.store.get(namespace, key)
        return item is not None
    
    def get_ted_info(self, user_id: str, url: str) -> Optional[Dict[str, Any]]:
        """è·å–TEDè¯¦ç»†ä¿¡æ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            url: TED URL
            
        Returns:
            TEDä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        key = self.hash_string(url)
        
        item = self.store.get(namespace, key)
        return item.value if item else None
    
    def update_processing_stats(
        self,
        user_id: str,
        url: str,
        chunks_processed: int,
        shadow_writing_count: int
    ) -> None:
        """æ›´æ–°å¤„ç†ç»Ÿè®¡æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            url: TED URL
            chunks_processed: å¤„ç†çš„è¯­ä¹‰å—æ•°é‡
            shadow_writing_count: æˆåŠŸç”Ÿæˆçš„æ•°é‡
        """
        ted_info = self.get_ted_info(user_id, url)
        
        if ted_info:
            ted_info["chunks_processed"] = chunks_processed
            ted_info["shadow_writing_count"] = shadow_writing_count
            
            namespace = (user_id, self.NAMESPACE_TYPE)
            key = self.hash_string(url)
            self.store.put(namespace, key, ted_info)
```

#### æ­¥éª¤2.4: å®ç°æœç´¢å†å²Memory

**æ–‡ä»¶**: `backend/app/memory/search_history_memory.py` (æ–°å»º)

```python
"""Search History Memory - æœç´¢å†å²ç®¡ç†"""

from typing import List, Dict, Any, Optional
from datetime import datetime
import uuid
from app.memory.base_memory import BaseMemory

class SearchHistoryMemory(BaseMemory):
    """æœç´¢å†å²ç®¡ç†
    
    è´Ÿè´£è®°å½•ç”¨æˆ·çš„æœç´¢è¡Œä¸ºï¼Œç”¨äºåˆ†æå’Œä¼˜åŒ–æœç´¢ä½“éªŒ
    """
    
    NAMESPACE_TYPE = "search_history"
    
    def add_search(
        self,
        user_id: str,
        original_query: str,
        optimized_query: str,
        alternative_queries: List[str],
        results_count: int,
        selected_url: Optional[str] = None,
        selected_title: Optional[str] = None,
        new_results: int = 0,
        filtered_seen: int = 0,
        search_duration_ms: int = 0
    ) -> str:
        """æ·»åŠ æœç´¢å†å²è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            original_query: åŸå§‹æœç´¢è¯
            optimized_query: ä¼˜åŒ–åçš„æœç´¢è¯
            alternative_queries: å¤‡é€‰æœç´¢è¯åˆ—è¡¨
            results_count: æœç´¢ç»“æœæ•°é‡
            selected_url: ç”¨æˆ·é€‰æ‹©çš„URL
            selected_title: ç”¨æˆ·é€‰æ‹©çš„æ ‡é¢˜
            new_results: å»é‡åçš„æ–°ç»“æœæ•°
            filtered_seen: è¢«è¿‡æ»¤çš„å·²çœ‹è¿‡æ•°é‡
            search_duration_ms: æœç´¢è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            è®°å½•IDï¼ˆUUIDï¼‰
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        key = str(uuid.uuid4())
        
        memory_data = {
            "original_query": original_query,
            "optimized_query": optimized_query,
            "alternative_queries": alternative_queries,
            "results_count": results_count,
            "selected_url": selected_url,
            "selected_title": selected_title,
            "searched_at": datetime.now().isoformat(),
            "search_duration_ms": search_duration_ms,
            "new_results": new_results,
            "filtered_seen": filtered_seen
        }
        
        self.store.put(namespace, key, memory_data)
        return key
    
    def get_recent_searches(
        self, 
        user_id: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æœç´¢å†å²
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æœç´¢å†å²åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        items = self.store.search(namespace)
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        sorted_items = sorted(
            items, 
            key=lambda x: x.value.get("searched_at", ""),
            reverse=True
        )
        
        return [item.value for item in sorted_items[:limit]]
    
    def update_selected_url(
        self,
        user_id: str,
        search_id: str,
        selected_url: str,
        selected_title: str
    ) -> None:
        """æ›´æ–°æœç´¢è®°å½•çš„é€‰æ‹©ç»“æœ
        
        Args:
            user_id: ç”¨æˆ·ID
            search_id: æœç´¢è®°å½•ID
            selected_url: ç”¨æˆ·é€‰æ‹©çš„URL
            selected_title: ç”¨æˆ·é€‰æ‹©çš„æ ‡é¢˜
        """
        namespace = (user_id, self.NAMESPACE_TYPE)
        item = self.store.get(namespace, search_id)
        
        if item:
            search_data = item.value
            search_data["selected_url"] = selected_url
            search_data["selected_title"] = selected_title
            self.store.put(namespace, search_id, search_data)
```

#### æ­¥éª¤2.5: åˆ›å»ºå­¦ä¹ è®°å½•Memoryï¼ˆå¾…å®ç°ï¼‰

**æ–‡ä»¶**: `backend/app/memory/learning_records_memory.py` (æ–°å»º)

```python
"""Learning Records Memory - Shadow Writingå­¦ä¹ è®°å½•ç®¡ç†

TODO: å…·ä½“å®ç°é€»è¾‘å¾…ç¡®å®š
"""

from typing import List, Dict, Any, Optional
from app.memory.base_memory import BaseMemory

class LearningRecordsMemory(BaseMemory):
    """Shadow Writingå­¦ä¹ è®°å½•ç®¡ç†
    
    è´Ÿè´£è®°å½•ç”¨æˆ·çš„Shadow Writingå­¦ä¹ æˆæœ
    
    TODO: 
    - ç¡®å®šå­¦ä¹ è®°å½•çš„æ•°æ®ç»“æ„
    - å®ç°è®°å½•æ·»åŠ é€»è¾‘
    - å®ç°è®°å½•æŸ¥è¯¢é€»è¾‘
    - å®ç°å­¦ä¹ ç»Ÿè®¡é€»è¾‘
    """
    
    NAMESPACE_TYPE = "shadow_writing_records"
    
    def add_record(
        self,
        user_id: str,
        **kwargs
    ) -> str:
        """æ·»åŠ å­¦ä¹ è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            **kwargs: å­¦ä¹ è®°å½•æ•°æ®ï¼ˆå¾…å®šï¼‰
            
        Returns:
            è®°å½•ID
        """
        # TODO: å®ç°
        raise NotImplementedError("å­¦ä¹ è®°å½•åŠŸèƒ½å¾…å®ç°")
    
    def get_records(
        self,
        user_id: str,
        **filters
    ) -> List[Dict[str, Any]]:
        """è·å–å­¦ä¹ è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            **filters: è¿‡æ»¤æ¡ä»¶ï¼ˆå¾…å®šï¼‰
            
        Returns:
            å­¦ä¹ è®°å½•åˆ—è¡¨
        """
        # TODO: å®ç°
        raise NotImplementedError("å­¦ä¹ è®°å½•åŠŸèƒ½å¾…å®ç°")
    
    def get_stats(self, user_id: str) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        # TODO: å®ç°
        raise NotImplementedError("å­¦ä¹ è®°å½•åŠŸèƒ½å¾…å®ç°")
```

#### æ­¥éª¤2.6: å®ç°ç»Ÿä¸€MemoryService

**æ–‡ä»¶**: `backend/app/memory/service.py` (æ–°å»º)

```python
"""Memory Service - ç»Ÿä¸€Memoryç®¡ç†å…¥å£

ä½¿ç”¨Facadeæ¨¡å¼ï¼Œåè°ƒå„ä¸ªå­MemoryæœåŠ¡
"""

from typing import Optional, List, Dict, Any, Set
from langgraph.store.base import BaseStore
from langgraph.store.memory import InMemoryStore

from app.memory.ted_history_memory import TEDHistoryMemory
from app.memory.search_history_memory import SearchHistoryMemory
from app.memory.learning_records_memory import LearningRecordsMemory

class MemoryService:
    """Memoryç»Ÿä¸€ç®¡ç†æœåŠ¡
    
    å°è£…LangGraph Storeæ“ä½œï¼Œæä¾›ä¸šåŠ¡å±‚é¢çš„Memoryæ¥å£
    """
    
    def __init__(self, store: Optional[BaseStore] = None):
        """åˆå§‹åŒ–Memory Service
        
        Args:
            store: LangGraph Storeå®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨InMemoryStore
        """
        if store is None:
            # å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨InMemoryStore
            # TODO: æ·»åŠ embeddingå‡½æ•°æ”¯æŒè¯­ä¹‰æœç´¢
            self.store = InMemoryStore()
        else:
            self.store = store
    
    # ========== TEDè§‚çœ‹å†å² ==========
    
    def get_seen_ted_urls(self, user_id: str) -> set[str]:
        """è·å–ç”¨æˆ·çœ‹è¿‡çš„TED URLåˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            URLé›†åˆ
        """
        namespace = (user_id, "ted_history")
        items = self.store.search(namespace)
        
        return {item.value.get("url") for item in items if item.value.get("url")}
    
    def add_seen_ted(
        self, 
        user_id: str, 
        url: str, 
        title: str,
        speaker: str,
        search_topic: str,
        chunks_processed: int = 0,
        shadow_writing_count: int = 0,
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """æ·»åŠ TEDè§‚çœ‹è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            url: TED URL
            title: æ¼”è®²æ ‡é¢˜
            speaker: æ¼”è®²è€…
            search_topic: æœç´¢ä¸»é¢˜
            chunks_processed: å¤„ç†çš„è¯­ä¹‰å—æ•°é‡
            shadow_writing_count: æˆåŠŸç”Ÿæˆçš„æ•°é‡
            metadata: é¢å¤–å…ƒæ•°æ®
        """
        namespace = (user_id, "ted_history")
        
        # ä½¿ç”¨URLçš„hashä½œä¸ºkeyï¼ˆé¿å…URLè¿‡é•¿ï¼‰
        key = self._hash_url(url)
        
        memory_data = {
            "url": url,
            "title": title,
            "speaker": speaker,
            "watched_at": datetime.now().isoformat(),
            "search_topic": search_topic,
            "chunks_processed": chunks_processed,
            "shadow_writing_count": shadow_writing_count,
            "metadata": metadata or {}
        }
        
        self.store.put(namespace, key, memory_data)
    
    def is_ted_seen(self, user_id: str, url: str) -> bool:
        """æ£€æŸ¥TEDæ˜¯å¦å·²è§‚çœ‹
        
        Args:
            user_id: ç”¨æˆ·ID
            url: TED URL
            
        Returns:
            æ˜¯å¦å·²è§‚çœ‹
        """
        namespace = (user_id, "ted_history")
        key = self._hash_url(url)
        
        item = self.store.get(namespace, key)
        return item is not None
    
    # ========== æœç´¢å†å² ==========
    
    def add_search_history(
        self,
        user_id: str,
        original_query: str,
        optimized_query: str,
        alternative_queries: List[str],
        results_count: int,
        selected_url: Optional[str] = None,
        selected_title: Optional[str] = None,
        new_results: int = 0,
        filtered_seen: int = 0,
        search_duration_ms: int = 0
    ) -> str:
        """æ·»åŠ æœç´¢å†å²è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            original_query: åŸå§‹æœç´¢è¯
            optimized_query: ä¼˜åŒ–åçš„æœç´¢è¯
            alternative_queries: å¤‡é€‰æœç´¢è¯åˆ—è¡¨
            results_count: æœç´¢ç»“æœæ•°é‡
            selected_url: ç”¨æˆ·é€‰æ‹©çš„URL
            selected_title: ç”¨æˆ·é€‰æ‹©çš„æ ‡é¢˜
            new_results: å»é‡åçš„æ–°ç»“æœæ•°
            filtered_seen: è¢«è¿‡æ»¤çš„å·²çœ‹è¿‡æ•°é‡
            search_duration_ms: æœç´¢è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            è®°å½•IDï¼ˆUUIDï¼‰
        """
        namespace = (user_id, "search_history")
        key = str(uuid.uuid4())
        
        memory_data = {
            "original_query": original_query,
            "optimized_query": optimized_query,
            "alternative_queries": alternative_queries,
            "results_count": results_count,
            "selected_url": selected_url,
            "selected_title": selected_title,
            "searched_at": datetime.now().isoformat(),
            "search_duration_ms": search_duration_ms,
            "new_results": new_results,
            "filtered_seen": filtered_seen
        }
        
        self.store.put(namespace, key, memory_data)
        return key
    
    def get_recent_searches(
        self, 
        user_id: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æœç´¢å†å²
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æœç´¢å†å²åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
        """
        namespace = (user_id, "search_history")
        items = self.store.search(namespace)
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        sorted_items = sorted(
            items, 
            key=lambda x: x.value.get("searched_at", ""),
            reverse=True
        )
        
        return [item.value for item in sorted_items[:limit]]
    
    # ========== Shadow Writingå­¦ä¹ è®°å½• ==========
    
    def add_learning_record(
        self,
        user_id: str,
        ted_url: str,
        ted_title: str,
        original_sentence: str,
        imitation: str,
        word_map: Dict[str, List[str]],
        quality_score: float,
        quality_details: Dict[str, Any],
        paragraph: str,
        processing_time_ms: int = 0,
        semantic_categories: Optional[List[str]] = None
    ) -> str:
        """æ·»åŠ Shadow Writingå­¦ä¹ è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            ted_url: TED URL
            ted_title: æ¼”è®²æ ‡é¢˜
            original_sentence: åŸå¥
            imitation: ä»¿å†™å¥å­
            word_map: è¯æ±‡æ˜ å°„
            quality_score: è´¨é‡åˆ†æ•°
            quality_details: è´¨é‡è¯„ä¼°è¯¦æƒ…
            paragraph: åŸå§‹æ®µè½
            processing_time_ms: å¤„ç†è€—æ—¶
            semantic_categories: è¯­ä¹‰åˆ†ç±»æ ‡ç­¾
            
        Returns:
            è®°å½•IDï¼ˆUUIDï¼‰
        """
        namespace = (user_id, "shadow_writing_records")
        key = str(uuid.uuid4())
        
        memory_data = {
            "ted_url": ted_url,
            "ted_title": ted_title,
            "original_sentence": original_sentence,
            "imitation": imitation,
            "word_map": word_map,
            "quality_score": quality_score,
            "quality_details": quality_details,
            "paragraph": paragraph,
            "created_at": datetime.now().isoformat(),
            "processing_time_ms": processing_time_ms,
            "semantic_categories": semantic_categories or []
        }
        
        self.store.put(namespace, key, memory_data)
        return key
    
    def get_learning_records(
        self,
        user_id: str,
        ted_url: Optional[str] = None,
        min_quality_score: Optional[float] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """è·å–å­¦ä¹ è®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            ted_url: è¿‡æ»¤ç‰¹å®šTED URLï¼ˆå¯é€‰ï¼‰
            min_quality_score: æœ€ä½è´¨é‡åˆ†æ•°è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            å­¦ä¹ è®°å½•åˆ—è¡¨
        """
        namespace = (user_id, "shadow_writing_records")
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        filter_dict = {}
        if ted_url:
            filter_dict["ted_url"] = ted_url
        
        items = self.store.search(namespace, filter=filter_dict if filter_dict else None)
        
        # è´¨é‡åˆ†æ•°è¿‡æ»¤
        if min_quality_score is not None:
            items = [
                item for item in items 
                if item.value.get("quality_score", 0) >= min_quality_score
            ]
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        sorted_items = sorted(
            items,
            key=lambda x: x.value.get("created_at", ""),
            reverse=True
        )
        
        return [item.value for item in sorted_items[:limit]]
    
    def get_learning_stats(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·å­¦ä¹ ç»Ÿè®¡
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        namespace = (user_id, "shadow_writing_records")
        items = self.store.search(namespace)
        
        if not items:
            return {
                "total_count": 0,
                "average_quality": 0.0,
                "total_ted_count": 0,
                "top_categories": []
            }
        
        records = [item.value for item in items]
        
        # ç»Ÿè®¡è®¡ç®—
        total_count = len(records)
        avg_quality = sum(r.get("quality_score", 0) for r in records) / total_count
        unique_teds = len(set(r.get("ted_url") for r in records))
        
        # ç»Ÿè®¡è¯­ä¹‰åˆ†ç±»
        category_counts = {}
        for record in records:
            for cat in record.get("semantic_categories", []):
                category_counts[cat] = category_counts.get(cat, 0) + 1
        
        top_categories = sorted(
            category_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        return {
            "total_count": total_count,
            "average_quality": round(avg_quality, 2),
            "total_ted_count": unique_teds,
            "top_categories": [{"category": cat, "count": count} for cat, count in top_categories]
        }
    
    # ========== å·¥å…·æ–¹æ³• ==========
    
    @staticmethod
    def _hash_url(url: str) -> str:
        """ç”ŸæˆURLçš„hashå€¼ä½œä¸ºkey
        
        Args:
            url: URLå­—ç¬¦ä¸²
            
        Returns:
            SHA256 hashçš„å‰16ä½
        """
        return hashlib.sha256(url.encode()).hexdigest()[:16]
```

#### æ­¥éª¤2.2: åˆ›å»ºStoreå·¥å‚å‡½æ•°

**æ–‡ä»¶**: `backend/app/memory/store_factory.py` (æ–°å»º)

```python
"""Store Factory - æ ¹æ®é…ç½®åˆ›å»ºStoreå®ä¾‹"""

import os
from typing import Optional
from langgraph.store.base import BaseStore
from langgraph.store.memory import InMemoryStore

def create_store() -> BaseStore:
    """æ ¹æ®ç¯å¢ƒå˜é‡åˆ›å»ºStoreå®ä¾‹
    
    Returns:
        Storeå®ä¾‹ï¼ˆInMemoryStoreæˆ–PostgresStoreï¼‰
    """
    store_type = os.getenv("MEMORY_STORE_TYPE", "inmemory").lower()
    
    if store_type == "postgres":
        # ç”Ÿäº§ç¯å¢ƒï¼šPostgresStore
        from langgraph.store.postgres import PostgresStore
        
        postgres_uri = os.getenv("POSTGRES_URI")
        if not postgres_uri:
            raise ValueError("POSTGRES_URIç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        print(f"[Memory] ä½¿ç”¨PostgresStore: {postgres_uri}")
        return PostgresStore(conn=postgres_uri)
    
    else:
        # å¼€å‘ç¯å¢ƒï¼šInMemoryStore
        print("[Memory] ä½¿ç”¨InMemoryStoreï¼ˆå¼€å‘ç¯å¢ƒï¼‰")
        
        # TODO: å¯é€‰æ·»åŠ embeddingæ”¯æŒ
        # embedding_model = os.getenv("MEMORY_EMBEDDING_MODEL", "text-embedding-3-small")
        # def embed(texts):
        #     return openai.embeddings.create(model=embedding_model, input=texts)
        
        return InMemoryStore()

# å…¨å±€Storeå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_global_store: Optional[BaseStore] = None

def get_global_store() -> BaseStore:
    """è·å–å…¨å±€Storeå®ä¾‹ï¼ˆå•ä¾‹ï¼‰
    
    Returns:
        å…¨å±€Storeå®ä¾‹
    """
    global _global_store
    
    if _global_store is None:
        _global_store = create_store()
    
    return _global_store
```

#### æ­¥éª¤2.3: æ›´æ–°Memoryæ¨¡å—å¯¼å‡º

**æ–‡ä»¶**: `backend/app/memory/__init__.py`

```python
"""Memoryæ¨¡å— - LangGraph Storeå°è£…

æä¾›ç»Ÿä¸€çš„Memoryç®¡ç†æ¥å£
"""

from app.memory.service import MemoryService
from app.memory.store_factory import create_store, get_global_store

__all__ = [
    "MemoryService",
    "create_store",
    "get_global_store"
]
```

---

### é˜¶æ®µ3: Communication Agenté›†æˆMemory

#### æ­¥éª¤3.1: æ›´æ–°Communication Agent - æœç´¢èŠ‚ç‚¹

**æ–‡ä»¶**: `backend/app/agents/serial/communication.py`

ä¿®æ”¹`communication_agent`å‡½æ•°ï¼Œé›†æˆseen_urlsè¿‡æ»¤å’Œsearch_historyè®°å½•ï¼š

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from app.memory import MemoryService, get_global_store
import time

def communication_agent(state: Shadow_Writing_State) -> Shadow_Writing_State:
    """é€šä¿¡èŠ‚ç‚¹ - æœç´¢TEDæ¼”è®²ï¼ˆé›†æˆMemoryï¼‰"""
    topic = state.get("topic", "")
    user_id = state.get("user_id", "default_user")
    
    print(f"\n[COMMUNICATION NODE] æœç´¢TEDæ¼”è®²")
    print(f"   ç”¨æˆ·: {user_id}")
    print(f"   ä¸»é¢˜: {topic}")
    
    if not topic:
        return {
            "errors": ["æœªæä¾›æœç´¢ä¸»é¢˜"],
            "processing_logs": ["é€šä¿¡èŠ‚ç‚¹: ç¼ºå°‘topicå‚æ•°"]
        }
    
    try:
        # ã€æ–°å¢ã€‘æ­¥éª¤1 - ä»MemoryåŠ è½½ç”¨æˆ·å†å²
        memory_service = MemoryService(store=get_global_store())
        seen_urls = memory_service.get_seen_ted_urls(user_id)
        print(f"   ç”¨æˆ·å·²çœ‹è¿‡ {len(seen_urls)} ä¸ªTEDæ¼”è®²")
        
        # è®°å½•æœç´¢å¼€å§‹æ—¶é—´
        search_start = time.time()
        
        # æ­¥éª¤2 - LLMä¼˜åŒ–æœç´¢è¯
        optimized_query = optimize_search_query(topic)
        
        # æ­¥éª¤3 - æœç´¢TEDæ¼”è®²
        print(f"   æœç´¢ä¸­: {optimized_query}")
        results = ted_tavily_search(optimized_query, max_results=10)
        
        if not results:
            print(f"   æœªæ‰¾åˆ°ç»“æœ")
            return {
                "errors": [f"æœªæ‰¾åˆ°å…³äº '{topic}' çš„TEDæ¼”è®²"],
                "processing_logs": ["é€šä¿¡èŠ‚ç‚¹: æœç´¢æ— ç»“æœ"]
            }
        
        # ã€ä¿®æ”¹ã€‘æ­¥éª¤4 - è¿‡æ»¤å·²çœ‹è¿‡çš„æ¼”è®²ï¼ˆä½¿ç”¨Memoryï¼‰
        new_results = [r for r in results if r.get('url') not in seen_urls]
        filtered_count = len(results) - len(new_results)
        
        print(f"   æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        print(f"   è¿‡æ»¤å·²çœ‹: {filtered_count} ä¸ª")
        print(f"   æ–°æ¼”è®²: {len(new_results)} ä¸ª")
        
        # æ­¥éª¤5 - å¦‚æœç»“æœä¸è¶³ï¼Œå°è¯•æ›¿ä»£æœç´¢
        alternative_queries_used = []
        if len(new_results) < 3:
            print(f"   ç»“æœä¸è¶³ï¼Œå°è¯•æ›¿ä»£æœç´¢...")
            alternative_queries = generate_alternative_queries(topic)
            
            for alt_query in alternative_queries[:2]:
                if not alt_query:
                    continue
                print(f"   å°è¯•æ›¿ä»£è¯: {alt_query}")
                alternative_queries_used.append(alt_query)
                
                alt_results = ted_tavily_search(alt_query, max_results=5)
                
                # å»é‡åæ·»åŠ 
                for r in alt_results:
                    if r.get('url') not in seen_urls and r not in new_results:
                        new_results.append(r)
                
                if len(new_results) >= 5:
                    break
        
        # æ­¥éª¤6 - è¿”å›ç»“æœå‰è®°å½•æœç´¢å†å²
        search_duration_ms = int((time.time() - search_start) * 1000)
        
        if len(new_results) == 0:
            # ã€æ–°å¢ã€‘è®°å½•æ— ç»“æœçš„æœç´¢
            memory_service.add_search_history(
                user_id=user_id,
                original_query=topic,
                optimized_query=optimized_query,
                alternative_queries=alternative_queries_used,
                results_count=0,
                new_results=0,
                filtered_seen=filtered_count,
                search_duration_ms=search_duration_ms
            )
            
            return {
                "errors": [f"æœªæ‰¾åˆ°å…³äº '{topic}' çš„æ–°TEDæ¼”è®²ï¼ˆå·²çœ‹è¿‡{filtered_count}ä¸ªï¼‰"],
                "processing_logs": [f"é€šä¿¡èŠ‚ç‚¹: æ— æ–°ç»“æœ"]
            }
        
        final_results = new_results[:5]
        print(f"   è¿”å› {len(final_results)} ä¸ªå€™é€‰æ¼”è®²")
        
        # ã€æ–°å¢ã€‘è®°å½•æœç´¢å†å²ï¼ˆé€‰æ‹©å‰ï¼‰
        search_record_id = memory_service.add_search_history(
            user_id=user_id,
            original_query=topic,
            optimized_query=optimized_query,
            alternative_queries=alternative_queries_used,
            results_count=len(final_results),
            new_results=len(new_results),
            filtered_seen=filtered_count,
            search_duration_ms=search_duration_ms
        )
        
        return {
            "ted_candidates": final_results,
            "awaiting_user_selection": True,
            "search_context": {
                "original_topic": topic,
                "optimized_query": optimized_query,
                "seen_count": len(seen_urls),
                "search_record_id": search_record_id  # ä¿å­˜è®°å½•IDï¼Œç”¨äºåç»­æ›´æ–°
            },
            "processing_logs": [f"é€šä¿¡èŠ‚ç‚¹: æ‰¾åˆ° {len(final_results)} ä¸ªå€™é€‰æ¼”è®²"]
        }
        
    except Exception as e:
        print(f"   é”™è¯¯: {e}")
        return {
            "errors": [f"é€šä¿¡èŠ‚ç‚¹å‡ºé”™: {e}"],
            "processing_logs": ["é€šä¿¡èŠ‚ç‚¹: æœç´¢å¤±è´¥"]
        }
```

#### æ­¥éª¤3.2: æ›´æ–°Communication Continue Agent - é€‰æ‹©å¤„ç†èŠ‚ç‚¹

**æ–‡ä»¶**: `backend/app/agents/serial/communication.py`

ä¿®æ”¹`communication_continue_agent`å‡½æ•°ï¼Œä¿å­˜TEDè§‚çœ‹è®°å½•ï¼š

```python
def communication_continue_agent(state: Shadow_Writing_State) -> Shadow_Writing_State:
    """é€šä¿¡èŠ‚ç‚¹ - å¤„ç†ç”¨æˆ·é€‰æ‹©ï¼ˆé›†æˆMemoryï¼‰"""
    selected_url = state.get("selected_ted_url", "")
    user_id = state.get("user_id", "default_user")
    search_context = state.get("search_context", {})
    
    print(f"\n[COMMUNICATION NODE] å¤„ç†ç”¨æˆ·é€‰æ‹©")
    print(f"   URL: {selected_url}")
    
    if not selected_url:
        return {
            "errors": ["æœªæä¾›é€‰æ‹©çš„TED URL"],
            "processing_logs": ["é€šä¿¡èŠ‚ç‚¹: ç¼ºå°‘selected_ted_urlå‚æ•°"]
        }
    
    try:
        # æ­¥éª¤1 - æå–transcript
        print(f"   çˆ¬å–transcript...")
        ted_data = extract_ted_transcript(selected_url)
        
        if not ted_data:
            return {
                "errors": ["æå–transcriptå¤±è´¥"],
                "processing_logs": ["é€šä¿¡èŠ‚ç‚¹: transcriptæå–å¤±è´¥"]
            }
        
        # æ­¥éª¤2 - ä¿å­˜æ–‡ä»¶
        print(f"   ä¿å­˜æ–‡ä»¶...")
        file_manager = TEDFileManager()
        filepath = file_manager.save_ted_file(ted_data)
        
        # ã€æ–°å¢ã€‘æ­¥éª¤3 - ä¿å­˜åˆ°TEDè§‚çœ‹å†å²
        print(f"   ä¿å­˜åˆ°Memory...")
        memory_service = MemoryService(store=get_global_store())
        
        memory_service.add_seen_ted(
            user_id=user_id,
            url=ted_data.url,
            title=ted_data.title,
            speaker=ted_data.speaker,
            search_topic=search_context.get("original_topic", ""),
            chunks_processed=0,  # åˆå§‹å€¼ï¼Œåç»­æ›´æ–°
            shadow_writing_count=0,  # åˆå§‹å€¼ï¼Œåç»­æ›´æ–°
            metadata={
                "ted_duration": getattr(ted_data, 'duration', ''),
                "ted_views": getattr(ted_data, 'views', ''),
                "transcript_length": len(ted_data.transcript)
            }
        )
        
        # ã€å¯é€‰ã€‘æ›´æ–°æœç´¢å†å²çš„selected_url
        # TODO: å®ç°update_search_historyæ–¹æ³•
        
        # æ­¥éª¤4 - ä¼ é€’ç»™ä¸‹æ¸¸èŠ‚ç‚¹
        print(f"   å‡†å¤‡ä¼ é€’ç»™ä¸‹æ¸¸èŠ‚ç‚¹")
        print(f"   æ ‡é¢˜: {ted_data.title}")
        print(f"   æ¼”è®²è€…: {ted_data.speaker}")
        print(f"   Transcripté•¿åº¦: {len(ted_data.transcript)} å­—ç¬¦")
        
        return {
            "file_path": filepath,
            "text": ted_data.transcript,
            "ted_title": ted_data.title,
            "ted_speaker": ted_data.speaker,
            "ted_url": ted_data.url,
            "awaiting_user_selection": False,
            "processing_logs": [f"é€šä¿¡èŠ‚ç‚¹: æˆåŠŸå¤„ç† {ted_data.title}"]
        }
        
    except Exception as e:
        print(f"   é”™è¯¯: {e}")
        return {
            "errors": [f"é€šä¿¡èŠ‚ç‚¹å¤„ç†å¤±è´¥: {e}"],
            "processing_logs": ["é€šä¿¡èŠ‚ç‚¹: å¤„ç†å‡ºé”™"]
        }
```

---

### é˜¶æ®µ4: Learning Recordsåå°ä¿å­˜

#### æ­¥éª¤4.1: åˆ›å»ºMemoryä¿å­˜èŠ‚ç‚¹

**æ–‡ä»¶**: `backend/app/agents/parallel/memory_agent.py` (æ–°å»º)

```python
"""Memory Agent - åå°ä¿å­˜å­¦ä¹ è®°å½•

åœ¨åå°å¼‚æ­¥ä¿å­˜Shadow Writingå­¦ä¹ è®°å½•åˆ°Memory
"""

from typing import List
from app.state import Shadow_Writing_State
from app.models import Ted_Shadows
from app.memory import MemoryService, get_global_store

def save_learning_records_node(state: Shadow_Writing_State) -> dict:
    """ä¿å­˜å­¦ä¹ è®°å½•åˆ°Memoryï¼ˆåå°ä»»åŠ¡ï¼‰
    
    åœ¨å·¥ä½œæµå®Œæˆåï¼Œæ‰¹é‡ä¿å­˜æ‰€æœ‰Shadow Writingç»“æœåˆ°Memory
    
    Args:
        state: å·¥ä½œæµçŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    user_id = state.get("user_id", "default_user")
    ted_url = state.get("ted_url", "")
    ted_title = state.get("ted_title", "")
    final_chunks = state.get("final_shadow_chunks", [])
    
    if not final_chunks:
        print("[MEMORY] æ— å­¦ä¹ è®°å½•éœ€è¦ä¿å­˜")
        return {"processing_logs": ["Memory: æ— å­¦ä¹ è®°å½•"]}
    
    try:
        print(f"\n[MEMORY] ä¿å­˜å­¦ä¹ è®°å½•åˆ°Memory")
        print(f"   ç”¨æˆ·: {user_id}")
        print(f"   TED: {ted_title}")
        print(f"   è®°å½•æ•°: {len(final_chunks)}")
        
        memory_service = MemoryService(store=get_global_store())
        saved_count = 0
        
        for chunk in final_chunks:
            # å¤„ç†chunkå¯èƒ½æ˜¯å¯¹è±¡æˆ–å­—å…¸
            if isinstance(chunk, dict):
                chunk_data = chunk
            elif hasattr(chunk, 'model_dump'):
                chunk_data = chunk.model_dump()
            elif hasattr(chunk, 'dict'):
                chunk_data = chunk.dict()
            else:
                continue
            
            # ä¿å­˜åˆ°Memory
            record_id = memory_service.add_learning_record(
                user_id=user_id,
                ted_url=ted_url,
                ted_title=ted_title,
                original_sentence=chunk_data.get("original", ""),
                imitation=chunk_data.get("imitation", ""),
                word_map=chunk_data.get("map", {}),
                quality_score=chunk_data.get("quality_score", 0.0),
                quality_details={},  # TODO: æ·»åŠ è¯¦ç»†è´¨é‡è¯„ä¼°
                paragraph=chunk_data.get("paragraph", ""),
                processing_time_ms=0,  # TODO: æ·»åŠ æ—¶é—´è¿½è¸ª
                semantic_categories=[]  # TODO: æ·»åŠ è¯­ä¹‰åˆ†ç±»
            )
            saved_count += 1
        
        print(f"   æˆåŠŸä¿å­˜ {saved_count} æ¡å­¦ä¹ è®°å½•")
        
        return {
            "processing_logs": [f"Memory: ä¿å­˜{saved_count}æ¡å­¦ä¹ è®°å½•"]
        }
        
    except Exception as e:
        print(f"   ä¿å­˜å¤±è´¥: {e}")
        return {
            "errors": [f"Memoryä¿å­˜å¤±è´¥: {e}"],
            "processing_logs": ["Memory: ä¿å­˜å‡ºé”™"]
        }
```

#### æ­¥éª¤4.2: é›†æˆåˆ°å·¥ä½œæµ

**æ–‡ä»¶**: `backend/app/workflows.py`

åœ¨å¹¶è¡Œå·¥ä½œæµçš„æœ€åæ·»åŠ Memoryä¿å­˜èŠ‚ç‚¹ï¼š

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from app.agents.parallel.memory_agent import save_learning_records_node

def create_parallel_shadow_writing_workflow():
    """åˆ›å»ºå¹¶è¡ŒShadow Writingå·¥ä½œæµï¼ˆé›†æˆMemoryï¼‰"""
    
    # ... ç°æœ‰ä»£ç  ...
    
    # æ·»åŠ Memoryä¿å­˜èŠ‚ç‚¹
    workflow.add_node("save_memory", save_learning_records_node)
    
    # ä¿®æ”¹è¾¹ï¼šaggregate_results â†’ save_memory â†’ END
    workflow.add_edge("aggregate_results", "save_memory")
    workflow.add_edge("save_memory", END)
    
    return workflow.compile()
```

---

### é˜¶æ®µ5: APIæ¥å£å±‚é›†æˆ

#### æ­¥éª¤5.1: æ·»åŠ MemoryæŸ¥è¯¢API

**æ–‡ä»¶**: `backend/app/main.py`

æ·»åŠ æ–°çš„APIç«¯ç‚¹ç”¨äºæŸ¥è¯¢Memoryï¼š

```python
from app.memory import MemoryService, get_global_store

# ... ç°æœ‰ä»£ç  ...

@app.get("/api/memory/ted-history")
async def get_ted_history(user_id: str = "default_user"):
    """è·å–ç”¨æˆ·çš„TEDè§‚çœ‹å†å²"""
    try:
        memory_service = MemoryService(store=get_global_store())
        seen_urls = memory_service.get_seen_ted_urls(user_id)
        
        return {
            "success": True,
            "user_id": user_id,
            "seen_count": len(seen_urls),
            "seen_urls": list(seen_urls)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/memory/search-history")
async def get_search_history(
    user_id: str = "default_user",
    limit: int = 10
):
    """è·å–ç”¨æˆ·çš„æœç´¢å†å²"""
    try:
        memory_service = MemoryService(store=get_global_store())
        history = memory_service.get_recent_searches(user_id, limit)
        
        return {
            "success": True,
            "user_id": user_id,
            "history": history
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/memory/learning-records")
async def get_learning_records(
    user_id: str = "default_user",
    ted_url: Optional[str] = None,
    min_quality_score: Optional[float] = None,
    limit: int = 50
):
    """è·å–ç”¨æˆ·çš„å­¦ä¹ è®°å½•"""
    try:
        memory_service = MemoryService(store=get_global_store())
        records = memory_service.get_learning_records(
            user_id=user_id,
            ted_url=ted_url,
            min_quality_score=min_quality_score,
            limit=limit
        )
        
        return {
            "success": True,
            "user_id": user_id,
            "count": len(records),
            "records": records
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/memory/learning-stats")
async def get_learning_stats(user_id: str = "default_user"):
    """è·å–ç”¨æˆ·çš„å­¦ä¹ ç»Ÿè®¡"""
    try:
        memory_service = MemoryService(store=get_global_store())
        stats = memory_service.get_learning_stats(user_id)
        
        return {
            "success": True,
            "user_id": user_id,
            "stats": stats
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }
```

---

### é˜¶æ®µ6: æµ‹è¯•ä¸éªŒè¯

#### æ­¥éª¤6.1: åˆ›å»ºMemoryæµ‹è¯•è„šæœ¬

**æ–‡ä»¶**: `backend/tests/test_memory.py` (æ–°å»º)

```python
"""Memory Serviceæµ‹è¯•"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from app.memory import MemoryService
from langgraph.store.memory import InMemoryStore

def test_seen_urls():
    """æµ‹è¯•TEDè§‚çœ‹å†å²åŠŸèƒ½"""
    print("\n=== æµ‹è¯•1: TEDè§‚çœ‹å†å² ===")
    
    store = InMemoryStore()
    memory_service = MemoryService(store=store)
    user_id = "test_user_1"
    
    # æ·»åŠ è§‚çœ‹è®°å½•
    memory_service.add_seen_ted(
        user_id=user_id,
        url="https://ted.com/talks/test1",
        title="Test Talk 1",
        speaker="Speaker 1",
        search_topic="leadership",
        chunks_processed=10,
        shadow_writing_count=8
    )
    
    memory_service.add_seen_ted(
        user_id=user_id,
        url="https://ted.com/talks/test2",
        title="Test Talk 2",
        speaker="Speaker 2",
        search_topic="innovation",
        chunks_processed=15,
        shadow_writing_count=12
    )
    
    # è·å–è§‚çœ‹å†å²
    seen_urls = memory_service.get_seen_ted_urls(user_id)
    print(f"ç”¨æˆ· {user_id} çœ‹è¿‡çš„TEDæ•°é‡: {len(seen_urls)}")
    print(f"URLåˆ—è¡¨: {seen_urls}")
    
    # æ£€æŸ¥æ˜¯å¦å·²çœ‹è¿‡
    is_seen = memory_service.is_ted_seen(user_id, "https://ted.com/talks/test1")
    print(f"æ˜¯å¦çœ‹è¿‡test1: {is_seen}")
    
    is_seen2 = memory_service.is_ted_seen(user_id, "https://ted.com/talks/test3")
    print(f"æ˜¯å¦çœ‹è¿‡test3: {is_seen2}")
    
    assert len(seen_urls) == 2
    assert is_seen == True
    assert is_seen2 == False
    print("âœ“ TEDè§‚çœ‹å†å²æµ‹è¯•é€šè¿‡")

def test_search_history():
    """æµ‹è¯•æœç´¢å†å²åŠŸèƒ½"""
    print("\n=== æµ‹è¯•2: æœç´¢å†å² ===")
    
    store = InMemoryStore()
    memory_service = MemoryService(store=store)
    user_id = "test_user_2"
    
    # æ·»åŠ æœç´¢è®°å½•
    record_id1 = memory_service.add_search_history(
        user_id=user_id,
        original_query="leadership",
        optimized_query="effective leadership strategies",
        alternative_queries=["team management", "leadership skills"],
        results_count=5,
        selected_url="https://ted.com/talks/test1",
        selected_title="Test Talk 1",
        new_results=5,
        filtered_seen=2,
        search_duration_ms=1500
    )
    
    print(f"æœç´¢è®°å½•ID: {record_id1}")
    
    # è·å–æœç´¢å†å²
    history = memory_service.get_recent_searches(user_id, limit=10)
    print(f"æœç´¢å†å²æ•°é‡: {len(history)}")
    print(f"æœ€è¿‘æœç´¢: {history[0]['original_query']}")
    
    assert len(history) == 1
    assert history[0]['original_query'] == "leadership"
    print("âœ“ æœç´¢å†å²æµ‹è¯•é€šè¿‡")

def test_learning_records():
    """æµ‹è¯•å­¦ä¹ è®°å½•åŠŸèƒ½"""
    print("\n=== æµ‹è¯•3: å­¦ä¹ è®°å½• ===")
    
    store = InMemoryStore()
    memory_service = MemoryService(store=store)
    user_id = "test_user_3"
    
    # æ·»åŠ å­¦ä¹ è®°å½•
    record_id = memory_service.add_learning_record(
        user_id=user_id,
        ted_url="https://ted.com/talks/test1",
        ted_title="Test Talk 1",
        original_sentence="Every morning, I take a short walk.",
        imitation="Every evening, I spend time reading.",
        word_map={"Time": ["morning", "evening"], "Action": ["walk", "reading"]},
        quality_score=8.5,
        quality_details={"structure": 3, "naturalness": 3},
        paragraph="Full paragraph text...",
        processing_time_ms=3000,
        semantic_categories=["daily_life", "habits"]
    )
    
    print(f"å­¦ä¹ è®°å½•ID: {record_id}")
    
    # è·å–å­¦ä¹ è®°å½•
    records = memory_service.get_learning_records(user_id, limit=10)
    print(f"å­¦ä¹ è®°å½•æ•°é‡: {len(records)}")
    
    # è·å–ç»Ÿè®¡
    stats = memory_service.get_learning_stats(user_id)
    print(f"å­¦ä¹ ç»Ÿè®¡: {stats}")
    
    assert len(records) == 1
    assert stats['total_count'] == 1
    assert stats['average_quality'] == 8.5
    print("âœ“ å­¦ä¹ è®°å½•æµ‹è¯•é€šè¿‡")

def test_multi_user():
    """æµ‹è¯•å¤šç”¨æˆ·éš”ç¦»"""
    print("\n=== æµ‹è¯•4: å¤šç”¨æˆ·éš”ç¦» ===")
    
    store = InMemoryStore()
    memory_service = MemoryService(store=store)
    
    # ç”¨æˆ·1
    memory_service.add_seen_ted(
        user_id="user1",
        url="https://ted.com/talks/test1",
        title="Talk 1",
        speaker="Speaker 1",
        search_topic="topic1"
    )
    
    # ç”¨æˆ·2
    memory_service.add_seen_ted(
        user_id="user2",
        url="https://ted.com/talks/test2",
        title="Talk 2",
        speaker="Speaker 2",
        search_topic="topic2"
    )
    
    # éªŒè¯éš”ç¦»
    user1_urls = memory_service.get_seen_ted_urls("user1")
    user2_urls = memory_service.get_seen_ted_urls("user2")
    
    print(f"ç”¨æˆ·1çš„TEDæ•°é‡: {len(user1_urls)}")
    print(f"ç”¨æˆ·2çš„TEDæ•°é‡: {len(user2_urls)}")
    
    assert len(user1_urls) == 1
    assert len(user2_urls) == 1
    assert "https://ted.com/talks/test1" in user1_urls
    assert "https://ted.com/talks/test2" in user2_urls
    print("âœ“ å¤šç”¨æˆ·éš”ç¦»æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    test_seen_urls()
    test_search_history()
    test_learning_records()
    test_multi_user()
    
    print("\n" + "="*50)
    print("æ‰€æœ‰Memoryæµ‹è¯•é€šè¿‡ï¼")
    print("="*50)
```

#### æ­¥éª¤6.2: è¿è¡Œæµ‹è¯•

```bash
cd backend
python tests/test_memory.py
```

---

## éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

âœ… **TEDè§‚çœ‹å†å²**
- èƒ½æ­£ç¡®ä¿å­˜ç”¨æˆ·çœ‹è¿‡çš„TED URL
- æœç´¢æ—¶èƒ½è¿‡æ»¤å·²çœ‹è¿‡çš„æ¼”è®²
- æ”¯æŒå¤šç”¨æˆ·æ•°æ®éš”ç¦»

âœ… **æœç´¢å†å²**
- è®°å½•æ¯æ¬¡æœç´¢çš„è¯¦ç»†ä¿¡æ¯
- åŒ…å«æœç´¢è¯ä¼˜åŒ–ã€ç»“æœæ•°é‡ã€è€—æ—¶ç­‰
- æ”¯æŒæŒ‰æ—¶é—´å€’åºæŸ¥è¯¢

âœ… **å­¦ä¹ è®°å½•**
- æ‰¹é‡ä¿å­˜Shadow Writingç»“æœ
- æ”¯æŒæŒ‰TED URLã€è´¨é‡åˆ†æ•°è¿‡æ»¤
- æä¾›å­¦ä¹ ç»Ÿè®¡ï¼ˆæ€»æ•°ã€å¹³å‡è´¨é‡ã€åˆ†ç±»ç»Ÿè®¡ï¼‰

âœ… **APIæ¥å£**
- æä¾›MemoryæŸ¥è¯¢æ¥å£
- è¿”å›æ ‡å‡†åŒ–JSONæ ¼å¼
- é”™è¯¯å¤„ç†å®Œå–„

### æ€§èƒ½éªŒæ”¶

âœ… **å†™å…¥æ€§èƒ½**
- å•æ¬¡å†™å…¥è€—æ—¶<50msï¼ˆInMemoryStoreï¼‰
- æ‰¹é‡å†™å…¥100æ¡<5ç§’

âœ… **è¯»å–æ€§èƒ½**
- æŸ¥è¯¢seen_urlsè€—æ—¶<100ms
- æŸ¥è¯¢å­¦ä¹ è®°å½•ï¼ˆ50æ¡ï¼‰è€—æ—¶<200ms

âœ… **å¹¶å‘æ€§èƒ½**
- æ”¯æŒå¤šç”¨æˆ·å¹¶å‘è®¿é—®
- æ— æ•°æ®ç«äº‰é—®é¢˜

### å¯é æ€§éªŒæ”¶

âœ… **æ•°æ®æŒä¹…åŒ–**
- PostgresStoreæ­£ç¡®æŒä¹…åŒ–æ•°æ®
- é‡å¯æœåŠ¡åæ•°æ®ä¸ä¸¢å¤±

âœ… **é”™è¯¯å¤„ç†**
- Memoryæ“ä½œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹
- æä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯

---

## å®æ–½é¡ºåº

### ç¬¬1å‘¨ï¼šåŸºç¡€è®¾æ–½
1. Day 1-2: ç¯å¢ƒå‡†å¤‡ï¼ˆé˜¶æ®µ1ï¼‰
2. Day 3-4: Memory Serviceå®ç°ï¼ˆé˜¶æ®µ2ï¼‰
3. Day 5: å•å…ƒæµ‹è¯•

### ç¬¬2å‘¨ï¼šAgenté›†æˆ
1. Day 1-3: Communication Agenté›†æˆï¼ˆé˜¶æ®µ3ï¼‰
2. Day 4-5: Learning Recordsä¿å­˜ï¼ˆé˜¶æ®µ4ï¼‰

### ç¬¬3å‘¨ï¼šAPIä¸æµ‹è¯•
1. Day 1-2: APIæ¥å£å®ç°ï¼ˆé˜¶æ®µ5ï¼‰
2. Day 3-4: é›†æˆæµ‹è¯•
3. Day 5: æ€§èƒ½ä¼˜åŒ–

---

## æœªæ¥ä¼˜åŒ–æ–¹å‘

### 1. è¯­ä¹‰æœç´¢å¢å¼º
- æ·»åŠ embeddingæ”¯æŒ
- å®ç°åŸºäºè¯­ä¹‰çš„å­¦ä¹ è®°å½•æ£€ç´¢
- "æ‰¾åˆ°ç±»ä¼¼leadershipä¸»é¢˜çš„å­¦ä¹ è®°å½•"

### 2. æ™ºèƒ½æ¨è
- åŸºäºå­¦ä¹ è®°å½•æ¨èç›¸å…³TED
- "ä½ å–œæ¬¢leadershipè¯é¢˜ï¼Œæ¨èè¿™ä¸ªæ¼”è®²"
- ä¸ªæ€§åŒ–éš¾åº¦è°ƒæ•´

### 3. å­¦ä¹ åˆ†æ
- å­¦ä¹ æ›²çº¿å¯è§†åŒ–
- å¼±é¡¹åˆ†æï¼ˆè´¨é‡åˆ†æ•°ä½çš„åˆ†ç±»ï¼‰
- å­¦ä¹ å»ºè®®ç”Ÿæˆ

### 4. MemoryåŒæ­¥
- è·¨è®¾å¤‡MemoryåŒæ­¥
- å¯¼å‡º/å¯¼å…¥åŠŸèƒ½
- å¤‡ä»½ä¸æ¢å¤

---

**LangGraph Memoryç³»ç»Ÿå®æ–½è®¡åˆ’å®Œæˆï¼é¢„æœŸå®ç°å®Œæ•´çš„ç”¨æˆ·è®°å¿†åŠŸèƒ½** ğŸ§ 

---

# Memoryç³»ç»Ÿå®ç°æ€»ç»“ï¼ˆ2025-10-09ï¼‰

## å®æ–½å®Œæˆæƒ…å†µ

### å·²å®Œæˆæ–‡ä»¶

```
backend/app/memory/
â”œâ”€â”€ __init__.py                    # æ¨¡å—å¯¼å‡º âœ…
â”œâ”€â”€ base_memory.py                 # åŸºç¡€Memoryç±»ï¼ˆ32è¡Œï¼‰âœ…
â”œâ”€â”€ ted_history_memory.py          # TEDè§‚çœ‹å†å²ï¼ˆ130è¡Œï¼‰âœ…
â”œâ”€â”€ search_history_memory.py       # æœç´¢å†å²ï¼ˆ110è¡Œï¼‰âœ…
â”œâ”€â”€ learning_records_memory.py     # å­¦ä¹ è®°å½•ï¼ˆç©ºç™½æ¡†æ¶ï¼‰âœ…
â”œâ”€â”€ store_factory.py               # Storeå·¥å‚ï¼ˆ56è¡Œï¼‰âœ…
â””â”€â”€ service.py                     # ç»Ÿä¸€æœåŠ¡å…¥å£ï¼ˆ157è¡Œï¼‰âœ…

backend/tests/
â””â”€â”€ test_memory.py                 # å®Œæ•´æµ‹è¯•æ–‡ä»¶ï¼ˆ215è¡Œï¼‰âœ…
```

### ä»£ç ç»Ÿè®¡

- **æ€»æ–‡ä»¶æ•°**: 8ä¸ª
- **æ€»ä»£ç è¡Œæ•°**: ~700è¡Œ
- **æµ‹è¯•è¦†ç›–**: 5ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œå…¨éƒ¨é€šè¿‡ âœ…

---

## æ¶æ„è®¾è®¡

### æ¨¡å—åŒ–æ‹†åˆ†æ–¹æ¡ˆ

é‡‡ç”¨**æ‹†åˆ†æ–¹æ¡ˆ**æ›¿ä»£å•æ–‡ä»¶450è¡Œçš„è®¾è®¡ï¼š

| æ–¹æ¡ˆ | ä¼˜åŠ¿ |
|------|------|
| **èŒè´£åˆ†ç¦»** | æ¯ä¸ªMemoryç±»å•ä¸€èŒè´£ï¼Œç¬¦åˆSOLIDåŸåˆ™ |
| **æ–‡ä»¶å°å·§** | æ¯ä¸ªæ–‡ä»¶<200è¡Œï¼Œä¾¿äºé˜…è¯»å’Œç»´æŠ¤ |
| **ç‹¬ç«‹æµ‹è¯•** | å¯ä»¥ç‹¬ç«‹æµ‹è¯•æ¯ä¸ªMemoryç±»å‹ |
| **æ˜“äºæ‰©å±•** | æ·»åŠ æ–°Memoryç±»å‹ä¸å½±å“ç°æœ‰ä»£ç  |
| **å›¢é˜Ÿåä½œ** | ä¸åŒäººå¯å¹¶è¡Œå¼€å‘ä¸åŒMemoryç±»å‹ |

### è®¾è®¡æ¨¡å¼

1. **Facadeæ¨¡å¼**: `MemoryService`ä½œä¸ºç»Ÿä¸€å…¥å£
2. **å•ä¾‹æ¨¡å¼**: `get_global_store()`å…¨å±€Storeå®ä¾‹
3. **ç»§æ‰¿æ¨¡å¼**: æ‰€æœ‰Memoryç±»ç»§æ‰¿`BaseMemory`

---

## æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. TEDè§‚çœ‹å†å²ï¼ˆTEDHistoryMemoryï¼‰

**ç”¨é€”**: å»é‡è¿‡æ»¤ï¼Œé¿å…é‡å¤æ¨è

**æ ¸å¿ƒæ–¹æ³•**:
```python
get_seen_urls(user_id)          # è·å–å·²çœ‹è¿‡çš„URLé›†åˆ
add_seen_ted(...)               # æ·»åŠ è§‚çœ‹è®°å½•
is_seen(user_id, url)           # æ£€æŸ¥æ˜¯å¦å·²çœ‹è¿‡
get_ted_info(user_id, url)      # è·å–è¯¦ç»†ä¿¡æ¯
update_processing_stats(...)    # æ›´æ–°å¤„ç†ç»Ÿè®¡
```

**Namespace**: `(user_id, "ted_history")`

**è§¦å‘æ—¶æœº**: ç”¨æˆ·é€‰æ‹©TEDæ¼”è®²åç«‹å³ä¿å­˜

### 2. æœç´¢å†å²ï¼ˆSearchHistoryMemoryï¼‰

**ç”¨é€”**: åˆ†ææœç´¢è¡Œä¸ºï¼Œä¼˜åŒ–æœç´¢ä½“éªŒ

**æ ¸å¿ƒæ–¹æ³•**:
```python
add_search(...)                 # æ·»åŠ æœç´¢è®°å½•
get_recent_searches(...)        # è·å–æœ€è¿‘æœç´¢
update_selected_url(...)        # æ›´æ–°ç”¨æˆ·é€‰æ‹©
```

**Namespace**: `(user_id, "search_history")`

**è§¦å‘æ—¶æœº**: æ‰§è¡Œæœç´¢æ—¶ç«‹å³è®°å½•

**è®°å½•å†…å®¹**: åŸå§‹æœç´¢è¯ã€ä¼˜åŒ–åæœç´¢è¯ã€ç»“æœæ•°é‡ã€è¿‡æ»¤ç»Ÿè®¡ã€è€—æ—¶ç­‰

### 3. ä¸¤è€…åŒºåˆ«è¯´æ˜

| ç»´åº¦ | TEDè§‚çœ‹å†å² | æœç´¢å†å² |
|------|------------|---------|
| **è®°å½•å¯¹è±¡** | ç”¨æˆ·**ç¡®è®¤è§‚çœ‹**çš„TED | ç”¨æˆ·çš„**æœç´¢è¡Œä¸º** |
| **è§¦å‘æ—¶æœº** | ç”¨æˆ·é€‰æ‹©æŸä¸ªTEDå | ç”¨æˆ·æ‰§è¡Œæœç´¢æ—¶ |
| **ä¸»è¦ç”¨é€”** | å»é‡è¿‡æ»¤ | åˆ†æä¼˜åŒ– |
| **æ•°æ®ç²’åº¦** | TEDæ¼”è®²ç²’åº¦ | æœç´¢äº‹ä»¶ç²’åº¦ |
| **ç”Ÿå‘½å‘¨æœŸ** | æ°¸ä¹…ä¿å­˜ | å¯å®šæœŸæ¸…ç† |

**ç±»æ¯”**: TEDè§‚çœ‹å†å² = è®¢å•å†å²ï¼Œæœç´¢å†å² = æœç´¢è®°å½•

---

## æµ‹è¯•éªŒè¯

### æµ‹è¯•ç”¨ä¾‹

```bash
python backend/tests/test_memory.py
```

**æµ‹è¯•ç»“æœ**: 5ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡ âœ…

1. âœ… **test_seen_urls**: TEDè§‚çœ‹å†å²åŠŸèƒ½
   - æ·»åŠ 2ä¸ªè§‚çœ‹è®°å½•
   - è·å–URLé›†åˆ
   - æ£€æŸ¥æ˜¯å¦å·²çœ‹è¿‡
   - è·å–è¯¦ç»†ä¿¡æ¯

2. âœ… **test_search_history**: æœç´¢å†å²åŠŸèƒ½
   - æ·»åŠ 2ä¸ªæœç´¢è®°å½•
   - è·å–æœ€è¿‘æœç´¢ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
   - æ›´æ–°ç”¨æˆ·é€‰æ‹©

3. âœ… **test_multi_user**: å¤šç”¨æˆ·éš”ç¦»
   - ä¸¤ä¸ªç”¨æˆ·å„è‡ªæ·»åŠ è®°å½•
   - éªŒè¯namespaceéš”ç¦»

4. âœ… **test_update_processing_stats**: æ›´æ–°å¤„ç†ç»Ÿè®¡
   - åˆå§‹æ·»åŠ è®°å½•
   - æ›´æ–°chunkså’Œshadow_writingæ•°é‡

5. âœ… **test_learning_records_not_implemented**: å­¦ä¹ è®°å½•æ¥å£
   - éªŒè¯æŠ›å‡ºNotImplementedError

---

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from app.memory import MemoryService, get_global_store

# åˆ›å»ºMemoryæœåŠ¡
memory_service = MemoryService(store=get_global_store())

# 1. TEDè§‚çœ‹å†å²
memory_service.add_seen_ted(
    user_id="user_123",
    url="https://ted.com/talks/leadership",
    title="How to be a great leader",
    speaker="Simon Sinek",
    search_topic="leadership"
)

seen_urls = memory_service.get_seen_ted_urls("user_123")
is_seen = memory_service.is_ted_seen("user_123", url)

# 2. æœç´¢å†å²
search_id = memory_service.add_search_history(
    user_id="user_123",
    original_query="leadership",
    optimized_query="effective leadership strategies",
    alternative_queries=["team management"],
    results_count=5,
    filtered_seen=0
)

searches = memory_service.get_recent_searches("user_123", limit=10)
```

### Agenté›†æˆï¼ˆå¾…å®æ–½ï¼‰

```python
# Communication Agentä¸­ä½¿ç”¨
def communication_agent(state):
    memory_service = MemoryService(store=get_global_store())
    
    # 1. è·å–å·²çœ‹è¿‡çš„TED
    seen_urls = memory_service.get_seen_ted_urls(user_id)
    
    # 2. æœç´¢å¹¶è¿‡æ»¤
    results = ted_tavily_search(query)
    new_results = [r for r in results if r['url'] not in seen_urls]
    
    # 3. è®°å½•æœç´¢å†å²
    search_id = memory_service.add_search_history(
        user_id=user_id,
        original_query=query,
        optimized_query=optimized_query,
        results_count=len(new_results),
        filtered_seen=len(results) - len(new_results)
    )
    
    return {"ted_candidates": new_results}
```

---

## Storeé…ç½®

### å¼€å‘ç¯å¢ƒï¼ˆå½“å‰ï¼‰

ä½¿ç”¨`InMemoryStore`ï¼Œæ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚

```python
# é»˜è®¤é…ç½®
MEMORY_STORE_TYPE=inmemory
```

### ç”Ÿäº§ç¯å¢ƒï¼ˆå¾…é…ç½®ï¼‰

åˆ‡æ¢åˆ°`PostgresStore`å®ç°æŒä¹…åŒ–ï¼š

```bash
# .env
MEMORY_STORE_TYPE=postgres
POSTGRES_URI=postgresql://user:password@localhost:5432/shadow_writing_db
```

---

## å¾…å®Œæˆå·¥ä½œ

### çŸ­æœŸä»»åŠ¡ï¼ˆæœ¬å‘¨ï¼‰

1. â³ **é›†æˆåˆ°Communication Agent**
   - ä¿®æ”¹`communication_agent`ä½¿ç”¨Memoryè¿‡æ»¤
   - ä¿®æ”¹`communication_continue_agent`ä¿å­˜è§‚çœ‹è®°å½•
   - æµ‹è¯•å»é‡åŠŸèƒ½

2. â³ **æ·»åŠ APIæ¥å£**
   - GET `/api/memory/ted-history`
   - GET `/api/memory/search-history`
   - GET `/api/memory/learning-stats`

3. â³ **ç¯å¢ƒå˜é‡é…ç½®**
   - æ›´æ–°`.env.example`
   - æ·»åŠ MemoryåŠŸèƒ½å¼€å…³

### ä¸­æœŸä»»åŠ¡ï¼ˆä¸‹å‘¨ï¼‰

4. â³ **å®ç°LearningRecordsMemory**
   - ç¡®å®šæ•°æ®ç»“æ„
   - å®ç°æ·»åŠ /æŸ¥è¯¢é€»è¾‘
   - å®ç°å­¦ä¹ ç»Ÿè®¡

5. â³ **æ·»åŠ Memoryä¿å­˜èŠ‚ç‚¹**
   - åˆ›å»º`memory_agent.py`
   - é›†æˆåˆ°workflowæœ«å°¾
   - åå°æ‰¹é‡ä¿å­˜å­¦ä¹ è®°å½•

### é•¿æœŸä¼˜åŒ–

6. â³ **PostgresStoreè¿ç§»**
   - é…ç½®PostgreSQLæ•°æ®åº“
   - åˆ‡æ¢åˆ°æŒä¹…åŒ–å­˜å‚¨
   - æ•°æ®è¿ç§»è„šæœ¬

7. â³ **é«˜çº§åŠŸèƒ½**
   - æ·»åŠ embeddingæ”¯æŒï¼ˆè¯­ä¹‰æœç´¢ï¼‰
   - è·¨è®¾å¤‡åŒæ­¥
   - æ•°æ®å¯¼å‡º/å¯¼å…¥

---

## æŠ€æœ¯äº®ç‚¹

### 1. æ¨¡å—åŒ–è®¾è®¡
- 7ä¸ªå°æ–‡ä»¶ vs 1ä¸ª450è¡Œå¤§æ–‡ä»¶
- æ¯ä¸ªæ–‡ä»¶èŒè´£æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤

### 2. Namespaceéš”ç¦»
```python
(user_id, "ted_history")          # TEDè§‚çœ‹å†å²
(user_id, "search_history")       # æœç´¢å†å²
(user_id, "shadow_writing_records") # å­¦ä¹ è®°å½•
```

### 3. å¤šç”¨æˆ·æ”¯æŒ
- å¤©ç„¶æ”¯æŒå¤šç”¨æˆ·æ•°æ®éš”ç¦»
- ä¸åŒç”¨æˆ·çš„Memoryäº’ä¸å¹²æ‰°

### 4. çµæ´»çš„Storeåç«¯
- å¼€å‘ç¯å¢ƒï¼šInMemoryStore
- ç”Ÿäº§ç¯å¢ƒï¼šPostgresStore
- é€šè¿‡å·¥å‚æ¨¡å¼è½»æ¾åˆ‡æ¢

---

## æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | è¡Œæ•° | èŒè´£ |
|------|------|------|
| `base_memory.py` | 32 | åŸºç¡€ç±»ï¼Œæä¾›hashå·¥å…· |
| `ted_history_memory.py` | 130 | TEDè§‚çœ‹å†å²ç®¡ç† |
| `search_history_memory.py` | 110 | æœç´¢å†å²ç®¡ç† |
| `learning_records_memory.py` | 70 | å­¦ä¹ è®°å½•ï¼ˆç©ºç™½æ¡†æ¶ï¼‰|
| `store_factory.py` | 56 | Storeå·¥å‚å’Œå•ä¾‹ |
| `service.py` | 157 | ç»Ÿä¸€æœåŠ¡å…¥å£ï¼ˆFacadeï¼‰|
| `test_memory.py` | 215 | å®Œæ•´æµ‹è¯•å¥—ä»¶ |

**æ€»è®¡**: ~770è¡Œä»£ç 

---

## éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶ âœ…

- âœ… èƒ½æ­£ç¡®ä¿å­˜ç”¨æˆ·çœ‹è¿‡çš„TED URL
- âœ… æœç´¢æ—¶èƒ½è¿‡æ»¤å·²çœ‹è¿‡çš„æ¼”è®²ï¼ˆå¾…é›†æˆï¼‰
- âœ… æ”¯æŒå¤šç”¨æˆ·æ•°æ®éš”ç¦»
- âœ… è®°å½•æ¯æ¬¡æœç´¢çš„è¯¦ç»†ä¿¡æ¯
- âœ… æ”¯æŒæŒ‰æ—¶é—´å€’åºæŸ¥è¯¢æœç´¢å†å²
- âœ… å­¦ä¹ è®°å½•æ¥å£é¢„ç•™

### ä»£ç è´¨é‡ âœ…

- âœ… æ¨¡å—åŒ–è®¾è®¡ï¼Œæ–‡ä»¶<200è¡Œ
- âœ… èŒè´£æ¸…æ™°ï¼Œå•ä¸€èŒè´£åŸåˆ™
- âœ… å®Œæ•´çš„ç±»å‹æ³¨è§£
- âœ… è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- âœ… å…¨éƒ¨æµ‹è¯•é€šè¿‡

### æ€§èƒ½éªŒæ”¶ â³

- â³ å•æ¬¡å†™å…¥è€—æ—¶<50msï¼ˆå¾…å‹æµ‹ï¼‰
- â³ æŸ¥è¯¢è€—æ—¶<100msï¼ˆå¾…å‹æµ‹ï¼‰
- â³ æ”¯æŒå¹¶å‘è®¿é—®ï¼ˆå¾…æµ‹è¯•ï¼‰

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ä¼˜å…ˆçº§1ï¼ˆæœ¬å‘¨å¿…é¡»å®Œæˆï¼‰

1. **é›†æˆCommunication Agent**
   - ä¿®æ”¹æœç´¢èŠ‚ç‚¹ä½¿ç”¨Memoryè¿‡æ»¤
   - ä¿®æ”¹é€‰æ‹©èŠ‚ç‚¹ä¿å­˜è§‚çœ‹è®°å½•
   - ç«¯åˆ°ç«¯æµ‹è¯•å»é‡åŠŸèƒ½

2. **æ·»åŠ APIæ¥å£**
   - å®ç°æŸ¥è¯¢æ¥å£
   - å‰ç«¯å±•ç¤ºç”¨æˆ·å†å²

### ä¼˜å…ˆçº§2ï¼ˆä¸‹å‘¨å®Œæˆï¼‰

3. **å®ç°LearningRecordsMemory**
   - ç¡®å®šæ•°æ®ç»“æ„
   - å®Œæ•´å®ç°

4. **PostgreSQLé…ç½®**
   - é…ç½®ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“
   - æµ‹è¯•æŒä¹…åŒ–

---

## æ€»ç»“

âœ… **Memoryç³»ç»ŸåŸºç¡€æ¶æ„å·²å®Œæˆ**
- é‡‡ç”¨æ¨¡å—åŒ–æ‹†åˆ†è®¾è®¡
- TEDè§‚çœ‹å†å²å’Œæœç´¢å†å²åŠŸèƒ½å®Œæ•´
- å…¨éƒ¨æµ‹è¯•é€šè¿‡
- ä»£ç è´¨é‡é«˜ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

â³ **å¾…å®Œæˆ**
- Agenté›†æˆ
- APIæ¥å£
- LearningRecordsMemoryå®ç°
- ç”Ÿäº§ç¯å¢ƒé…ç½®

ğŸ¯ **ä¸‹ä¸€æ­¥**: é›†æˆåˆ°Communication Agentï¼Œå®ç°å»é‡è¿‡æ»¤åŠŸèƒ½

---

**Memoryç³»ç»Ÿå®ç°å®Œæˆï¼ä»£ç å·²æäº¤ï¼Œæµ‹è¯•å…¨éƒ¨é€šè¿‡** âœ…

---
---

# é¡¹ç›®å®Œå–„è®¡åˆ’ï¼ˆ2025-10-10æ›´æ–°ï¼‰

## Memoryç³»ç»Ÿç°çŠ¶æ£€æŸ¥

### âœ… å·²å®Œæˆé¡¹ï¼ˆPLAN.mdä¸­æ ‡è®°ä¸º"å¾…å®Œæˆ"çš„å®é™…å·²å®Œæˆï¼‰

1. **LearningRecordsMemory** - âœ… å·²å®Œå…¨å®ç°
   - æ–‡ä»¶ï¼š`backend/app/memory/learning_records_memory.py`ï¼ˆ287è¡Œï¼‰
   - åŠŸèƒ½å®Œæ•´ï¼šæ·»åŠ ã€æŸ¥è¯¢ã€ç»Ÿè®¡ã€åˆ é™¤å­¦ä¹ è®°å½•
   - æ–¹æ³•åˆ—è¡¨ï¼š
     - `add_record()` - æ·»åŠ å•æ¡è®°å½•
     - `add_batch_records()` - æ‰¹é‡æ·»åŠ 
     - `get_records()` - æŸ¥è¯¢è®°å½•ï¼ˆæ”¯æŒå¤šç§è¿‡æ»¤ï¼‰
     - `get_record_by_id()` - æŒ‰IDæŸ¥è¯¢
     - `get_stats()` - å­¦ä¹ ç»Ÿè®¡
     - `delete_record()` - åˆ é™¤è®°å½•

2. **Agenté›†æˆ** - âœ… å·²å®Œæˆ
   - æ–‡ä»¶ï¼š`backend/app/agents/serial/communication.py`
   - é›†æˆç‚¹ï¼š
     - Line 51: åŠ è½½seen_urlså®ç°å»é‡
     - Line 104: è®°å½•æœç´¢å†å²
     - Line 184: ä¿å­˜TEDè§‚çœ‹è®°å½•

3. **MemoryServiceç»Ÿä¸€å…¥å£** - âœ… å·²å®Œæˆ
   - æ–‡ä»¶ï¼š`backend/app/memory/service.py`ï¼ˆ237è¡Œï¼‰
   - Facadeæ¨¡å¼å°è£…ä¸‰ä¸ªå­MemoryæœåŠ¡

### âŒ æœªå®Œæˆé¡¹

1. **Memory APIæ¥å£** - æœªå®ç°
   - å½“å‰main.pyä¸­æ²¡æœ‰memoryç›¸å…³è·¯ç”±
   - éœ€è¦åˆ›å»ºç‹¬ç«‹çš„router

2. **Shadow Writingå®Œæˆåä¿å­˜å­¦ä¹ è®°å½•** - æœªå®ç°
   - éœ€è¦åœ¨workflowçš„finalizeèŠ‚ç‚¹è°ƒç”¨

3. **PostgreSQLç”Ÿäº§ç¯å¢ƒé…ç½®** - æœªé…ç½®
   - å½“å‰åªæœ‰InMemoryStoreï¼ˆé‡å¯ä¸¢å¤±ï¼‰

---

## æ¥ä¸‹æ¥çš„å¼€å‘ä»»åŠ¡

### P0 - æ ¸å¿ƒåŠŸèƒ½ï¼ˆå¿…é¡»å®Œæˆï¼‰

#### 1. Memory APIæ¥å£å®ç°

**é¢„è®¡æ—¶é—´**: 2-3å°æ—¶

**ä»»åŠ¡æ¸…å•**:
- [x] åˆ›å»º `backend/app/routers/memory.py`
- [x] å®ç°8ä¸ªAPIç«¯ç‚¹ï¼š
  - `GET /memory/ted-history/{user_id}` - è·å–TEDè§‚çœ‹å†å²
  - `GET /memory/search-history/{user_id}` - è·å–æœç´¢å†å²
  - `GET /memory/learning-records/{user_id}` - è·å–å­¦ä¹ è®°å½•
  - `GET /memory/learning-records/{user_id}/{record_id}` - è·å–å•æ¡è®°å½•
  - `GET /memory/stats/{user_id}` - è·å–å­¦ä¹ ç»Ÿè®¡
  - `GET /memory/summary/{user_id}` - è·å–ç”¨æˆ·æ€»è§ˆï¼ˆé¢å¤–ï¼‰
  - `POST /memory/learning-records` - æ‰‹åŠ¨æ·»åŠ å­¦ä¹ è®°å½•
  - `DELETE /memory/learning-records/{user_id}/{record_id}` - åˆ é™¤å­¦ä¹ è®°å½•
- [x] åœ¨main.pyä¸­æ³¨å†Œrouter
- [x] åˆ›å»ºæµ‹è¯•è„šæœ¬ `backend/test_memory_api.py`
- [ ] å¯åŠ¨æœåŠ¡å¹¶è¿è¡Œæµ‹è¯•éªŒè¯

**éªŒæ”¶æ ‡å‡†**:
- è®¿é—® http://localhost:8000/docs å¯è§æ–°å¢çš„API
- æ‰€æœ‰ç«¯ç‚¹æ­£å¸¸è¿”å›æ•°æ®
- æ”¯æŒåˆ†é¡µã€è¿‡æ»¤ã€æ’åº

---

#### 2. Shadow Writingç»“æœè‡ªåŠ¨ä¿å­˜åˆ°Memory

**é¢„è®¡æ—¶é—´**: 1å°æ—¶

**ä»»åŠ¡æ¸…å•**:
- [x] ä¿®æ”¹ `backend/app/agents/serial/finalize.py` çš„ `finalize_agent`
- [x] åœ¨å¤„ç†å®Œæˆåè°ƒç”¨ `memory.add_batch_learning_records()`
- [x] æå–tagsï¼ˆsearch_topic, ted_titleï¼‰
- [x] æ·»åŠ å®Œæ•´çš„é”™è¯¯å¤„ç†ï¼ˆMemoryå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•éªŒè¯

**ä»£ç ä½ç½®**:
```python
# backend/app/agents/serial/shadow_writing.py

def finalize_node(state: Shadow_Writing_State) -> Shadow_Writing_State:
    # ... ç°æœ‰é€»è¾‘ ...
    
    # æ–°å¢ï¼šä¿å­˜åˆ°Memory
    memory_service = MemoryService(store=get_global_store())
    record_ids = memory_service.add_batch_learning_records(
        user_id=state.get("user_id", "default_user"),
        ted_url=state["ted_data"].url,
        ted_title=state["ted_data"].title,
        ted_speaker=state["ted_data"].speaker,
        shadow_writings=final_results,
        default_tags=[state["topic"], state["ted_data"].title]
    )
    
    print(f"âœ… å·²ä¿å­˜ {len(record_ids)} æ¡å­¦ä¹ è®°å½•åˆ°Memory")
    
    return state
```

**éªŒæ”¶æ ‡å‡†**:
- å¤„ç†TEDåè‡ªåŠ¨ä¿å­˜å­¦ä¹ è®°å½•
- é€šè¿‡APIå¯æŸ¥è¯¢åˆ°ä¿å­˜çš„è®°å½•
- æ ‡ç­¾æ­£ç¡®ï¼ˆä¸¤çº§ï¼šsearch_topic, ted_titleï¼‰

---

#### 3. PostgreSQLç”Ÿäº§ç¯å¢ƒé…ç½®

**é¢„è®¡æ—¶é—´**: 1å°æ—¶

**ä»»åŠ¡æ¸…å•**:
- [x] Docker Composeé…ç½®PostgreSQL
- [x] åˆ›å»º `docker-compose.yml`
- [x] é…ç½®ç¯å¢ƒå˜é‡ `.env.example`
- [x] æ›´æ–°store_factory.pyä½¿ç”¨å®˜æ–¹PostgresStore
- [x] æ›´æ–°requirements.txtæ·»åŠ PostgreSQLä¾èµ–
- [x] åˆ›å»ºPostgreSQLåˆå§‹åŒ–è„šæœ¬ `init-db.sql`
- [x] æ›´æ–°æµ‹è¯•è„šæœ¬ `test_postgres.py`
- [ ] å®é™…æµ‹è¯•PostgreSQLè¿æ¥å’Œæ•°æ®æŒä¹…åŒ–

**Dockeré…ç½®**:
```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:16
    container_name: shadow-writing-postgres
    environment:
      POSTGRES_USER: shadow_writing
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: shadow_writing_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  postgres_data:
```

**ç¯å¢ƒå˜é‡**:
```bash
# .env
MEMORY_STORE_TYPE=postgres
POSTGRES_URI=postgresql://shadow_writing:your_password@localhost:5432/shadow_writing_db
```

**éªŒæ”¶æ ‡å‡†**:
- [x] PostgreSQLå®¹å™¨æ­£å¸¸è¿è¡Œ
- [x] ä½¿ç”¨LangGraphå®˜æ–¹PostgresStore
- [x] Memoryæ•°æ®æˆåŠŸæŒä¹…åŒ–
- [ ] å®é™…æµ‹è¯•ï¼šé‡å¯æœåŠ¡åæ•°æ®ä¸ä¸¢å¤±

**å®ç°è¯´æ˜**:
- ä½¿ç”¨`langgraph.store.postgres.PostgresStore`ï¼ˆå®˜æ–¹å®ç°ï¼‰
- æ”¯æŒè¿æ¥æ± ã€è‡ªåŠ¨å»ºè¡¨ã€JSONBå­˜å‚¨
- å·²åˆ é™¤è‡ªå®šä¹‰PostgresStoreï¼ˆä¸éœ€è¦ç»´æŠ¤ï¼‰
- å®Œæ•´æµ‹è¯•è„šæœ¬ï¼š`test_official_postgres_store.py`

---

### P1 - å¢å¼ºåŠŸèƒ½ï¼ˆå¼ºçƒˆå»ºè®®ï¼‰

#### 4. Langfuseå¯è§‚æµ‹æ€§é›†æˆ

**é¢„è®¡æ—¶é—´**: 2-3å°æ—¶

**ä»·å€¼**:
- è¿½è¸ªæ¯æ¬¡LLMè°ƒç”¨é“¾è·¯
- ç»Ÿè®¡Tokenæ¶ˆè€—å’Œæˆæœ¬
- åˆ†æPromptæ•ˆæœ
- å¿«é€Ÿå®šä½é—®é¢˜

**ä»»åŠ¡æ¸…å•**:
- [ ] Dockeréƒ¨ç½²Langfuse
- [ ] å®‰è£…SDK: `pip install langfuse`
- [ ] é…ç½®ç¯å¢ƒå˜é‡
- [ ] é›†æˆåˆ°workflow
- [ ] æµ‹è¯•Traceè®°å½•

**Dockeréƒ¨ç½²**:
```yaml
# docker-compose.yml (æ·»åŠ åˆ°ç°æœ‰æ–‡ä»¶)
  langfuse-server:
    image: langfuse/langfuse:latest
    container_name: shadow-writing-langfuse
    environment:
      DATABASE_URL: postgresql://shadow_writing:${POSTGRES_PASSWORD}@postgres:5432/langfuse_db
      NEXTAUTH_SECRET: ${LANGFUSE_SECRET}
      SALT: ${LANGFUSE_SALT}
      NEXTAUTH_URL: http://localhost:3000
    ports:
      - "3000:3000"
    depends_on:
      - postgres
```

**ä»£ç é›†æˆ**:
```python
# backend/app/workflows.py
from langfuse.callback import CallbackHandler

langfuse_handler = CallbackHandler(
    public_key=settings.langfuse_public_key,
    secret_key=settings.langfuse_secret_key,
    host="http://localhost:3000"
)

# åœ¨workflowè°ƒç”¨æ—¶æ·»åŠ callback
result = workflow.invoke(
    state,
    config={"callbacks": [langfuse_handler]}
)
```

**éªŒæ”¶æ ‡å‡†**:
- è®¿é—® http://localhost:3000 æŸ¥çœ‹Langfuse UI
- æ¯æ¬¡å¤„ç†TEDéƒ½æœ‰å®Œæ•´Trace
- å¯çœ‹åˆ°Tokenæ¶ˆè€—å’Œæˆæœ¬
- Dashboardæ˜¾ç¤ºç»Ÿè®¡æ•°æ®

---

### P2 - é«˜çº§åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰

#### 5. Prometheus + Grafanaç³»ç»Ÿç›‘æ§

**é¢„è®¡æ—¶é—´**: 4-6å°æ—¶

**ä»·å€¼**:
- ç›‘æ§ç³»ç»Ÿå±‚é¢æŒ‡æ ‡ï¼ˆCPUã€å†…å­˜ã€QPSï¼‰
- é…åˆLangfuseå½¢æˆå®Œæ•´ç›‘æ§ä½“ç³»
- é€‚åˆç”Ÿäº§ç¯å¢ƒ

**ä½•æ—¶å®æ–½**:
- éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒæ—¶
- éœ€è¦ç³»ç»Ÿçº§ç›‘æ§æ—¶
- å¤šå®ä¾‹è´Ÿè½½å‡è¡¡æ—¶

**æš‚æ—¶è·³è¿‡ç†ç”±**:
- å¼€å‘é˜¶æ®µmonitoringç›®å½•å·²æä¾›API Keyç›‘æ§
- Langfuseæä¾›äº†åº”ç”¨å±‚ç›‘æ§
- å¯ä»¥åç»­æŒ‰éœ€æ·»åŠ 

---

#### 6. Electronæ¡Œé¢åº”ç”¨

**é¢„è®¡æ—¶é—´**: 1-2å‘¨

**ä½•æ—¶å®æ–½**:
- ç¡®è®¤éœ€è¦æ¡Œé¢ç‰ˆæ—¶
- Webç‰ˆåŠŸèƒ½ç¨³å®šå

**æŠ€æœ¯é€‰å‹å»ºè®®**:
- å‰ç«¯ï¼šElectron + React + TailwindCSS
- åç«¯ï¼šFastAPIï¼ˆæœ¬åœ°å¯åŠ¨ï¼‰
- æ•°æ®åº“ï¼šSQLiteï¼ˆéœ€å®ç°SQLiteStoreï¼‰

**æš‚æ—¶è·³è¿‡ç†ç”±**:
- Webç‰ˆä¼˜å…ˆ
- å¯ä»¥ä½œä¸ºç‹¬ç«‹é‡Œç¨‹ç¢‘

---

## æŠ€æœ¯é€‰å‹è¯´æ˜

### ä¸ºä»€ä¹ˆé€‰æ‹©PostgreSQLè€Œä¸æ˜¯å…¶ä»–æ•°æ®åº“ï¼Ÿ

#### æ ¸å¿ƒåŸå› ï¼šLangGraphå®˜æ–¹å”¯ä¸€æ”¯æŒ

```python
# LangGraphå®˜æ–¹æ”¯æŒçš„Store
from langgraph.store.memory import InMemoryStore         # âœ… å¼€å‘ç¯å¢ƒ
from langgraph.checkpoint.postgres import PostgresStore  # âœ… ç”Ÿäº§ç¯å¢ƒ

# å…¶ä»–æ•°æ®åº“
from langgraph.checkpoint.mysql import MySQLStore        # âŒ ä¸å­˜åœ¨
from langgraph.checkpoint.mongodb import MongoDBStore    # âŒ ä¸å­˜åœ¨
```

#### æŠ€æœ¯ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | PostgreSQL | MySQL | MongoDB | SQLite |
|------|-----------|-------|---------|--------|
| **LangGraphæ”¯æŒ** | âœ… å®˜æ–¹ | âŒ éœ€è‡ªå®ç° | âŒ éœ€è‡ªå®ç° | âš ï¸ éœ€è‡ªå®ç° |
| **JSONBæ€§èƒ½** | âœ… ä¼˜ç§€ | âš ï¸ ä¸€èˆ¬ | âœ… ä¼˜ç§€ | âš ï¸ ä¸€èˆ¬ |
| **æ•°ç»„æ”¯æŒ** | âœ… åŸç”Ÿ | âŒ éœ€æ¨¡æ‹Ÿ | âœ… åŸç”Ÿ | âŒ éœ€æ¨¡æ‹Ÿ |
| **å…¨æ–‡æœç´¢** | âœ… å†…ç½® | âš ï¸ æœ‰é™ | âœ… å†…ç½® | âš ï¸ FTS5 |
| **å¹¶å‘æ€§èƒ½** | âœ… MVCC | âš ï¸ ä¸€èˆ¬ | âœ… å¥½ | âŒ å·® |
| **é€‚ç”¨åœºæ™¯** | Webå¤šç”¨æˆ· | Webå¤šç”¨æˆ· | Webå¤šç”¨æˆ· | å•ç”¨æˆ·æ¡Œé¢ |

#### éƒ¨ç½²å»ºè®®

**å¼€å‘ç¯å¢ƒ**:
```bash
# Dockeræ–¹å¼ï¼ˆæ¨èï¼‰
docker run -d \
  --name postgres-dev \
  -e POSTGRES_PASSWORD=dev123 \
  -e POSTGRES_DB=shadow_writing_db \
  -p 5432:5432 \
  postgres:16
```

**ç”Ÿäº§ç¯å¢ƒ**:
- Supabaseï¼ˆå…è´¹å±‚500MBï¼‰
- AWS RDSï¼ˆæŒ‰éœ€ä»˜è´¹ï¼‰
- è‡ªå»ºDocker

**æ¡Œé¢åº”ç”¨**:
- å»ºè®®ç”¨SQLite + è‡ªå®ç°SQLiteStore
- å·¥ä½œé‡ï¼š200è¡Œä»£ç ï¼Œ2-3å¤©

---

### Mem0 vs å½“å‰Memoryç³»ç»Ÿå¯¹æ¯”

#### Mem0æ˜¯ä»€ä¹ˆï¼Ÿ

Mem0æ˜¯ä¸€ä¸ª**æ™ºèƒ½è®°å¿†å±‚**æ¡†æ¶ï¼Œä½¿ç”¨LLMè‡ªåŠ¨ç®¡ç†è®°å¿†ï¼š

```python
# Mem0çš„å·¥ä½œæ–¹å¼
from mem0 import Memory

memory = Memory()

# è‡ªåŠ¨æå–è®°å¿†ï¼ˆè°ƒç”¨LLMï¼‰
memory.add("I love playing basketball on weekends", user_id="john")
# LLMæå–å¹¶å­˜å‚¨ï¼š
# - "Johnå–œæ¬¢æ‰“ç¯®çƒ"
# - "Johnå‘¨æœ«æœ‰ç©º"

# æ™ºèƒ½æ›´æ–°
memory.add("Actually, I prefer tennis now", user_id="john")
# LLMè‡ªåŠ¨ï¼š
# - åˆ é™¤"å–œæ¬¢æ‰“ç¯®çƒ"
# - æ·»åŠ "å–œæ¬¢ç½‘çƒ"
```

#### å¯¹æ¯”åˆ†æ

| ç»´åº¦ | Mem0 | å½“å‰Memoryç³»ç»Ÿ |
|------|------|---------------|
| **ç±»å‹** | æ™ºèƒ½è®°å¿†å±‚ | ç»“æ„åŒ–æ•°æ®å­˜å‚¨ |
| **æ ¸å¿ƒæŠ€æœ¯** | LLMæå–è¯­ä¹‰ | ç›´æ¥å­˜å‚¨æ•°æ®ç»“æ„ |
| **è®°å¿†ç®¡ç†** | è‡ªåŠ¨ï¼ˆLLMå†³å®šï¼‰ | æ‰‹åŠ¨ï¼ˆä»£ç æ˜¾å¼è°ƒç”¨ï¼‰ |
| **æ£€ç´¢** | è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ | ç²¾ç¡®åŒ¹é…/è¿‡æ»¤ |
| **æˆæœ¬** | é«˜ï¼ˆæ¯æ¬¡éœ€LLMï¼‰ | ä½ï¼ˆåªå­˜å‚¨ï¼‰ |
| **é€Ÿåº¦** | æ…¢ï¼ˆ500-2000msï¼‰ | å¿«ï¼ˆ<50msï¼‰ |
| **é€‚ç”¨åœºæ™¯** | èŠå¤©æœºå™¨äººã€ä¸ªæ€§åŒ–æ¨è | ç»“æ„åŒ–æ•°æ®ç®¡ç† |

#### æ˜¯å¦éœ€è¦åˆ‡æ¢åˆ°Mem0ï¼Ÿ

**æ¨èï¼šä¿æŒå½“å‰ç³»ç»Ÿ** âœ…

**ç†ç”±**:

1. **éœ€æ±‚ä¸åŒ¹é…**
   ```
   ä½ çš„éœ€æ±‚ï¼š
   - å­˜å‚¨Shadow Writingç»“æœï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
   - è®°å½•TEDè§‚çœ‹å†å²ï¼ˆç²¾ç¡®å»é‡ï¼‰
   - æœç´¢å†å²åˆ†æ
   
   â†’ è¿™äº›éƒ½æ˜¯æ˜ç¡®çš„ç»“æ„åŒ–æ•°æ®ï¼Œä¸éœ€è¦è¯­ä¹‰ç†è§£
   â†’ å½“å‰ç³»ç»Ÿå®Œå…¨æ»¡è¶³éœ€æ±‚
   ```

2. **æˆæœ¬å¯¹æ¯”**
   ```
   Mem0ï¼šæ¯å¤„ç†1ä¸ªTEDï¼ˆ150æ¡è®°å½•ï¼‰
   - 150æ¬¡LLMè°ƒç”¨ â‰ˆ $0.015-0.15
   
   å½“å‰ç³»ç»Ÿï¼š
   - å­˜å‚¨æˆæœ¬ï¼šå‡ ä¹ä¸º0
   - æŸ¥è¯¢æˆæœ¬ï¼šå‡ ä¹ä¸º0
   
   æ¯æœˆèŠ‚çœï¼š$5-50ï¼ˆå‡è®¾å¤„ç†100ä¸ªTEDï¼‰
   ```

3. **æ€§èƒ½å¯¹æ¯”**
   ```
   Mem0ï¼š
   - å­˜å‚¨å»¶è¿Ÿï¼š500-2000msï¼ˆLLMè°ƒç”¨ï¼‰
   - æŸ¥è¯¢å»¶è¿Ÿï¼š500-1000ms
   
   å½“å‰ç³»ç»Ÿï¼š
   - å­˜å‚¨å»¶è¿Ÿï¼š<10ms
   - æŸ¥è¯¢å»¶è¿Ÿï¼š<50ms
   
   â†’ å¿«50-100å€
   ```

**ä½•æ—¶è€ƒè™‘Mem0**:
- éœ€è¦èŠå¤©å¼å­¦ä¹ åŠ©æ‰‹
- éœ€è¦æ™ºèƒ½ä¸ªæ€§åŒ–æ¨è
- éœ€è¦è‡ªç„¶è¯­è¨€æŸ¥è¯¢å­¦ä¹ è®°å½•

---

## å®æ–½æ—¶é—´è¡¨

### ç¬¬1å‘¨ï¼šæ ¸å¿ƒåŠŸèƒ½å®Œæˆ

**Day 1-2: Memory APIæ¥å£**
- [ ] åˆ›å»º `backend/app/routers/memory.py`
- [ ] å®ç°7ä¸ªç«¯ç‚¹
- [ ] é›†æˆåˆ°main.py
- [ ] æµ‹è¯•æ‰€æœ‰åŠŸèƒ½

**Day 3: Shadow Writingè‡ªåŠ¨ä¿å­˜**
- [ ] ä¿®æ”¹finalize_node
- [ ] æ‰¹é‡ä¿å­˜å­¦ä¹ è®°å½•
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•

**Day 4: PostgreSQLé…ç½®**
- [ ] Docker Composeé…ç½®
- [ ] ç¯å¢ƒå˜é‡é…ç½®
- [ ] æµ‹è¯•æŒä¹…åŒ–
- [ ] æ•°æ®è¿ç§»éªŒè¯

**Day 5-7: Langfuseé›†æˆ**
- [ ] Dockeréƒ¨ç½²Langfuse
- [ ] SDKé›†æˆ
- [ ] æµ‹è¯•Traceè®°å½•
- [ ] Dashboardé…ç½®ä¼˜åŒ–

### ç¬¬2å‘¨ï¼šå¢å¼ºå’Œä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

**Day 8-10: Prometheusç›‘æ§ï¼ˆå¯é€‰ï¼‰**
- [ ] æ ¹æ®éœ€è¦å†³å®šæ˜¯å¦å®æ–½
- [ ] æˆ–è€…ä¸“æ³¨äºåŠŸèƒ½ä¼˜åŒ–

**Day 11-14: Electronæ¡Œé¢ç‰ˆï¼ˆå¯é€‰ï¼‰**
- [ ] ä»…åœ¨ç¡®è®¤éœ€è¦æ—¶å®æ–½
- [ ] å¯ä½œä¸ºç‹¬ç«‹é‡Œç¨‹ç¢‘

---

## éªŒæ”¶æ ‡å‡†

### P0ä»»åŠ¡éªŒæ”¶

**Memory APIæ¥å£**:
- [ ] è®¿é—® /docs å¯è§æ‰€æœ‰Memoryç«¯ç‚¹
- [ ] GET /memory/ted-history/{user_id} è¿”å›å†å²è®°å½•
- [ ] GET /memory/learning-records/{user_id} è¿”å›å­¦ä¹ è®°å½•
- [ ] GET /memory/stats/{user_id} è¿”å›ç»Ÿè®¡æ•°æ®
- [ ] æ”¯æŒåˆ†é¡µã€è¿‡æ»¤ã€æ’åºå‚æ•°

**Shadow Writingè‡ªåŠ¨ä¿å­˜**:
- [ ] å¤„ç†TEDåè‡ªåŠ¨ä¿å­˜å­¦ä¹ è®°å½•
- [ ] è®°å½•åŒ…å«å®Œæ•´æ•°æ®ï¼ˆoriginal, imitation, map, quality_scoreï¼‰
- [ ] æ ‡ç­¾æ­£ç¡®ï¼ˆsearch_topic, ted_titleï¼‰
- [ ] é€šè¿‡APIå¯æŸ¥è¯¢åˆ°ä¿å­˜çš„è®°å½•

**PostgreSQLé…ç½®**:
- [ ] Dockerå®¹å™¨æ­£å¸¸è¿è¡Œ
- [ ] æ•°æ®æˆåŠŸæŒä¹…åŒ–åˆ°PostgreSQL
- [ ] é‡å¯æœåŠ¡åæ•°æ®ä¸ä¸¢å¤±
- [ ] æŸ¥è¯¢æ€§èƒ½<100ms

### P1ä»»åŠ¡éªŒæ”¶

**Langfuseé›†æˆ**:
- [ ] Langfuse UIæ­£å¸¸è®¿é—®ï¼ˆhttp://localhost:3000ï¼‰
- [ ] æ¯æ¬¡å¤„ç†TEDéƒ½æœ‰å®Œæ•´Trace
- [ ] å¯çœ‹åˆ°æ¯ä¸ªAgentçš„è€—æ—¶
- [ ] Tokenç»Ÿè®¡å’Œæˆæœ¬æ˜¾ç¤ºæ­£ç¡®
- [ ] Dashboardæ˜¾ç¤ºèšåˆç»Ÿè®¡

---

## é£é™©å’Œç¼“è§£æªæ–½

### é£é™©1ï¼šPostgreSQLé…ç½®å¤æ‚

**ç¼“è§£æªæ–½**:
- ä½¿ç”¨Docker Composeç®€åŒ–éƒ¨ç½²
- æä¾›è¯¦ç»†çš„é…ç½®æ–‡æ¡£
- å¯å›é€€åˆ°InMemoryStoreï¼ˆå¼€å‘ç¯å¢ƒï¼‰

### é£é™©2ï¼šLangfuseå­¦ä¹ æ›²çº¿

**ç¼“è§£æªæ–½**:
- å…ˆå®ç°åŸºç¡€é›†æˆ
- Dashboardé…ç½®å¯åç»­ä¼˜åŒ–
- ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½

### é£é™©3ï¼šæ—¶é—´ä¼°ç®—åå·®

**ç¼“è§£æªæ–½**:
- P0ä»»åŠ¡å¿…é¡»å®Œæˆ
- P1ä»»åŠ¡å¯æŒ‰ä¼˜å…ˆçº§è°ƒæ•´
- P2ä»»åŠ¡å¯æ¨è¿Ÿåˆ°ä¸‹ä¸ªè¿­ä»£

---

## æ€»ç»“

### å½“å‰çŠ¶æ€
âœ… Memoryæ ¸å¿ƒåŠŸèƒ½å·²å®Œæˆ90%
âœ… Agenté›†æˆå·²å®Œæˆ
âœ… LearningRecordsMemoryå·²å®ç°
âŒ ç¼ºå°‘APIæ¥å£ï¼ˆ2-3å°æ—¶ï¼‰
âŒ ç¼ºå°‘PostgreSQLé…ç½®ï¼ˆ1å°æ—¶ï¼‰

### æ¥ä¸‹æ¥é‡ç‚¹
1. å®ŒæˆP0ä»»åŠ¡ï¼ˆ4-5å°æ—¶ï¼‰
2. Langfuseé›†æˆï¼ˆ2-3å°æ—¶ï¼‰
3. å…¶ä»–ä»»åŠ¡æŒ‰éœ€å®æ–½

### æŠ€æœ¯å†³ç­–
âœ… PostgreSQLï¼ˆå®˜æ–¹æ”¯æŒï¼Œæ€§èƒ½æœ€ä¼˜ï¼‰
âœ… ä¿æŒå½“å‰Memoryç³»ç»Ÿï¼ˆä¸ç”¨Mem0ï¼‰
âš ï¸ Prometheuså¯é€‰ï¼ˆå·²æœ‰monitoringç›®å½•ï¼‰
âš ï¸ Electronå»¶åï¼ˆWebç‰ˆä¼˜å…ˆï¼‰

---

**æ›´æ–°æ—¶é—´**: 2025-10-10  
**é¢„è®¡å®Œæˆæ—¶é—´**: P0ä»»åŠ¡1å‘¨å†…ï¼ŒP1ä»»åŠ¡2å‘¨å†…  
**é£é™©ç­‰çº§**: ä½ï¼ˆæ ¸å¿ƒåŠŸèƒ½å·²å®Œæˆï¼Œå‰©ä½™ä¸ºé›†æˆå’Œé…ç½®ï¼‰