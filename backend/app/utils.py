from litellm import completion
from app.config import settings
import json
import time
from collections import deque
from typing import Callable, Optional, Dict, Any

def ensure_dependencies():
    """æ£€æŸ¥ API key æ˜¯å¦é…ç½®"""
    if not settings.groq_api_key:
        raise ValueError("GROQ_API_KEY not set")
    print("Groq API already configured")


# ==================== API Key ç®¡ç†å™¨ ====================

class APIKeyManager:
    """API Key è½®æ¢ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    - ç®¡ç†å¤šä¸ª API Key çš„è½®è¯¢ä½¿ç”¨
    - æ£€æµ‹é€Ÿç‡é™åˆ¶é”™è¯¯å¹¶è‡ªåŠ¨åˆ‡æ¢
    - å¯¹è¾¾åˆ°é™åˆ¶çš„ Key è®¾ç½®å†·å´æ—¶é—´
    """
    
    def __init__(self, keys: list[str], cooldown_seconds: int = 60):
        """åˆå§‹åŒ– API Key ç®¡ç†å™¨
        
        Args:
            keys: API Key åˆ—è¡¨
            cooldown_seconds: å†·å´æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
        """
        if not keys:
            raise ValueError("è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ª API Key")
        
        self.keys = deque(keys)  # ä½¿ç”¨åŒç«¯é˜Ÿåˆ—ä¾¿äºè½®è¯¢
        self.cooldown_seconds = cooldown_seconds
        self.key_failures = {key: 0 for key in keys}  # è®°å½•æ¯ä¸ª Key çš„å¤±è´¥æ¬¡æ•°
        self.key_cooldown = {}  # è®°å½•æ¯ä¸ª Key çš„å†·å´ç»“æŸæ—¶é—´æˆ³
        self.total_calls = 0  # æ€»è°ƒç”¨æ¬¡æ•°
        self.total_switches = 0  # æ€»åˆ‡æ¢æ¬¡æ•°
        
        print(f"API Key ç®¡ç†å™¨åˆå§‹åŒ–: {len(keys)} ä¸ª Key, å†·å´æ—¶é—´ {cooldown_seconds}ç§’")
    
    def get_key(self) -> str:
        """è·å–å½“å‰å¯ç”¨çš„ Key
        
        Returns:
            str: å½“å‰å¯ç”¨çš„ API Key
        """
        current_time = time.time()
        
        # å°è¯•æ‰¾åˆ°ä¸€ä¸ªä¸åœ¨å†·å´æœŸçš„ Key
        for _ in range(len(self.keys)):
            key = self.keys[0]
            cooldown_until = self.key_cooldown.get(key, 0)
            
            if current_time >= cooldown_until:
                # æ‰¾åˆ°å¯ç”¨çš„ Key
                return key
            
            # å½“å‰ Key è¿˜åœ¨å†·å´ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
            remaining_time = int(cooldown_until - current_time)
            print(f"Key ***{key[-8:]} å†·å´ä¸­ï¼Œå‰©ä½™ {remaining_time}ç§’")
            self.keys.rotate(-1)
        
        # æ‰€æœ‰ Key éƒ½åœ¨å†·å´ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¹¶ç­‰å¾…
        key = self.keys[0]
        cooldown_until = self.key_cooldown.get(key, 0)
        wait_time = max(0, cooldown_until - current_time)
        
        if wait_time > 0:
            print(f"æ‰€æœ‰ Key éƒ½åœ¨å†·å´ä¸­ï¼Œç­‰å¾… {int(wait_time)}ç§’...")
            time.sleep(wait_time)
        
        return key
    
    def rotate_key(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª Key"""
        self.keys.rotate(-1)
        self.total_switches += 1
        new_key = self.keys[0]
        print(f"åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API Key: ***{new_key[-8:]}")
    
    def mark_failure(self, key: str, error_message: str):
        """æ ‡è®° Key å¤±è´¥å¹¶å¤„ç†
        
        Args:
            key: å¤±è´¥çš„ API Key
            error_message: é”™è¯¯ä¿¡æ¯
        """
        self.key_failures[key] = self.key_failures.get(key, 0) + 1
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
        error_lower = error_message.lower()
        is_rate_limit = any(keyword in error_lower for keyword in [
            'rate', 'limit', 'quota', 'exceeded', 'too many'
        ])
        
        if is_rate_limit:
            # è®¾ç½®å†·å´æ—¶é—´
            cooldown_until = time.time() + self.cooldown_seconds
            self.key_cooldown[key] = cooldown_until
            
            print(f" Key ***{key[-8:]} è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œå†·å´ {self.cooldown_seconds}ç§’")
            print(f"å¤±è´¥æ¬¡æ•°: {self.key_failures[key]}")
            
            # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª Key
            self.rotate_key()
        else:
            print(f" Key ***{key[-8:]} è°ƒç”¨å¤±è´¥ï¼ˆéé€Ÿç‡é™åˆ¶ï¼‰: {error_message[:100]}")
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            dict: åŒ…å«æ€»è°ƒç”¨æ¬¡æ•°ã€åˆ‡æ¢æ¬¡æ•°ã€å¤±è´¥æ¬¡æ•°ç­‰ä¿¡æ¯
        """
        return {
            'total_keys': len(self.keys),
            'total_calls': self.total_calls,
            'total_switches': self.total_switches,
            'key_failures': dict(self.key_failures),
            'active_key': f"***{self.keys[0][-8:]}"
        }


# å…¨å±€ API Key ç®¡ç†å™¨å®ä¾‹
api_key_manager: Optional[APIKeyManager] = None


def initialize_key_manager(cooldown_seconds: int = 60):
    """åˆå§‹åŒ– API Key ç®¡ç†å™¨
    
    Args:
        cooldown_seconds: å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
    """
    global api_key_manager
    
    if settings.groq_api_keys and len(settings.groq_api_keys) > 1:
        api_key_manager = APIKeyManager(settings.groq_api_keys, cooldown_seconds)
        print(f"å¤š Key è½®æ¢å·²å¯ç”¨")
    else:
        api_key_manager = None
        if settings.groq_api_key:
            print(f"åªæœ‰ 1 ä¸ª API Keyï¼Œæœªå¯ç”¨è½®æ¢ï¼ˆå»ºè®®é…ç½®å¤šä¸ª Keyï¼‰")
        else:
            print(f"æœªé…ç½® API Key")


# ==================== LLM è°ƒç”¨å‡½æ•° ====================

def create_llm_function(system_prompt: Optional[str] = None) -> Callable:
    """åˆ›å»º LLM è°ƒç”¨å‡½æ•°
    
    Args:
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        callable: LLM è°ƒç”¨å‡½æ•°
    """
    
    def call_llm(user_prompt: str, output_format: Optional[Dict] = None, temperature: Optional[float] = None, _retry_count: int = 0) -> Any:
        """è°ƒç”¨ LLMï¼ˆæ”¯æŒè‡ªåŠ¨ Key åˆ‡æ¢ï¼‰
        
        Args:
            user_prompt: ç”¨æˆ·æç¤ºè¯
            output_format: è¾“å‡ºæ ¼å¼å­—å…¸ï¼ˆå¦‚æœæŒ‡å®šï¼Œåˆ™è¿”å› JSONï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼‰
            _retry_count: é‡è¯•è®¡æ•°ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
            
        Returns:
            str or dict: LLM å“åº”å†…å®¹
        """
        # è·å–å½“å‰å¯ç”¨çš„ API Key
        if api_key_manager:
            current_key = api_key_manager.get_key()
            api_key_manager.total_calls += 1
        else:
            current_key = settings.groq_api_key
        
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": user_prompt})
            
            # è°ƒç”¨å‚æ•°
            kwargs = {
                "model": f"groq/{settings.model_name}",
                "messages": messages,
                "temperature": temperature if temperature is not None else settings.temperature,
                "api_key": current_key,  # ä½¿ç”¨å½“å‰ Key
            }
            
            # å¦‚æœéœ€è¦ JSON è¾“å‡º
            if output_format:
                kwargs["response_format"] = {"type": "json_object"}
            
            # è°ƒç”¨ LiteLLM
            response = completion(**kwargs)
            content = response.choices[0].message.content
            
            # è§£æ JSON
            if output_format:
                return json.loads(content)
            
            return content
            
        except json.JSONDecodeError as e:
            print(f"JSON parsing failed: {e}")
            return None
            
        except Exception as e:
            error_msg = str(e)
            
            # æ£€æµ‹æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
            is_rate_limit = any(keyword in error_msg.lower() for keyword in [
                'rate', 'limit', 'quota', 'exceeded', 'too many'
            ])
            
            if is_rate_limit and api_key_manager:
                # æ ‡è®°å½“å‰ Key å¤±è´¥
                api_key_manager.mark_failure(current_key, error_msg)
                
                # é™åˆ¶é‡è¯•æ¬¡æ•°ï¼ˆæœ€å¤šé‡è¯• Key æ•°é‡æ¬¡ï¼‰
                max_retries = len(api_key_manager.keys)
                if _retry_count < max_retries:
                    print(f"ğŸ”„ é‡è¯•ä¸­... ({_retry_count + 1}/{max_retries})")
                    # é€’å½’é‡è¯•ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨ä¸‹ä¸€ä¸ª Keyï¼‰
                    return call_llm(user_prompt, output_format, temperature, _retry_count + 1)
                else:
                    print(f"âŒ æ‰€æœ‰ API Key éƒ½å·²å°è¯•ï¼Œä»ç„¶å¤±è´¥")
                    return None
            else:
                # éé€Ÿç‡é™åˆ¶é”™è¯¯æˆ–æ²¡æœ‰ç®¡ç†å™¨
                print(f"LLM call failed: {e}")
                return None
    
    return call_llm


def create_llm_function_native() -> Callable:
    """åˆ›å»ºåŸç”Ÿ LLM å‡½æ•°ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
    
    Returns:
        callable: LLM è°ƒç”¨å‡½æ•°
    """
    return create_llm_function(system_prompt=settings.system_prompt)